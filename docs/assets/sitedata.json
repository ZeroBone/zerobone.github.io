

{
  "pages": [
    {
      
      
      
      "content": "\n",
      "url": "/404.html"
    },{
      
      "title": "Blog",
      "description": "Alexander Mayorov’s blog about computer science.\n",
      "content": "\n",
      "url": "/blog/"
    },{
      
      "title": "Other",
      "description": "This page contains some of my summaries, cheat sheets and other materials that you might also find useful.\n",
      "content": "\n  Integral table.\n  Boolean algebra.\n\n",
      "url": "/other/"
    },{
      
      "title": "Welcome",
      
      "content": "Hi, I am Alexander Mayorov (aka ZeroBone) and this is my personal website. I am currently a computer science student and a backend developer.\n\nApart from studying I do research. My fields of interests:\n\n\n  Theoretical computer science, formal languages &amp; computability\n  Compiler design and programming languages\n  Formal verification and automated proof procedures\n  Group theory &amp; linear algebra\n  Graph theory\n\n\nLatest posts\n\n\n\nLatest projects\n\n\n",
      "url": "/"
    },{
      
      
      
      "content": "\n",
      "url": "/offline.html"
    },{
      
      "title": "Posts",
      
      "content": "\n",
      "url": "/posts/"
    },{
      
      "title": "Projects",
      "description": "Most of my open-source projects are listed on this page. Every project has a link to a GitHub repo with all the details and the source code.\n",
      "content": "\n",
      "url": "/projects/"
    },{
      
      "title": "Resume",
      "description": "Alexander Mayorov’s resume as a software engineer.\n",
      "content": "\n",
      "url": "/resume/"
    },{
      
      "title": "Boolean algebra cheat sheet",
      
      "content": "\n  Operator Precedence\n  Axioms\n  Basic laws\n  Implication properties    \n      Simplification rules\n      Rewrite rules\n      Implication in a operator basis\n    \n  \n  XOR and equivalence properties\n  NAND and NOR\n  Linear clause forms\n\nOperator Precedence\n\nFirst operators in this list bind stronger:\n\n\n  ¬\\neg¬ (Negation)\n  ∧\\wedge∧ (And)\n  ⊕\\oplus⊕ (Xor)\n  ∨\\vee∨ (Or)\n  →\\rightarrow→ (Implication)\n  ↔\\leftrightarrow↔ (Equivalence)\n\n\nFrom this point on we will use multiplication (⋅\\cdot⋅) instead of ∧\\wedge∧ and +++ instead of ∨\\vee∨. Also, instead of writing ¬a\\neg a¬a we will write aˉ\\bar{a}aˉ.\n\nAxioms\n\na+b=b+aa⋅b=b⋅a}commutativitya(b+c)=ab+aca+bc=(a+b)(a+c)}distributivitya+0=aa⋅1=a}neutral elementsa+aˉ=1a⋅aˉ=0}complement\\begin{aligned}\n\\left.\\begin{aligned}\na + b &amp;= b + a \\\\\na \\cdot b &amp;= b \\cdot a\n\\end{aligned}\\right\\rbrace\n&amp;\\text{commutativity} \\\\\n\\left.\\begin{aligned}\na(b + c) &amp;= ab + ac \\\\\na + bc &amp;= (a + b)(a + c)\n\\end{aligned}\\right\\rbrace\n&amp;\\text{distributivity} \\\\\n\\left.\\begin{aligned}\na + 0 &amp;= a \\\\\na \\cdot 1 &amp;= a\n\\end{aligned}\\right\\rbrace\n&amp;\\text{neutral elements} \\\\\n\\left.\\begin{aligned}\na + \\bar{a} &amp;= 1 \\\\\na \\cdot \\bar{a} &amp;= 0\n\\end{aligned}\\right\\rbrace\n&amp;\\text{complement}\n\\end{aligned}a+ba⋅b​=b+a=b⋅a​}a(b+c)a+bc​=ab+ac=(a+b)(a+c)​}a+0a⋅1​=a=a​}a+aˉa⋅aˉ​=1=0​}​commutativitydistributivityneutral elementscomplement​\n\nBasic laws\n\na+a=aa⋅a=a}idempotencya+1=1a⋅0=0}killer elementsa+ab=aa(a+b)=a}absorbtion(a+b)+c=a+(b+c)(a⋅b)⋅c=a⋅(b⋅c)}associativitya+b‾=aˉ⋅bˉa⋅b‾=aˉ+bˉ}De Morganaˉˉ=a}involutionab+bc+aˉc=ab+aˉc(a+b)(b+c)(aˉ+c)=(a+b)(aˉ+c)}consensus\\begin{aligned}\n\\left.\\begin{aligned}\na + a &amp;= a \\\\\na \\cdot a &amp;= a\n\\end{aligned}\\right\\rbrace\n&amp;\\text{idempotency} \\\\\n\\left.\\begin{aligned}\na + 1 &amp;= 1 \\\\\na \\cdot 0 &amp;= 0\n\\end{aligned}\\right\\rbrace\n&amp;\\text{killer elements} \\\\\n\\left.\\begin{aligned}\na + ab &amp;= a \\\\\na(a + b) &amp;= a\n\\end{aligned}\\right\\rbrace\n&amp;\\text{absorbtion} \\\\\n\\left.\\begin{aligned}\n(a + b) + c &amp;= a + (b + c) \\\\\n(a \\cdot b) \\cdot c &amp;= a \\cdot (b \\cdot c)\n\\end{aligned}\\right\\rbrace\n&amp;\\text{associativity} \\\\\n\\left.\\begin{aligned}\n\\overline{a + b} &amp;= \\bar{a} \\cdot \\bar{b} \\\\\n\\overline{a \\cdot b} &amp;= \\bar{a} + \\bar{b}\n\\end{aligned}\\right\\rbrace\n&amp;\\text{De Morgan} \\\\\n\\left.\\begin{aligned}\n\\bar{\\bar{a}} &amp;= a\n\\end{aligned}\\right\\rbrace\n&amp;\\text{involution} \\\\\n\\left.\\begin{aligned}\nab + bc + \\bar{a}c &amp;= ab + \\bar{a}c \\\\\n(a + b)(b + c)(\\bar{a} + c) &amp;= (a + b)(\\bar{a} + c)\n\\end{aligned}\\right\\rbrace\n&amp;\\text{consensus}\n\\end{aligned}a+aa⋅a​=a=a​}a+1a⋅0​=1=0​}a+aba(a+b)​=a=a​}(a+b)+c(a⋅b)⋅c​=a+(b+c)=a⋅(b⋅c)​}a+b​a⋅b​=aˉ⋅bˉ=aˉ+bˉ​}aˉˉ​=a​}ab+bc+aˉc(a+b)(b+c)(aˉ+c)​=ab+aˉc=(a+b)(aˉ+c)​}​idempotencykiller elementsabsorbtionassociativityDe Morganinvolutionconsensus​\n\nImplication properties\n\nSimplification rules\n\n0→a=11→a=aa→1=1a→0=aˉa→aˉ=aˉa→a=1a→(a→b)=a→ba→(b→a)=1(a→b)→a=a\\begin{aligned}\n0 \\rightarrow a &amp;= 1 \\\\\n1 \\rightarrow a &amp;= a \\\\\na \\rightarrow 1 &amp;= 1 \\\\\na \\rightarrow 0 &amp;= \\bar{a} \\\\\na \\rightarrow \\bar{a} &amp;= \\bar{a} \\\\\na \\rightarrow a &amp;= 1 \\\\\na \\rightarrow (a \\rightarrow b) &amp;= a \\rightarrow b \\\\\na \\rightarrow (b \\rightarrow a) &amp;= 1 \\\\\n(a \\rightarrow b) \\rightarrow a &amp;= a\n\\end{aligned}0→a1→aa→1a→0a→aˉa→aa→(a→b)a→(b→a)(a→b)→a​=1=a=1=aˉ=aˉ=1=a→b=1=a​\n\nRewrite rules\n\na→b=aˉ+ba→b‾=abˉa→b=bˉ→aˉa→bc=(a→b)(a→c)a→b+c=(a→b)+(a→c)(a+b)→c=(a→c)(b→c)\\begin{aligned}\na \\rightarrow b &amp;= \\bar{a} + b \\\\\n\\overline{a \\rightarrow b} &amp;= a\\bar{b} \\\\\na \\rightarrow b &amp;= \\bar{b} \\rightarrow \\bar{a} \\\\\na \\rightarrow bc &amp;= (a \\rightarrow b)(a \\rightarrow c) \\\\\na \\rightarrow b + c &amp;= (a \\rightarrow b) + (a \\rightarrow c) \\\\\n(a + b) \\rightarrow c &amp;= (a \\rightarrow c)(b \\rightarrow c)\n\\end{aligned}a→ba→ba→ba→bca→b+c(a+b)→c​=aˉ+b=abˉ=bˉ→aˉ=(a→b)(a→c)=(a→b)+(a→c)=(a→c)(b→c)​\n\nImplication in a operator basis\n\naˉ=a→0a⋅b=a→bˉ‾a⋅b=(a→(b→0))→0a+b=(a→b)→b\\begin{aligned}\n\\bar{a} &amp;= a \\rightarrow 0 \\\\\na \\cdot b &amp;= \\overline{a \\rightarrow \\bar{b}} \\\\\na \\cdot b &amp;= (a \\rightarrow (b \\rightarrow 0)) \\rightarrow 0 \\\\\na + b &amp;= (a \\rightarrow b) \\rightarrow b\n\\end{aligned}aˉa⋅ba⋅ba+b​=a→0=a→bˉ=(a→(b→0))→0=(a→b)→b​\n\nXOR and equivalence properties\n\na⊕0=aa⊕1=aˉa⊕a=0a⊕b=abˉ+aˉba⊕b=aˉ⊕bˉa⊕b=aˉ↔b=a↔bˉa⊕b=a↔b‾a⋅(b⊕c)=ab⊕aca+b=ab⊕a⊕ba→b=ab⊕a⊕1a↔b=a⊕b⊕1\\begin{aligned}\na \\oplus 0 &amp;= a \\\\\na \\oplus 1 &amp;= \\bar{a} \\\\\na \\oplus a &amp;= 0 \\\\\na \\oplus b &amp;= a\\bar{b} + \\bar{a}b \\\\\na \\oplus b &amp;= \\bar{a} \\oplus \\bar{b} \\\\\na \\oplus b &amp;= \\bar{a} \\leftrightarrow b = a \\leftrightarrow \\bar{b} \\\\\na \\oplus b &amp;= \\overline{a \\leftrightarrow b} \\\\\na \\cdot (b \\oplus c) &amp;= ab \\oplus ac \\\\\na + b &amp;= ab \\oplus a \\oplus b \\\\\na \\rightarrow b &amp;= ab \\oplus a \\oplus 1 \\\\\na \\leftrightarrow b &amp;= a \\oplus b \\oplus 1\n\\end{aligned}a⊕0a⊕1a⊕aa⊕ba⊕ba⊕ba⊕ba⋅(b⊕c)a+ba→ba↔b​=a=aˉ=0=abˉ+aˉb=aˉ⊕bˉ=aˉ↔b=a↔bˉ=a↔b=ab⊕ac=ab⊕a⊕b=ab⊕a⊕1=a⊕b⊕1​\n\nNAND and NOR\n\naˉ=a⊼aaˉ=a⊻aa⊼b‾=aˉ⊻bˉa⊻b‾=aˉ⊼bˉa⋅b=(a⊼b)⊼(a⊼b)a⋅b=(a⊻a)⊻(b⊻b)a+b=(a⊼a)⊼(b⊼b)a+b=(a⊻b)⊻(a⊻b)a⊕b=(a⊼(a⊼b))⊼((a⊼b)⊼b)a⊕b=(a⊻b)⊻((a⊻a)⊻(b⊻b))a↔b=(a⊼b)⊼((a⊼a)⊼(b⊼b))a↔b=(a⊻(a⊻b))⊻((a⊻b)⊻b)\\begin{aligned}\n\\bar{a} &amp;= a \\barwedge a \\\\\n\\bar{a} &amp;= a \\veebar a \\\\\n\\overline{a \\barwedge b} &amp;= \\bar{a} \\veebar \\bar{b} \\\\\n\\overline{a \\veebar b} &amp;= \\bar{a} \\barwedge \\bar{b} \\\\\na \\cdot b &amp;= (a \\barwedge b) \\barwedge (a \\barwedge b) \\\\\na \\cdot b &amp;= (a \\veebar a) \\veebar (b \\veebar b) \\\\\na + b &amp;= (a \\barwedge a) \\barwedge (b \\barwedge b) \\\\\na + b &amp;= (a \\veebar b) \\veebar (a \\veebar b) \\\\\na \\oplus b &amp;= (a \\barwedge (a \\barwedge b))\\barwedge ((a \\barwedge b) \\barwedge b) \\\\\na \\oplus b &amp;= (a \\veebar b) \\veebar ((a \\veebar a) \\veebar (b \\veebar b)) \\\\\na \\leftrightarrow b &amp;= (a \\barwedge b) \\barwedge ((a \\barwedge a) \\barwedge (b \\barwedge b)) \\\\\na \\leftrightarrow b &amp;= (a \\veebar (a \\veebar b)) \\veebar ((a \\veebar b) \\veebar b)\n\\end{aligned}aˉaˉa⊼b​a⊻b​a⋅ba⋅ba+ba+ba⊕ba⊕ba↔ba↔b​=a⊼a=a⊻a=aˉ⊻bˉ=aˉ⊼bˉ=(a⊼b)⊼(a⊼b)=(a⊻a)⊻(b⊻b)=(a⊼a)⊼(b⊼b)=(a⊻b)⊻(a⊻b)=(a⊼(a⊼b))⊼((a⊼b)⊼b)=(a⊻b)⊻((a⊻a)⊻(b⊻b))=(a⊼b)⊼((a⊼a)⊼(b⊼b))=(a⊻(a⊻b))⊻((a⊻b)⊻b)​\n\nLinear clause forms\n\nThese minimum conjunctive normal forms are often used to construct a linear clause form of some formula. The CNF is then typically passed to a SAT-solver.\n\nx↔aˉ=(xˉ+aˉ)(x+a)x↔a⋅b=(xˉ+a)(xˉ+b)(x+aˉ+bˉ)x↔a+b=(x+aˉ)(x+bˉ)(xˉ+a+b)x↔a⊕b=(x+a+bˉ)(x+aˉ+b)(xˉ+a+b)(xˉ+aˉ+bˉ)x↔a→b=(x+a)(x+bˉ)(xˉ+aˉ+b)x↔a↔b=(xˉ+aˉ+b)(xˉ+a+bˉ)(x+aˉ+bˉ)(x+a+b)\\begin{aligned}\nx \\leftrightarrow \\bar{a} &amp;= (\\bar{x} + \\bar{a})(x + a) \\\\\nx \\leftrightarrow a \\cdot b &amp;= (\\bar{x} + a)(\\bar{x} + b)(x + \\bar{a} + \\bar{b}) \\\\\nx \\leftrightarrow a + b &amp;= (x + \\bar{a})(x + \\bar{b})(\\bar{x} + a + b) \\\\\nx \\leftrightarrow a \\oplus b &amp;= (x + a + \\bar{b})(x + \\bar{a} + b)(\\bar{x} + a + b)(\\bar{x} + \\bar{a} + \\bar{b}) \\\\\nx \\leftrightarrow a \\rightarrow b &amp;= (x + a)(x + \\bar{b})(\\bar{x} + \\bar{a} + b) \\\\\nx \\leftrightarrow a \\leftrightarrow b &amp;= (\\bar{x} + \\bar{a} + b)(\\bar{x} + a + \\bar{b})(x + \\bar{a} + \\bar{b})(x + a + b)\n\\end{aligned}x↔aˉx↔a⋅bx↔a+bx↔a⊕bx↔a→bx↔a↔b​=(xˉ+aˉ)(x+a)=(xˉ+a)(xˉ+b)(x+aˉ+bˉ)=(x+aˉ)(x+bˉ)(xˉ+a+b)=(x+a+bˉ)(x+aˉ+b)(xˉ+a+b)(xˉ+aˉ+bˉ)=(x+a)(x+bˉ)(xˉ+aˉ+b)=(xˉ+aˉ+b)(xˉ+a+bˉ)(x+aˉ+bˉ)(x+a+b)​\n",
      "url": "/other/boolean-algebra/"
    },{
      
      "title": "Integral table",
      
      "content": "\n  Inverse derivatives\n  Standart integrals\n\n\nInverse derivatives\n\n∫dx=x+C\\int \\mathrm{d}x = x + C∫dx=x+C\n\n∫0dx=C\\int 0\\mathrm{d}x = C∫0dx=C\n\n∫xmdx=xm+1m+1+C,m≠−1\\int x^m\\mathrm{d}x = \\frac{x^{m+1}}{m+1} + C, m \\neq -1∫xmdx=m+1xm+1​+C,m​=−1\n\n∫dxx=ln⁡∣x∣+C\\int \\frac{\\mathrm{d}x}{x} = \\ln|x| + C∫xdx​=ln∣x∣+C\n\n∫cos⁡(x)dx=sin⁡(x)+C\\int \\cos(x) \\mathrm{d}x = \\sin(x) + C∫cos(x)dx=sin(x)+C\n\n∫sin⁡(x)dx=−cos⁡(x)+C\\int \\sin(x) \\mathrm{d}x = -\\cos(x) + C∫sin(x)dx=−cos(x)+C\n\n∫dx1+x2=arctg⁡(x)+C=−arcctg⁡(x)+C\\int \\frac{\\mathrm{d}x}{1+x^2} = \\arctg(x) + C = -\\arcctg(x) + C∫1+x2dx​=arctg(x)+C=−arcctg(x)+C\n\n∫dx1−x2=arcsin⁡(x)+C=−arccos⁡(x)+C\\int \\frac{\\mathrm{d}x}{\\sqrt{1-x^2}} = \\arcsin(x) + C = -\\arccos(x) + C∫1−x2​dx​=arcsin(x)+C=−arccos(x)+C\n\n∫axdx=axln⁡a+C\\int a^x \\mathrm{d}x = \\frac{a^x}{\\ln a} + C∫axdx=lnaax​+C\n\n∫exdx=ex+C\\int e^x \\mathrm{d}x = e^x + C∫exdx=ex+C\n\n∫sec⁡(x)2dx=∫dxcos⁡(x)2=tg⁡(x)+C\\int \\sec(x)^2 \\mathrm{d}x = \\int \\frac{dx}{\\cos(x)^2} = \\tg(x) + C∫sec(x)2dx=∫cos(x)2dx​=tg(x)+C\n\n∫cosec⁡(x)2dx=∫dxsin⁡(x)2=−ctg⁡(x)+C\\int \\cosec(x)^2 \\mathrm{d}x = \\int \\frac{dx}{\\sin(x)^2} = -\\ctg(x) + C∫cosec(x)2dx=∫sin(x)2dx​=−ctg(x)+C\n\n∫sh⁡(x)dx=ch⁡(x)+C\\int \\sh(x)\\mathrm{d}x = \\ch(x) + C∫sh(x)dx=ch(x)+C\n\n∫ch⁡(x)dx=sh⁡(x)+C\\int \\ch(x)\\mathrm{d}x = \\sh(x) + C∫ch(x)dx=sh(x)+C\n\n∫dxch⁡(x)2=th⁡(x)+C\\int \\frac{\\mathrm{d}x}{\\ch(x)^2} = \\th(x) + C∫ch(x)2dx​=th(x)+C\n\n∫dxsh⁡(x)2=−cth⁡(x)+C\\int \\frac{\\mathrm{d}x}{\\sh(x)^2} = -\\cth(x) + C∫sh(x)2dx​=−cth(x)+C\n\nStandart integrals\n\n∫dxx2+a2=1aarctg⁡(xa)+C\\int \\frac{\\mathrm{d}x}{x^2 + a^2} = \\frac{1}{a} \\arctg\\Big(\\frac{x}{a}\\Big) + C∫x2+a2dx​=a1​arctg(ax​)+C\n\n∫dxx2−a2=12aln⁡∣x−ax+a∣+C\\int \\frac{\\mathrm{d}x}{x^2 - a^2} = \\frac{1}{2a}\\ln\\Big|\\frac{x-a}{x+a}\\Big| + C∫x2−a2dx​=2a1​ln∣∣∣∣​x+ax−a​∣∣∣∣​+C\n\n∫dxx2±a2=ln⁡∣x+x2±a2∣+C\\int \\frac{\\mathrm{d}x}{\\sqrt{x^2 \\pm a^2}} = \\ln|x + \\sqrt{x^2 \\pm a^2}| + C∫x2±a2​dx​=ln∣x+x2±a2​∣+C\n\n∫dxa2−x2=arcsin⁡(xa)+C\\int \\frac{\\mathrm{d}x}{\\sqrt{a^2 - x^2}} = \\arcsin \\Big(\\frac{x}{a}\\Big) + C∫a2−x2​dx​=arcsin(ax​)+C\n",
      "url": "/other/int-table/"
    }
  ], 
  "documents": [
    {
      "image": "../../assets/img/blog/call-stack-buffer-overflow.svg",
      "title": "Call Stack - buffer overflow vulnerability",
      "date": "2019-06-30 00:00:00 +0200",
      
      "content": "Buffer overflows are a kind of call stack vulnerability that occur when buffers are created on the stack, but accessed improperly. Buffer underruns are typically not so dangerous, because writing in the current stack frame or beyond the stack pointer will only affect local variables on that stack frame. On the other side, buffer overruns can allow the attacker to overwrite the return address and thus even modify the program’s behaviour.\n\nBuffer overflow\n\nC programmers often allocate buffers on the stack to handle user input. If the input reading logic is implemented incorrectly and has now buffer length checks, a underflow/overflow can happen. If the user input is long enouph, it will overwrite the saved ebp register of the previous stack frame and, what matters most, the return address.\n\n\n\nExample\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nvoid __attribute__((noinline)) fun(int a, int b, int c) {\n\t\n\tchar buffer[16] = {0};\n\t\n\tint* prevEbp = &amp;a - 2;\n\tint* ret = &amp;a - 1;\n\t\n\tprintf(\"Buffer start: %p Buffer start pointer address: %p\\n\", buffer, &amp;buffer);\n\tprintf(\"Previous EBP: %p Value: %d Value as hex: %x\\n\", prevEbp, *prevEbp, *prevEbp);\n\tprintf(\"Return address: %p Value: %x\\n\", ret, *ret);\n\tprintf(\"Buffer end: %p\\n\", buffer + 16);\n\t\n\tfflush(stdout);\n\t\n}\n\nint main() {\n\tprintf(\"Ptr size: %d bytes\\n\", sizeof(void*));\n\tfun(1, 2, 3)\n\treturn 0;\n}\n\n\nWe can calculate the return address position by taking addresses of the buffer and the function arguments. In this case we only take the pointer to the first argument, because it is added to the stack last. The previous base pointer size as well as the return address size are 4 bytes, so we can just subtract 1 (4 bytes) from the pointer to get the return address and 2 (8 bytes) to get the base pointer.\n\nWe can now compile the program with the -fno-stack-protector flag to disable stack protecting canary that gcc adds by default:\n\n$ gcc main.c -o viewret -fno-stack-protector\n\n\nBy running the program I got:\n\nPtr size: 4 bytes\nBuffer start: 0061FEE8 Buffer start pointer address: 0061FEE8\nPrevious EBP: 0061FF08 Value: 6422312 Value as hex: 61ff28\nReturn address: 0061FF0C Value: 401508\nBuffer end: 0061FEF8\n\n\nWe can easly alter the return address value now:\n\nvoid __attribute__((noinline)) fun(int a, int b, int c) {\n\t\n\tchar buffer[16] = {0};\n\t\n\tint* prevEbp = &amp;a - 2;\n\tint* ret = &amp;a - 1;\n\t\n\tprintf(\"Buffer start: %p Buffer start pointer address: %p\\n\", buffer, &amp;buffer);\n\tprintf(\"Previous EBP: %p Value: %d Value as hex: %x\\n\", prevEbp, *prevEbp, *prevEbp);\n\tprintf(\"Return address: %p Value: %x\\n\", ret, *ret);\n\tprintf(\"Buffer end: %p\\n\", buffer + 16);\n\t\n\tfflush(stdout);\n\t\n\t*ret = 0xcafeefac;\n\t\n}\n\n\nNow, if we run the program we will get a segmentation fault error because the function will try to jump back to the calee using an invalid address.\n\nWe can examine exactly how it works by running the GDB debugger:\n\n$ gdb viewret.exe\n\n\nOf course, we need to set the breakpoint at the fun function:\n\n(gdb) $ br fun\n\n\n[New Thread 3388.0x3368]\n[New Thread 3388.0x1a2c]\nPtr size: 4 bytes\n\nBreakpoint 1, 0x00401416 in fun ()\n\n\nBy using the frame command we can view the saved registers if the current stack frame.\n\n(gdb) $ info frame\n\n\nStack level 0, frame at 0x61ff10:\n eip = 0x401416 in fun; saved eip 0x401508\n called by frame at 0x61ff30\n Arglist at 0x61ff08, args:\n Locals at 0x61ff08, Previous frame's sp is 0x61ff10\n Saved registers:\n  ebp at 0x61ff08, eip at 0x61ff0c\n\n\nThe ebp register of the previous stack frame is at address 0x61ff08, the return address - at 0x61ff0c. The values are the same as generated by the program above.\n\n(gdb) $ c\n\n\nContinuing.\nBuffer start: 0061FEE8 Buffer start pointer address: 0061FEE8\nPrevious EBP: 0061FF08 Value: 6422312 Value as hex: 61ff28\nReturn address: 0061FF0C Value: 401508\nBuffer end: 0061FEF8\n\nProgram received signal SIGSEGV, Segmentation fault.\n0xcafeefac in ?? ()\n\n\nBy stepping over the breakpoint we can see the invalid return address that caused the segmentation fault.\n\nAltering variables\n\nLet’s examine another program that reads data from the standart input stream:\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main() {\n\t\n\tvolatile int zero;\n\t\n\tchar buffer[64];\n\t\n\tzero = 0;\n\t\n\tgets(buffer);\n\t\n\tif (zero) {\n\t\tprintf(\"You changed the zero variable to %d (hex: %x)!\", zero, zero);\n\t}\n\telse {\n\t\tputs(\"Variable not changed.\");\n\t}\n\t\n\treturn 0;\n}\n\n\nThe zero variable is marked as volatile to prevent the compiler from optimizing it’s usage, e.g. by caching it’s value in one of the general-purpose registers.\n\nBy dissassembling with GDB we get:\n\n0x00401410 &lt;+0&gt;:     push   ebp ; save the previous ebp register\n0x00401411 &lt;+1&gt;:     mov    ebp,esp ; initializing ebp of the new stack frame\n0x00401413 &lt;+3&gt;:     and    esp,0xfffffff0 ; memory aligning\n0x00401416 &lt;+6&gt;:     sub    esp,0x60 ; memory allocation on the stack\n0x00401419 &lt;+9&gt;:     call   0x401980 &lt;__main&gt;\n0x0040141e &lt;+14&gt;:    mov    DWORD PTR [esp+0x5c],0x0 ; assign to zero\n; eax = esp + 0x1c\n0x00401426 &lt;+22&gt;:    lea    eax,[esp+0x1c]\n; the address calculated with the previous instruction gets saved on the stack\n0x0040142a &lt;+26&gt;:    mov    DWORD PTR [esp],eax\n0x0040142d &lt;+29&gt;:    call   0x403ae8 &lt;gets&gt; ; gets() call\n; load the value from the memory for comparison\n0x00401432 &lt;+34&gt;:    mov    eax,DWORD PTR [esp+0x5c]\n0x00401436 &lt;+38&gt;:    test   eax,eax ; test if it is zero\n0x00401438 &lt;+40&gt;:    je     0x401458 &lt;main+72&gt; \n0x0040143a &lt;+42&gt;:    mov    edx,DWORD PTR [esp+0x5c]\n; commands needed for printf\n0x0040143e &lt;+46&gt;:    mov    eax,DWORD PTR [esp+0x5c]\n0x00401442 &lt;+50&gt;:    mov    DWORD PTR [esp+0x8],edx\n0x00401446 &lt;+54&gt;:    mov    DWORD PTR [esp+0x4],eax\n0x0040144a &lt;+58&gt;:    mov    DWORD PTR [esp],0x405044\n0x00401451 &lt;+65&gt;:    call   0x403ac8 &lt;printf&gt; ; success print\n0x00401456 &lt;+70&gt;:    jmp    0x401464 &lt;main+84&gt; ; jump over the else branch\n0x00401458 &lt;+72&gt;:    mov    DWORD PTR [esp],0x405073\n0x0040145f &lt;+79&gt;:    call   0x403ac0 &lt;puts&gt; ; error print\n; return with exit code 0\n0x00401464 &lt;+84&gt;:    mov    eax,0x0\n0x00401469 &lt;+89&gt;:    leave\n0x0040146a &lt;+90&gt;:    ret\n0x0040146b &lt;+91&gt;:    nop\n0x0040146c &lt;+92&gt;:    xchg   ax,ax\n0x0040146e &lt;+94&gt;:    xchg   ax,ax\n\n\nWe can set 2 breakpoints - before and after the gets() call.\n\n(gdb) $ br *0x0040142d\n(gdb) $ br *0x00401432\n\n\nWith gdb we can define what commands to run when these breakpoints are reached:\n\n(gdb) $ define hook-stop\n&gt;info registers\n&gt;x/24wx $esp\n&gt;x/2i $eip\n&gt;end\n\n\nWith the commands above we will see the register state, 24 machine words on the stack and two next instuctions after the instruction pointer:\n\neax            0x61fedc 6422236\necx            0x4018f0 4200688\nedx            0x50000018       1342177304\nebx            0x2d2000 2957312\nesp            0x61fec0 0x61fec0\nebp            0x61ff28 0x61ff28\nesi            0x4012d0 4199120\nedi            0x4012d0 4199120\neip            0x40142d 0x40142d &lt;main+29&gt;\neflags         0x202    [ IF ]\ncs             0x23     35\nss             0x2b     43\nds             0x2b     43\nes             0x2b     43\nfs             0x53     83\ngs             0x2b     43\n0x61fec0:       0x0061fedc      0x00000008      0x772c8023      0x772c801a\n0x61fed0:       0xb3b6879d      0x004012d0      0x004012d0      0x00000000\n0x61fee0:       0x004018f0      0x0061fed0      0x0061ff08      0x0061ffcc\n0x61fef0:       0x772cdd70      0xc4e6dd59      0xfffffffe      0x772c801a\n0x61ff00:       0x772c810d      0x004018f0      0x0061ff50      0x0040195b\n0x61ff10:       0x004018f0      0x00000000      0x002d2000      0x00000000\n=&gt; 0x40142d &lt;main+29&gt;:  call   0x403ae8 &lt;gets&gt;\n   0x401432 &lt;main+34&gt;:  mov    eax,DWORD PTR [esp+0x5c]\n\nBreakpoint 1, 0x0040142d in main ()\n\n\nNow we can examine how the input affects the stack:\n\n(gdb) $ c\nContinuing.\n0000000000000000000000000000000000000000000\n\n\neax            0x61fedc 6422236\necx            0x772eb098       1999548568\nedx            0xa      10\nebx            0x2d2000 2957312\nesp            0x61fec0 0x61fec0\nebp            0x61ff28 0x61ff28\nesi            0x4012d0 4199120\nedi            0x4012d0 4199120\neip            0x401432 0x401432 &lt;main+34&gt;\neflags         0x216    [ PF AF IF ]\ncs             0x23     35\nss             0x2b     43\nds             0x2b     43\nes             0x2b     43\nfs             0x53     83\ngs             0x2b     43\n0x61fec0:       0x0061fedc      0x00000008      0x772c8023      0x772c801a\n0x61fed0:       0xb3b6879d      0x004012d0      0x004012d0      0x30303030\n0x61fee0:       0x30303030      0x30303030      0x30303030      0x30303030\n0x61fef0:       0x30303030      0x30303030      0x30303030      0x30303030\n0x61ff00:       0x30303030      0x00303030      0x0061ff50      0x0040195b\n0x61ff10:       0x004018f0      0x00000000      0x002d2000      0x00000000\n=&gt; 0x401432 &lt;main+34&gt;:  mov    eax,DWORD PTR [esp+0x5c]\n   0x401436 &lt;main+38&gt;:  test   eax,eax\n\nBreakpoint 2, 0x00401432 in main ()\n\n\nAs we see, 43 zero-characters (ascii code 0x30) was not enouph to get to the zero value that we want ti akter. In order to get to the value, we need 64 bytes (because the buffer size is 64). For demonstration purpuses we will use the following string as the input:\n\n000011111111111111112222222222222222333333333333333344444444444456\n\n\nThis string contains 66 characters, so the 2 last characters 5 and 6 should overwrite the 2 least significant bytes (because memory endianness is little-endian) of the variable.\n\n(gdb) $ c\nContinuing.\n000011111111111111112222222222222222333333333333333344444444444456\n\n\neax            0x61fedc 6422236\necx            0x772eb098       1999548568\nedx            0xa      10\nebx            0x3f9000 4165632\nesp            0x61fec0 0x61fec0\nebp            0x61ff28 0x61ff28\nesi            0x4012d0 4199120\nedi            0x4012d0 4199120\neip            0x401432 0x401432 &lt;main+34&gt;\neflags         0x216    [ PF AF IF ]\ncs             0x23     35\nss             0x2b     43\nds             0x2b     43\nes             0x2b     43\nfs             0x53     83\ngs             0x2b     43\n0x61fec0:       0x0061fedc      0x00000008      0x772c8023      0x772c801a\n0x61fed0:       0xe53b01b1      0x004012d0      0x004012d0      0x30303030\n0x61fee0:       0x31313131      0x31313131      0x31313131      0x31313131\n0x61fef0:       0x32323232      0x32323232      0x32323232      0x32323232\n0x61ff00:       0x33333333      0x33333333      0x33333333      0x33333333\n0x61ff10:       0x34343434      0x34343434      0x34343434      0x00003635\n=&gt; 0x401432 &lt;main+34&gt;:  mov    eax,DWORD PTR [esp+0x5c]\n   0x401436 &lt;main+38&gt;:  test   eax,eax\n\nBreakpoint 2, 0x00401432 in main ()\n\n\nBy continuing we see that the variable now contains 0x3635 or 13877 in decimal.\n\n(gdb) $ c\n\n\nContinuing.\nYou changed the zero variable to 13877 (hex: 3635)![Inferior 1 (process 4848) exited normally]\nError while running hook_stop:\nThe program has no registers now.\n\n\nIn order to alter the zero variable we need to represent the number in the little endian form and write the corresponding bytes to the 65, 66, 67 and 68 offsets in in buffer.\n\nProtection against buffer overflows\n\nCompilers and operating systems have some techniques to prevent such stack exploits. In gcc, for example, if the function allocates a buffer on the stack, an additional so-called stack canary is added. A stack canary is just a random integer generated when the function is called. Before returning the function makes sure that the canary has the same value. If the canary has been altered, the program is terminated with a fatal Stack smashing detected error.\n\nAnother technique used by operating systems is restricting code evaluation on the stack. When the stack overflow is exploited, hackers will try to overwrite the return address so that it points at the buffer location with the malicious code injected. Even if the exact address is not known, it is possible to construct a NO-OP-instruction slide in the stack buffer so that a jump at any address within this slide will lead to malicious code execution. Exact stack addresses are typically different after every program run because operating systems push environmental variables onto it.\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/call-stack-buffer-overflow/"
    },{
      "image": "../../assets/img/blog/extended-euklidian-code.jpg",
      "title": "Extended Euclidean algorithm without stack or recursion",
      "date": "2020-02-21 00:00:00 +0100",
      
      "content": "Typical implementation of the extended Euclidean algorithm on the internet will just iteratively calculate modulo until 0 is reached. However, sometimes you also need to calculate the linear combination coefficients for the greatest common divisor.\n\nExtended Euclidean algorithm\n\nThe extended Euclidean algorithm allows us not only to calculate the gcd (greatest common divisor) of 2 numbers, but gives us also a representation of the result in a form of a linear combination:\n\ngcd⁡(a,b)=u⋅a+v⋅bu,v∈Z\\gcd(a, b) = u \\cdot a + v \\cdot b \\quad u,v \\in \\mathbb{Z}gcd(a,b)=u⋅a+v⋅bu,v∈Z\n\ngcd of more than 2 numbers can always be done by iteratively calculating the gcd of 2 numbers.\n\nFor example, let’s calculate gcd⁡(14,5)\\gcd(14, 5)gcd(14,5):\n\n14=5⋅2+45=4⋅1+14=1⋅4+0\\begin{aligned}\n14 &amp;= 5 \\cdot 2 + 4 \\\\\n5 &amp;= 4 \\cdot 1 + 1 \\\\\n4 &amp;= 1 \\cdot 4 + 0\n\\end{aligned}1454​=5⋅2+4=4⋅1+1=1⋅4+0​\n\nSo the greatest common divisor of 141414 and 555 is 111.\n\nWe can find the linear combination coefficients by writing 111 in terms of 141414 and 555:\n\n1=5−4⋅1=5−(14−5⋅2)⋅1=5−14+5⋅2=3⋅5+(−1)⋅14\\begin{aligned}\n1 &amp;= 5 - 4 \\cdot 1 \\\\\n&amp;= 5 - (14 - 5 \\cdot 2) \\cdot 1 \\\\\n&amp;= 5 - 14 + 5 \\cdot 2 \\\\\n&amp;= 3 \\cdot 5 + (-1) \\cdot 14\n\\end{aligned}1​=5−4⋅1=5−(14−5⋅2)⋅1=5−14+5⋅2=3⋅5+(−1)⋅14​\n\nSo in this case u=3u = 3u=3 and v=−1v = -1v=−1:\n\ngcd⁡(14,5)=(−1)⋅14+3⋅5=1\\gcd(14, 5) = (-1) \\cdot 14 + 3 \\cdot 5 = 1gcd(14,5)=(−1)⋅14+3⋅5=1\n\nWe can calculate the linear combination coefficients by doing back substitution. But it is not so easy to implement this without recursion, because the back substitution is done when we are climbing out of the recursive calls. We will implement the algorithm recursively first.\n\nRecursive implementation\n\nThe formula\n\ngcd⁡(a,b)={b,if a=0gcd⁡(b mod a,a),otherwise\\gcd(a, b) =\n\t\\begin{cases}\n\tb, &amp; \\text{if}\\ a = 0 \\\\\n\t\\gcd(b \\bmod a, a), &amp; \\text{otherwise}\n\t\\end{cases}gcd(a,b)={b,gcd(bmoda,a),​if a=0otherwise​\n\nallows us to describe the algorithm in a functional way:\n\n\n  If a=0a = 0a=0, then the greatest common divisor is bbb. Coefficients u=0u = 0u=0 and v=0v = 0v=0.\n  Else, we make the problem simpler by calculating gcd⁡(b mod a,a)\\gcd(b \\bmod a, a)gcd(bmoda,a). We can calculate the new coefficients based on the coefficients of the simpler problem.\n\n\nSo, how can we calculate uuu and vvv so that\n\ngcd⁡(a,b)=u⋅a+v⋅b\\gcd(a, b) = u \\cdot a + v \\cdot bgcd(a,b)=u⋅a+v⋅b\n\nby knowing u′u&#x27;u′ and v′v&#x27;v′ with:\n\ngcd⁡(b mod a,a)=u′⋅(b mod a)+v′⋅a\\gcd(b \\bmod a, a) = u&#x27; \\cdot (b \\bmod a) + v&#x27; \\cdot agcd(bmoda,a)=u′⋅(bmoda)+v′⋅a\n\nIn order to do that we can write b mod ab \\bmod abmoda in terms of initial aaa and bbb:\n\ngcd⁡(b mod a,a)=u′⋅(b mod a)+v′⋅a=u′⋅(b−⌊ba⌋⋅a)+v′⋅a=u′⋅b−u′⋅⌊ba⌋⋅a+v′⋅a=(v′−u′⋅⌊ba⌋)⋅a+u′⋅b\\begin{aligned}\n\t\\gcd(b \\bmod a, a)\n    \t&amp;= u&#x27; \\cdot (b \\bmod a) + v&#x27; \\cdot a \\\\\n    \t&amp;= u&#x27; \\cdot (b - \\left\\lfloor \\frac{b}{a} \\right\\rfloor \\cdot a) + v&#x27; \\cdot a \\\\\n    \t&amp;= u&#x27; \\cdot b - u&#x27; \\cdot \\left\\lfloor \\frac{b}{a} \\right\\rfloor \\cdot a + v&#x27; \\cdot a \\\\\n    \t&amp;= (v&#x27; - u&#x27; \\cdot \\left\\lfloor \\frac{b}{a} \\right\\rfloor) \\cdot a + u&#x27; \\cdot b\n\\end{aligned}gcd(bmoda,a)​=u′⋅(bmoda)+v′⋅a=u′⋅(b−⌊ab​⌋⋅a)+v′⋅a=u′⋅b−u′⋅⌊ab​⌋⋅a+v′⋅a=(v′−u′⋅⌊ab​⌋)⋅a+u′⋅b​\n\nSo the new linear combination coefficients are:\n\nu=v′−u′⋅⌊ba⌋v=u′\\begin{aligned}\n    u &amp;= v&#x27; - u&#x27; \\cdot \\left\\lfloor \\frac{b}{a} \\right\\rfloor \\\\\n    v &amp;= u&#x27;\n\\end{aligned}uv​=v′−u′⋅⌊ab​⌋=u′​\n\nWith this formula we are now ready to implement the algorithm:\n\nclass GCD_Result: # Representation of the result\n    def __init__(self, gcd, u, v):\n        self.gcd = gcd\n        self.u = u\n        self.v = v\n\ndef extended_gcd(a, b):\n    if a == 0:\n        return GCD_Result(b, 0, 1)\n    result = extended_gcd(b % a, a)\n    u = result.u # save u'\n    result.u = result.v - (b // a) * result.u # u = v' - u' * (b // a)\n    result.v = u # v = u'\n    return result\n\n\nNon-recursive implementation\n\nThe recursion in the algorithm above cannot be easily eliminated because the function is not tail-recursive.\n\nIn order to implement the algorithm with a loop we need to define a sequence of division remainders and then update the corresponding remainers as we calculate the remainders. Formally, we can define f finite sequence rnr_nrn​:\n\nr1=ar2=brn+2=rn mod rn+1\\begin{aligned}\nr_1 &amp;= a \\\\\nr_2 &amp;= b \\\\\nr_{n+2} &amp;= r_n \\bmod r_{n+1}\n\\end{aligned}r1​r2​rn+2​​=a=b=rn​modrn+1​​\n\nIf rn+1=0r_{n+1} = 0rn+1​=0, rn+2r_{n+2}rn+2​ is not defined. We can write each rnr_nrn​ as a linear combination of uuu and vvv. Now we are interested in how uuu and vvv change as we calculate remainders. To do this formally, we will need to define two new finite sequences unu_nun​ and vnv_nvn​ which will represent the linear combination coefficients:\n\nrn=un⋅a+vn⋅br_n = u_n \\cdot a + v_n \\cdot brn​=un​⋅a+vn​⋅b\n\nBy definition, r1=ar_1  = ar1​=a and r2=br_2 = br2​=b, so we can directly write the linear combination coefficients for r1r_1r1​ and r2r_2r2​:\n\nu1=1v1=0u2=0v2=1\\begin{aligned}\n    u_1 &amp;= 1 \\\\\n    v_1 &amp;= 0 \\\\\n    u_2 &amp;= 0 \\\\\n    v_2 &amp;= 1\n\\end{aligned}u1​v1​u2​v2​​=1=0=0=1​\n\nLet qnq_nqn​ be the finite sequence of integer divisions in rnr_nrn​:\n\nrn=rn+1⋅qn+2+rn+2r_n = r_{n+1} \\cdot q_{n+2} + r_{n+2}rn​=rn+1​⋅qn+2​+rn+2​\n\nNow we can write unu_nun​ and vnv_nvn​ in terms of qnq_nqn​:\n\nrn+2=rn−rn+1⋅qn+2=un⋅a+vn⋅b−rn+1⋅qn+2=un⋅a+vn⋅b−(un+1⋅a+vn+1⋅b)⋅qn+2=un⋅a+vn⋅b−un+1⋅a⋅qn+2−vn+1⋅b⋅qn+2=(un−un+1⋅qn+2)⋅a+(vn−vn+1⋅qn+2)⋅b\\begin{aligned} \n    r_{n+2} &amp;= r_n - r_{n+1} \\cdot q_{n+2} \\\\\n    &amp;= u_n \\cdot a + v_n \\cdot b - r_{n+1} \\cdot q_{n+2} \\\\\n    &amp;= u_n \\cdot a + v_n \\cdot b - (u_{n+1} \\cdot a + v_{n+1} \\cdot b) \\cdot q_{n+2} \\\\\n    &amp;= u_n \\cdot a + v_n \\cdot b - u_{n+1} \\cdot a \\cdot q_{n+2} - v_{n+1} \\cdot b \\cdot q_{n+2} \\\\\n    &amp;= (u_n - u_{n+1} \\cdot q_{n+2}) \\cdot a + (v_n - v_{n+1} \\cdot q_{n+2}) \\cdot b\n\\end{aligned}rn+2​​=rn​−rn+1​⋅qn+2​=un​⋅a+vn​⋅b−rn+1​⋅qn+2​=un​⋅a+vn​⋅b−(un+1​⋅a+vn+1​⋅b)⋅qn+2​=un​⋅a+vn​⋅b−un+1​⋅a⋅qn+2​−vn+1​⋅b⋅qn+2​=(un​−un+1​⋅qn+2​)⋅a+(vn​−vn+1​⋅qn+2​)⋅b​\n\nTo get the formula for unu_nun​ and vnv_nvn​ we can just substitute nnn instead of n+2n + 2n+2:\n\nun=un−2−qn⋅un−1vn=vn−2−qn⋅vn−1\\begin{aligned}\n    u_n &amp;= u_{n-2} - q_n \\cdot u_{n-1} \\\\\n    v_n &amp;= v_{n-2} - q_n \\cdot v_{n-1}\n\\end{aligned}un​vn​​=un−2​−qn​⋅un−1​=vn−2​−qn​⋅vn−1​​\n\nWith this formula and the initial values of the unu_nun​ and vnv_nvn​ sequences we can now implement the extended Euclidean algorithm without recursion:\n\ndef extended_gcd(a, b):\n    if a == 0:\n        # The algorithm will work correctly without this check\n        # But it will take one iteration of the inner loop\n        return GCD_Result(b, 0, 1)\n\n    unPrev = 1\n    vnPrev = 0\n    unCur = 0\n    vnCur = 1\n\n    while b != 0:\n        # Calculate new element of the qn sequence\n        qn = a // b\n        \n        # Calculate new element of the rn sequence\n        newRemainder = a % b\n        a = b\n        b = newRemainder\n\n        # Calculate new coefficients with the formula above\n        unNew = unPrev - qn * unCur\n        vnNew = vnPrev - qn * vnCur\n\n        # Shift coefficients\n        unPrev = unCur\n        vnPrev = vnCur\n        unCur = unNew\n        vnCur = vnNew\n\n    return GCD_Result(a, unPrev, vnPrev)\n\n\nExample\n\nWe can visualize the finite sequences we defined and see how the algorithm works with a table. We will calculate gcd⁡(104,47)\\gcd(104, 47)gcd(104,47) and it’s linear combination coefficients:\n\ngcd⁡(104,47)=u⋅104+v⋅47\\gcd(104, 47) = u \\cdot 104 + v \\cdot 47gcd(104,47)=u⋅104+v⋅47\n\n\n  \n    \n      rnr_nrn​\n      qnq_nqn​\n      unu_nun​\n      vnv_nvn​\n    \n  \n  \n    \n      104\n      -\n      1\n      0\n    \n    \n      47\n      -\n      0\n      1\n    \n    \n      10\n      2\n      1\n      -2\n    \n    \n      7\n      4\n      -4\n      9\n    \n    \n      3\n      1\n      5\n      -11\n    \n    \n      1\n      2\n      -14\n      31\n    \n    \n      0\n      3\n      33\n      20\n    \n  \n\n\nAt each step we first calculate the next element from the qnq_nqn​ sequence and then use it to calculate new linear combination coefficients unu_nun​ and vnv_nvn​.\n\nThe result of the algorithm:\n\ngcd⁡(104,47)=−14⋅104+31⋅47=1\\gcd(104, 47) = -14 \\cdot 104 + 31 \\cdot 47 = 1gcd(104,47)=−14⋅104+31⋅47=1\n\nImprovement of the non-recusive solution\n\nAs we see in the example above, we don’t need to calculate the last row of the table because we aren’t interested in the linear combination that forms zero. We can terminate the algorithm directly after calculating the new element of the rnr_nrn​ sequence:\n\ndef extended_gcd(a, b):\n    if a == 0: # Optional check\n        return GCD_Result(b, 0, 1)\n\n    if b == 0: # Without this check the first iteration will divide by zero\n        return GCD_Result(a, 1, 0)\n\n    unPrev = 1\n    vnPrev = 0\n    unCur = 0\n    vnCur = 1\n\n    while True:\n        qn = a // b\n        newR = a % b\n        a = b\n        b = newR\n\n        if b == 0:\n            return GCD_Result(a, unCur, vnCur)\n\n        # Update coefficients\n        unNew = unPrev - qn * unCur\n        vnNew = vnPrev - qn * vnCur\n\n        # Shift coefficients\n        unPrev = unCur\n        vnPrev = vnCur\n        unCur = unNew\n        vnCur = vnNew\n\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/non-recursive-extended-euklidian-algorithm/"
    },{
      "image": "../../assets/img/blog/dfa-radix2-modulo4.svg",
      "title": "Numbers in congruence classes are regular languages",
      "date": "2020-08-29 00:00:00 +0200",
      
      "content": "In this post we will consider natural Radix-b numbers in positional number systems. The congruence class of any such arbitrary natural number can be determined by a finite automata, and thus, intuitively speaking, the language of all Radix-b numbers that satisfy some fixed properties modulo b is regular.\n\nRadix-b numbers divisible by m\n\nThe key idea behind the automation construction is that after reading a digit, the new congruence class depends only on the current read digit and on the previous congruence class. There are only m&lt;∞m &lt; \\inftym&lt;∞ congruence classes so we can construct a finite automata that accepts all numbers divisible by m:\n\nA=(Z,Σ,δ,z0,E)Z:={0,…,m−1}Σ:={0,…,b−1}E:={0}z0:=0δ(r,d):=r⋅b+d mod m\\begin{aligned}\nA &amp;= (Z,\\Sigma,\\delta, z_0, E) \\\\\nZ &amp;:= \\{0,\\dots, m-1\\} \\\\\n\\Sigma &amp;:= \\{0,\\dots, b-1\\} \\\\\nE &amp;:= \\{0\\} \\\\\nz_0 &amp;:= 0 \\\\\n\\delta(r,d) &amp;:= r \\cdot b + d \\bmod{m}\n\\end{aligned}AZΣEz0​δ(r,d)​=(Z,Σ,δ,z0​,E):={0,…,m−1}:={0,…,b−1}:={0}:=0:=r⋅b+dmodm​\n\nThe correctness of the transition function can be seen as follows: when the automation is in state rrr, the number that has been read is in the congruence class rrr modulo mmm. So we can write it as mk+rmk+rmk+r. By multiplying with bbb (i.e. shift the number by 1 digit to the left) and adding ddd we get the new congruence class:\n\nδ(r,d)=(mk+r)⋅b+d mod m=mkb+rb+d mod m=rb+d mod m\\begin{aligned}\n\\delta(r,d) &amp;= (mk + r)\\cdot b + d \\bmod{m} \\\\\n&amp;= mkb + rb + d \\bmod{m} \\\\\n&amp;= rb + d \\bmod{m}\n\\end{aligned}δ(r,d)​=(mk+r)⋅b+dmodm=mkb+rb+dmodm=rb+dmodm​\n\nOf course, by altering the set of final states EEE we can accept not only multiples of mmm, but any such number nnn with n mod m∈En \\bmod{m} \\in Enmodm∈E for any E⊆ZE \\subseteq ZE⊆Z.\n\nBinary numbers modulo 4\n\nFor example, we can construct a finite automation that accepts all binary (b=2b = 2b=2) numbers divisible by 4 (m=4m = 4m=4):\n\n\n\nThe transitions are obtained as follows:\n\n0⋅2 mod 4=0  ⟹  δ(0,0)=0,δ(0,1)=11⋅2 mod 4=2  ⟹  δ(1,0)=2,δ(1,1)=32⋅2 mod 4=0  ⟹  δ(2,0)=0,δ(2,1)=13⋅2 mod 4=2  ⟹  δ(3,0)=2,δ(3,1)=3\\begin{aligned}\n0 \\cdot 2 \\bmod{4} = 0 &amp;\\implies \\delta(0, 0) = 0, \\delta(0, 1) = 1 \\\\\n1 \\cdot 2 \\bmod{4} = 2 &amp;\\implies \\delta(1, 0) = 2, \\delta(1, 1) = 3 \\\\\n2 \\cdot 2 \\bmod{4} = 0 &amp;\\implies \\delta(2, 0) = 0, \\delta(2, 1) = 1 \\\\\n3 \\cdot 2 \\bmod{4} = 2 &amp;\\implies \\delta(3, 0) = 2, \\delta(3, 1) = 3\n\\end{aligned}0⋅2mod4=01⋅2mod4=22⋅2mod4=03⋅2mod4=2​⟹δ(0,0)=0,δ(0,1)=1⟹δ(1,0)=2,δ(1,1)=3⟹δ(2,0)=0,δ(2,1)=1⟹δ(3,0)=2,δ(3,1)=3​\n\nIn this particular case the constructed automation is not minimal. States s1 and s3 are equivalent (this can be formally proven with the Myhill-Nerode theorem) and can be replaced by one state:\n\n\n\nAs languages accepted by DFA’s are exactly the regular languages, we can transform any DFA in a regular expression to see the exact structure of numbers divisible, for example, by 4. Unfortunately such regular expressions are very long when constructed with the Kleene or with the Arden method by a computer. These regular expressions must be massively simplified in order to be readable. With the Kleene construction I’ve implemented in this project we get the following regular expression:\n\nε|0|(ε|0)0*(ε|0)|(1|(ε|0)0*1)(1|0*1)*0*(ε|0)|(1|(ε|0)0*1)(1|0*1)*0((1|00*1)(1|0*1)*0)*(0|00*(ε|0)|(1|00*1)(1|0*1)*0*(ε|0))\n\n\nIt can be simplified by computer heuristics down to:\n\nε|0|1(1|01)*00|(0|ε|1(1|01)*00)(0|1(1|01)*00)*(0|ε|1(1|01)*00)\n\n\nStill, the regular expression is not so readable. By transforming it further by hand, we can prove that it is equivalent to:\n\nε|0|1(1|01)*00|(0|ε|1(1|01)*00)(0|1(1|01)*00)*(0|ε|1(1|01)*00) =\nε|0|1(1|01)*00|(ε|0|1(1|01)*00)(0|1(1|01)*00)*(ε|0|1(1|01)*00) =\nε|0|1(1|01)*00|(0|1(1|01)*00)*(ε|0|1(1|01)*00) =\nε|0|1(1|01)*00|(0|1(1|01)*00)* =\nε|0|(0|1(1|01)*00)* =\nε|0|(0|1(1|0)*00)* =\nε|0|0*(1(1|0)*000*)* =\nε|0|0*(1(1|0)*0*00)* =\nε|0|0*(1(1|0)*00)* =\nε|0|0*(1(0|1)*00)* =\nε|0|0*(1(0|1)*00|ε) =\nε|0|0*|0*1(0|1)*00 =\nε|0|0*|0*(0|1)*00 =\nε|0|0*(0|1)*00 =\nε|0|(0|1)*00\n\n\nSo, any binary number divisible by 4 must be zero or end with 00.\n\nOther examples\n\nDecimal numbers divisible by 20\n\n\n\nDecimal numbers divisible by 75\n\n\n\nHexadecimal numbers divisible by 24\n\n\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/numbers-are-regular-languages/"
    },{
      "image": "../../assets/img/blog/dfa-radix10-modulo75-min.svg",
      "title": "Efficient compression of congruence class automations",
      "date": "2020-09-01 00:00:00 +0200",
      
      "content": "As already discussed in the previous post, any radix-b number nnn with n mod m∈E⊆Zn \\bmod{m} \\in E \\subseteq Znmodm∈E⊆Z can be accepted by finite automata in a digit-by-digit manner. However, the construction is not always optimal. The amount of states required is not always the amount of congruence classes. In this post we will examine when exactly the finite automata can be simplified by combining states. Reducing the amount of states will also help produce a much simpler regular expression, for example, with the Kleene construction.\n\nGeneral way to optimize an automation\n\nOf course, we can optimize the DFA with the well-known algorithm based on the Myhill-Nerode theorem. Unfortunately, even an optimized implementation is not efficient enough to do the optimization for large mmm and bbb, because the complexity of the algorithm expressed in these terms is O(b⋅m2)O(b \\cdot m^2)O(b⋅m2), as the algorithm needs to iterate over all m2m^2m2 pairs of states and consider all the outgoing transitions (bbb in each state). With this tool we can run the algorithm and get the following results for b=10b = 10b=10 and 1≤m≤201 \\le m \\le 201≤m≤20:\n\nm= 1 |Z|= 1  Z = [[0]]\nm= 2 |Z|= 2  Z = [[0], [1]]\nm= 3 |Z|= 3  Z = [[0], [1], [2]]\nm= 4 |Z|= 3  Z = [[0], [3, 1], [2]]\nm= 5 |Z|= 2  Z = [[0], [2, 1, 3, 4]]\nm= 6 |Z|= 4  Z = [[0], [4, 1], [5, 2], [3]]\nm= 7 |Z|= 7  Z = [[0], [1], [2], [3], [4], [5], [6]]\nm= 8 |Z|= 5  Z = [[0], [5, 1], [6, 2], [7, 3], [4]]\nm= 9 |Z|= 9  Z = [[0], [1], [2], [3], [4], [5], [6], [7], [8]]\nm=10 |Z|= 2  Z = [[0], [5, 4, 3, 2, 7, 6, 9, 8, 1]]\nm=11 |Z|=11  Z = [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\nm=12 |Z|= 7  Z = [[0], [7, 1], [8, 2], [9, 3], [10, 4], [11, 5], [6]]\nm=13 |Z|=13  Z = [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12]]\nm=14 |Z|= 8  Z = [[0], [8, 1], [9, 2], [10, 3], [11, 4], [12, 5], [13, 6], [7]]\nm=15 |Z|= 4  Z = [[0], [13, 10, 7, 4, 1], [5, 2, 8, 11, 14], [9, 6, 12, 3]]\nm=16 |Z|= 9  Z = [[0], [9, 1], [10, 2], [11, 3], [12, 4], [13, 5], [14, 6], [15, 7], [8]]\nm=17 |Z|=17  Z = [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16]]\nm=18 |Z|=10  Z = [[0], [10, 1], [11, 2], [12, 3], [13, 4], [14, 5], [15, 6], [16, 7], [17, 8], [9]]\nm=19 |Z|=19  Z = [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18]]\nm=20 |Z|= 3  Z = [[0], [13, 11, 15, 17, 5, 3, 7, 9, 19, 1], [12, 10, 14, 16, 4, 2, 6, 8, 18]]\n\n\nHere, ZZZ is the set of states in the new, minimal DFA. ZZZ is a set of equivalence classes that represent which states can be combined into one state. These equivalence classes have been computed for E:={0}E := \\{0\\}E:={0}. That is why, for example, for m=8m = 8m=8 states 0 and 4 aren’t in one equivalence class. They can’t be equivalent, because state 4 is intermediate while state 0 is final.\n\nComputing equivalence classes ahead-of-time\n\nAs you can see, there is clearly a pattern in the equivalence states above. For example, we can see that no states are equivalent when mmm is prime. By further examining the data above we can even conclude that the DFA probably can’t be simplified if gcd⁡(b,m)=1\\gcd(b, m) = 1gcd(b,m)=1 i.e. if bbb and mmm are coprime.\n\nAfter formally examining when the states can be combined I came up with the following result:\n\nTheorem\n\nIf m≤bm \\le bm≤b and E≠∅E \\neq \\varnothingE​=∅, then the minimum finite automation can be constructed as follows:\n\nZ=⋃A∈Z′⋅{A∩E,A\\E}\\{∅}Z = \\overset{\\cdot}{\\bigcup_{A\\in Z&#x27;}} \\{A \\cap E, A \\backslash E\\}\\backslash\\{\\varnothing\\}Z=A∈Z′⋃​⋅​{A∩E,A&lt;/span&gt;E}&lt;/span&gt;{∅}\n\nwhere Z′Z&#x27;Z′ is the set of equivalence classes of the following equivalence relation:\n\nx∼y⇔x≡ymod  mgcd⁡(b,m)x \\sim y \\Leftrightarrow x \\equiv y \\mod{\\frac{m}{\\gcd(b, m)}}x∼y⇔x≡ymodgcd(b,m)m​\n\nProof\n\nBy definition of δ\\deltaδ, we know that:\n\nδ(r,d)=k  ⟹  δ(r,d+1 mod b)=k+1 mod m\\delta(r, d) = k \\implies \\delta(r, d + 1 \\bmod b) = k + 1 \\bmod mδ(r,d)=k⟹δ(r,d+1modb)=k+1modm\n\nBecause m≤bm \\le bm≤b, it follows that the mapping δ(x,Σ)\\delta(x, \\Sigma)δ(x,Σ) is surjective. In other words, m≤bm \\le bm≤b implies that every state has at least one transition to any other state. Any change to this mapping will shift it. As E≠∅E \\neq \\varnothingE​=∅, any shifted mapping δ′\\delta&#x27;δ′ will lead to at least 1 digit ddd such that δ(x,d)∈E\\delta(x, d) \\in Eδ(x,d)∈E and δ′(x,d)∉E\\delta&#x27;(x, d) \\notin Eδ′(x,d)∈/​E.\n\nThus, 2 states x,y∈Zx,y \\in Zx,y∈Z are equivalent if and only if they have equivalent mappings which is equivalent to:\n\nδ(x,Σ)=δ(y,Σ)⇔δ(x,d)=δ(y,d)∀d∈Σ⇔xb+d mod m=yb+d mod m⇔xb+d≡yb+dmod  m⇔xb≡ybmod  m⇔xb−yb≡0mod  m⇔(x−y)⋅b≡0mod  m⇔x−y≡0mod  mgcd⁡(b,m)⇔x≡ymod  mgcd⁡(b,m)\\begin{aligned}\n\\delta(x, \\Sigma) = \\delta(y, \\Sigma) &amp;\\Leftrightarrow \\delta(x, d) = \\delta(y, d) \\quad \\forall d \\in \\Sigma \\\\\n&amp;\\Leftrightarrow xb + d \\bmod m = yb + d \\bmod m \\\\\n&amp;\\Leftrightarrow xb + d \\equiv yb + d \\mod{m} \\\\\n&amp;\\Leftrightarrow xb \\equiv yb \\mod{m} \\\\\n&amp;\\Leftrightarrow xb - yb \\equiv 0 \\mod{m} \\\\\n&amp;\\Leftrightarrow (x-y) \\cdot b \\equiv 0 \\mod{m} \\\\\n&amp;\\Leftrightarrow x-y \\equiv 0 \\mod{\\frac{m}{\\gcd(b, m)}} \\\\\n&amp;\\Leftrightarrow x \\equiv y \\mod{\\frac{m}{\\gcd(b, m)}}\n\\end{aligned}δ(x,Σ)=δ(y,Σ)​⇔δ(x,d)=δ(y,d)∀d∈Σ⇔xb+dmodm=yb+dmodm⇔xb+d≡yb+dmodm⇔xb≡ybmodm⇔xb−yb≡0modm⇔(x−y)⋅b≡0modm⇔x−y≡0modgcd(b,m)m​⇔x≡ymodgcd(b,m)m​​\n\nFirst corollary\n\nIt follows, that if m≤bm \\le bm≤b, E≠∅E \\neq \\varnothingE​=∅ and gcd⁡(b,m)=1\\gcd(b, m) = 1gcd(b,m)=1, then no states can be combined and the minimal automation has mmm states.\n\nSecond corollary\n\nIf m≤bm \\le bm≤b and E≠∅E \\neq \\varnothingE​=∅, then the amount of states Z′Z&#x27;Z′ (before splitting each equivalence class in final states and non final ones as shown in the theorem) is equal to the following set of orbits:\n\nZ′=(Z/m)/⟨m/gcd⁡(b,m)‾⟩Z&#x27; = (\\mathbb{Z}/m)/\\langle \\overline{m / \\gcd(b, m)} \\rangleZ′=(Z/m)/⟨m/gcd(b,m)​⟩\n\nExample implementation\n\nThis Java method uses the results above to compute the equivalence classes efficiently:\n\npublic static List&lt;List&lt;Integer&gt;&gt; computeEquivalenceClasses(int b, int m, HashSet&lt;Integer&gt; finalStates) {\n    assert m &lt;= b;\n    assert !finalStates.isEmpty();\n\n    // Union-Find datastructure, preferrably with union-by-rank and path compression\n    UnionFind equivalenceClasses = new UnionFind(m);\n\n    int bmgcd = Euklidian.gcd(b, m);\n\n    if (bmgcd == 1) {\n        return equivalenceClasses.getDisjointSets();\n    }\n\n    int optimizedM = m / bmgcd;\n\n    // loop through every set in the new set of equivalence classes\n    for (int anchor = 0; anchor &lt; optimizedM; anchor++) {\n\n        int current = anchor; // [anchor] is the equivalence class\n        // oppositeAnchor is the element that is final if anchor is intermediate\n        // and intermediate if anchor is final\n        // if oppositeAnchor == anchor, then it is considered as not yet found\n        int oppositeAnchor = anchor;\n\n        boolean anchorFinal = finalStates.contains(anchor);\n\n        for (;;) {\n            current = (current + optimizedM) % m;\n\n            if (current == anchor) {\n                break;\n            }\n\n            boolean currentFinal = finalStates.contains(current);\n\n            if (currentFinal == anchorFinal) {\n                equivalenceClasses.union(current, anchor);\n            }\n            else if (oppositeAnchor == anchor) {\n                // \"initialize\" oppositeAnchor\n                oppositeAnchor = current;\n            }\n            else {\n                equivalenceClasses.union(current, oppositeAnchor);\n            }\n        }\n\n    }\n\n    return equivalenceClasses.getDisjointSets();\n}\n\n\nIf we use a union-find datastructure with union in O(1)O(1)O(1) (e.g. union-by-rank with path compression), then the complexity of the algorithm is O(m)O(m)O(m) which is much better than O(b⋅m2)O(b \\cdot m^2)O(b⋅m2).\n\nCase when m &gt; b\n\nIn case m&gt;bm &gt; bm&gt;b the equivalence relation depends very much on the set of final states EEE. With the Myhill Nerode theorem we get:\n\nx∼y⇔(xc∈L⇔yc∈L∀c∈Σ∗)⇔(x⋅b∣c∣+c mod m∈E⇔y⋅b∣c∣+c mod m∈E)\\begin{aligned}\nx \\sim y &amp;\\Leftrightarrow (xc \\in L \\Leftrightarrow yc \\in L \\quad \\forall c \\in \\Sigma^*) \\\\\n&amp;\\Leftrightarrow (x \\cdot b^{|c|} + c \\bmod m \\in E \\Leftrightarrow y \\cdot b^{|c|} + c \\bmod m \\in E)\n\\end{aligned}x∼y​⇔(xc∈L⇔yc∈L∀c∈Σ∗)⇔(x⋅b∣c∣+cmodm∈E⇔y⋅b∣c∣+cmodm∈E)​\n\nConclusion\n\nWith the above theorem it is easy to implement a much faster algorithm that computes equivalent states. It also gives an intuition, why for example it is harder to test whether a decimal number is divisible by 9 than to test whether a decimal number is divisible by 5, if we measure “hardness” by the amount of states in the minimal DFA. It is the case because gcd⁡(5,10)=5\\gcd(5, 10) = 5gcd(5,10)=5 and gcd⁡(9,10)=1\\gcd(9, 10) = 1gcd(9,10)=1.\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/compressing-congruence-automata/"
    },{
      "image": "../../assets/img/blog/kadane-example.svg",
      "title": "Kadane's algorithm and the idea behind it",
      "date": "2020-09-19 00:00:00 +0200",
      
      "content": "People often refer to Kadane’s algorithm only in the context of the maximum subarray problem. However, the idea behind this algorithm allows one to use it for solving a variety of problems that have something to do with finding a continuous subarray with a given property. The algorithm can also be used in 2d or multidimensional arrays but in this post we will only consider regular one-dimensional arrays.\n\nMotivation &amp; idea\n\nIf we are searching for a subarray with some property, the easiest solution would be to try all possible intervals. A naive algorithm can do that in O(n3)O(n^3)O(n3) time, but we can improve that by computing solutions for intervals of increasing length and reusing already computed solutions (aka dynamic programming). In this case the complexity of the algorithm is O(n2)O(n^2)O(n2). Of course, this will work not for all problems. It will work, for example, for the computation of any binary associative operation for all intervals in the array. Another example for such an algorithm would be finding all palindromes in a given string:\n\n\n  Mark all letters as palindromes of length 1\n  Mark all adjacent equal letters as palindromes of length 2\n  For every fixed length kkk, starting with k=3k = 3k=3 traverse all substrings of length kkk in the string and mark the current substring as a palindrome if the letters at the start and at the end match and if the middle part is a palindrome.\n\n\nO(n2)O(n^2)O(n2) is the optimal worst-case complexity if the problem cannot be solved without traversing the entire search space. For example, this is the case for the problem of computing all palindromes of a given string (a worst-case example is an∈Σ∗a^n \\in \\Sigma^*an∈Σ∗ where the amount of palindromes is ∑i=1ni=n⋅(n+1)2∈Ω(n2)\\sum_{i=1}^{n}i =\\frac{n \\cdot (n + 1)}{2} \\in \\Omega(n^2)∑i=1n​i=2n⋅(n+1)​∈Ω(n2)).\n\nThe key question is: How can we traverse only some subset of the search space and still benefit from dynamic programming?\n\nWell, we can identify a problem with only one side of the interval in the array. We will choose the right side of the interval because that is what is commonly used in real algorithms. That way it is possible to construct a linear time algorithm the following way:\n\n\n  Create a recursive function f(k)f(k)f(k) that computes the trivial solution if k=1k = 1k=1 and computes the new solution based on the already computed result, e.g. f(k−1)f(k-1)f(k−1).\n  Find the best solution among {f(k):0≤k&lt;n}\\{f(k) : 0 \\le k &lt; n\\}{f(k):0≤k&lt;n}.\n\n\nBoth parts take linear (O(n)O(n)O(n)) time if we cache and reuse the result of f(k)f(k)f(k) or if we use dynamic programming which is better most of the times.\n\nMaximum sum subarray\n\nA good example for a construction of such an algorithm is the maximum sum subarray problem - given an array AAA of integers the algorithm should find such indices a,b∈{1,…,n−1}a,b \\in \\{1, \\dots, n-1\\}a,b∈{1,…,n−1} with a≤ba \\le ba≤b such that ∑i=abA[i]\\sum_{i=a}^b {A[i]}∑i=ab​A[i] is maximal.\n\nWe can define the problem only in terms of the right border kkk - “what is the maximum subarray ending at kkk”?\n\nClearly, the maximum subarray of the whole array is the maximum of subarrays ending at kkk for all 0≤k&lt;n0 \\le k &lt; n0≤k&lt;n. Also, the maximum sum subarray ending at k is either A[k]A[k]A[k] itself or the maximum sum subarray ending at k−1k - 1k−1 combined with A[k]A[k]A[k]. So we can now write the algorithm formally with pseudocode:\n\nmaxSumSubarrayEndingAt(A, k) {\n    if (k == 0) {\n        return (A[0], 1);\n    }\n    (sum, left) = maxSumSubarrayEndingAt(k - 1);\n    if (sum &gt;= 0) { /* sum + A[k] &gt;= A[k] */\n        /* the max subarray (ending at k) is the previous subarray together with this element */\n        return (sum + A[k], left);\n    }\n    else {\n        /* the max subarray (ending at k) is the current element */\n        return (A[k], k);\n    }\n}\n\n\nAnd the maximum subarray sum and indices can be computed with a simple maximim-search algorithm:\n\nmaxSumSubarray(A) {\n    n = size(A);\n    maxSum = A[0];\n    maxLeft = 0;\n    maxRight = 0;\n    for (r = 1; r &lt; n; r++) {\n        (s, l) = maxSumSubarrayEndingAt(A, r);\n        if (s &gt; maxSum) {\n            maxSum = s;\n            maxLeft = l;\n            maxRight = r;\n        }\n    }\n    return (maxSum, maxLeft, maxRight);\n}\n\n\nThis intermediate pseudocode solution doesn’t cache maxSumSubarrayEndingAt results and is therefore inefficient “as-is”. But we can remove recursion and rewrite the same solution with dynamic programming (Java):\n\npublic static void maxSumSubarray(int[] a) {\n    int maxSum = a[0];\n    int maxLeft = 0;\n    int maxRight = 0;\n\n    int currentSum = a[0];\n    int currentLeft = 0;\n\n    for (int r = 1; r &lt; a.length; r++) {\n\n        if (currentSum &gt;= 0) {\n            currentSum += a[r];\n        }\n        else {\n            currentSum = a[r];\n            currentLeft = r;\n        }\n\n        if (currentSum &gt; maxSum) {\n            maxSum = currentSum;\n            maxLeft = currentLeft;\n            maxRight = r;\n        }\n    }\n\n    // the sum between A[maxLeft] and A[maxRight] (inclusive) is equal maxSum and maximal\n    System.out.printf(\"Max sum: %5d Indices from %5d to %5d.\\n\", maxSum, maxLeft, maxRight);\n}\n\n\nThis is the efficient Θ(n)\\Theta(n)Θ(n) time and Θ(1)\\Theta(1)Θ(1) space solution that uses the idea of Kadane’s algorithm to compute the maximum sum subarray.\n\nExample\n\nConsider the array {-2, 1, -3, 4, -1, 2, 1, -5, -2, 5}. By running the algorithm we get the following maximum subarrays ending at a specific index:\n\n\n\nThe maximum subarray is marked red.\n\nOther problems that can be solved analogously\n\n\n  Smallest sum subarray problem\n  Largest product subarray problem\n  Smallest product subarray problem\n  Maximum circular sum\n\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/kadane-algorithm/"
    },{
      "image": "../../assets/img/blog/bt-full-15-node-0.svg",
      "title": "Computing the lowest common ancestor in a full binary tree",
      "date": "2020-09-23 00:00:00 +0200",
      
      "content": "The lowest common ancestor (LCA) problem is important in many applications of binary trees. For example, by knowing the lowest common ancestor we can easily compute the shortest path between any two vertices in a tree. The most common way to compute the lca of vertices uuu and vvv is to iteratively go up until we get to the root of the subtree containing both uuu and vvv. This method works only if uuu and vvv are on the same level. If not, we can first measure the difference of heights ddd between uuu and vvv and then find the lowest common ancestor of the ddd-th parent of the lowest vertex and the higher vertex.\n\nLCA in a full binary tree\n\nFull binary trees are often represented implicitly in memory. That means, parent-child relations are determined by looking at the positions of nodes in the array. For example, in this tree the nodes are numbered the way they will be positioned in the array:\n\n\n\nIn a full binary tree the parent of node xxx is p(x):=⌊x−12⌋p(x):=\\left\\lfloor\\frac{x-1}{2}\\right\\rfloorp(x):=⌊2x−1​⌋, and children are 2⋅x+12 \\cdot x + 12⋅x+1 and 2⋅x+22 \\cdot x + 22⋅x+2. Formally speaking, for nodes aaa and bbb on the same level we would like to find the value of pn(a)p^n(a)pn(a) such that pn(a)=pn(b)p^n(a) = p^n(b)pn(a)=pn(b) for n minimal. In binary representation, dividing by 2 and discarding the remainder is equivalent to shifting the number by 1 bit to the right. In order to use this we can just add 1 to each node index:\n\n\n\nWith this change we can implement the lca algorithm:\n\nuint32_t lca_sameLevel(uint32_t a, uint32_t b) {\n    while (a != b) {\n        a &gt;&gt;= 1u;\n        b &gt;&gt;= 1u;\n    }\n    return a;\n}\n\n\nThis algorithm works because the lowest common ancestor is the longest common prefix of the binary representation of both nodes.\n\nIf we address nodes starting with one, then any nodewith level lll will be greater than or equal to 2l2^l2l. Therefore, the amount of leading zeroes in the binary representation of nodes in the same level is equal. Moreover, the difference of amounts of leading zeroes is equal to the difference of levels. With this idea we can now implement the algorithm that correctly finds the lowest common ancestor for any pair of nodes.\n\nuint32_t lca(uint32_t a, uint32_t b) {\n    \n    uint32_t aLeadingZeroes = __builtin_clz(a);\n    uint32_t bLeadingZeroes = __builtin_clz(b);\n    \n    while (aLeadingZeroes &gt; bLeadingZeroes) {\n        b &gt;&gt;= 1u;\n        bLeadingZeroes++;\n    }\n    \n    while (bLeadingZeroes &gt; aLeadingZeroes) {\n        a &gt;&gt;= 1u;\n        aLeadingZeroes++;\n    }\n    \n    while (a != b) {\n        a &gt;&gt;= 1u;\n        b &gt;&gt;= 1u;\n    }\n    \n    return a;\n}\n\n\nIt is also easy to modify the algorithm slightly so that it works for elements indexed starting from zero.\n\n#include &lt;stdint.h&gt;\n\nuint32_t lca(uint32_t a, uint32_t b) {\n    a++;\n    b++;\n    \n    uint32_t aLeadingZeroes = __builtin_clz(a);\n    uint32_t bLeadingZeroes = __builtin_clz(b);\n    \n    while (aLeadingZeroes &gt; bLeadingZeroes) {\n        b &gt;&gt;= 1u;\n        bLeadingZeroes++;\n    }\n    \n    while (bLeadingZeroes &gt; aLeadingZeroes) {\n        a &gt;&gt;= 1u;\n        aLeadingZeroes++;\n    }\n    \n    while (a != b) {\n        a &gt;&gt;= 1u;\n        b &gt;&gt;= 1u;\n    }\n    \n    return a - 1u;\n}\n\n\nComplexity: O(log⁡(n))O(\\log(n))O(log(n)) where nnn is the amount if nodes in the tree.\n\nExample\n\nIf the we want to find the lowest common ancestor of 8 and 10 (indexed from zero), then we add 1 to both of them and find the longest common prefix. In this case it is the longest common prefix of 1001 and 1011 which is 10 = 2 in decimal. 2 is the lowest common ancestor in the tree with increased indices, so in the original tree the lowest common ancestor is 2 - 1 = 1.\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/lowest-common-ancestor/"
    },{
      "image": "../../assets/img/blog/4d-boolean-cube-cnf.svg",
      "title": "Measuring the size of a regular language is NP-Hard",
      "date": "2020-10-15 00:00:00 +0200",
      
      "content": "In this post we will examine an interesting connection between the NP\\mathcal{NP}NP-complete CNF-SAT problem and the problem of computing the amount of words generated by some efficient representation of a formal language. Here, I call a way of representing a formal language efficient, if it has a polynomially-long encoding but can possibly describe an exponentially-large formal language. Examples of such efficient representations are nondeteministic finite automations and regular expressions.\n\nFormal definition of the problem\n\nWe can formally define the problem of determining the language size the following way:\n\nName: NFA Language Size\n\nInput: A nondeterministic finite automata (NFA) M:=(Z,Σ,δ,S,E)M := (Z, \\Sigma, \\delta, S, E)M:=(Z,Σ,δ,S,E) and a number m∈Nm \\in \\mathbb{N}m∈N.\n\nQuestion: Is ∣L(M)∣≤m\\st L(M) \\st \\le m∣L(M)∣≤m?\n\nProof of NP-hardness\n\nWe will construct a reduction from the NP\\mathcal{NP}NP-complete CNF-SAT problem. Consider a formula φ\\varphiφ with kkk clauses and nnn variables:\n\n\n  Create an NFA M:=(Z,Σ,δ,S,E)M := (Z, \\Sigma, \\delta, S, E)M:=(Z,Σ,δ,S,E) with the alphabet Σ:={0,1}\\Sigma := \\{0, 1\\}Σ:={0,1}.\n  For every variable 0≤v≤n0 \\le v \\le n0≤v≤n and clause 1≤c≤k1 \\le c \\le k1≤c≤k create a state z(v,c)∈Zz(v, c) \\in Zz(v,c)∈Z. Intuitively, if the NFA is in the state z(v,c)z(v, c)z(v,c), it means that it has already read vvv symbols of some variable assignment where clause ccc is zero.\n  For each clause 1≤c≤k1 \\le c \\le k1≤c≤k of the formula, construct a boolean cube ψ:V→{0,1,∗}\\psi : V \\to \\{0, 1, *\\}ψ:V→{0,1,∗} with ψ−1(1)\\psi^{-1}(1)ψ−1(1) containing variables that are negated in the clause and ψ−1(0)\\psi^{-1}(0)ψ−1(0) containing positive variables (other variables are mapped to ∗*∗). By doing this, we essentially construct a cube C(ψ):=(⋀ψ(x)=1x)∧(⋀ψ(x)=0xˉ)C(\\psi) := (\\bigwedge_{\\psi(x) = 1}{x}) \\wedge (\\bigwedge_{\\psi(x) = 0}{\\bar{x}})C(ψ):=(⋀ψ(x)=1​x)∧(⋀ψ(x)=0​xˉ) that is the negation of the clause. In other words, all full variable assignments ψ′:V→{0,1}\\psi&#x27; : V \\to \\{0, 1\\}ψ′:V→{0,1} such that ψ(x)≠∗⇒ψ′(x)=ψ(x)∀x∈V\\psi(x) \\neq * \\Rightarrow \\psi&#x27;(x) = \\psi(x) \\quad\\forall x \\in Vψ(x)​=∗⇒ψ′(x)=ψ(x)∀x∈V will make the clause (and the whole formula φ\\varphiφ) false. For all 0≤v&lt;n0 \\le v &lt; n0≤v&lt;n create the following transitions:\n    \n      Set δ(z(v,c),0):={z(v+1,c)}\\delta(z(v,c), 0) := \\{z(v + 1,c)\\}δ(z(v,c),0):={z(v+1,c)} if ψ(v+1)=0\\psi(v + 1) = 0ψ(v+1)=0.\n      Set δ(z(v,c),1):={z(v+1,c)}\\delta(z(v,c), 1) := \\{z(v + 1,c)\\}δ(z(v,c),1):={z(v+1,c)} if ψ(v+1)=1\\psi(v + 1) = 1ψ(v+1)=1.\n      Set δ(z(v,c),0):={z(v+1,c)}\\delta(z(v,c), 0) := \\{z(v + 1,c)\\}δ(z(v,c),0):={z(v+1,c)} and δ(z(v,c),1):={z(v+1,c)}\\delta(z(v,c), 1) := \\{z(v + 1,c)\\}δ(z(v,c),1):={z(v+1,c)} if ψ(v+1)=∗\\psi(v + 1) = *ψ(v+1)=∗.\n    \n  \n  Mark all states with v=0v = 0v=0 as initial: S:={z(0,c):1≤c≤k}S := \\{z(0, c) : 1 \\le c \\le k\\}S:={z(0,c):1≤c≤k}.\n  Mark all states with v=nv = nv=n as final: E:={z(n,c):1≤c≤k}E := \\{z(n, c) : 1 \\le c \\le k\\}E:={z(n,c):1≤c≤k}.\n\n\nBy construction, MMM will accept any variable assignment a1,…,an∈Σna_1,\\dots,a_n \\in \\Sigma^na1​,…,an​∈Σn where f(a1,…,an)=0f(a_1, \\dots, a_n) = 0f(a1​,…,an​)=0. As φ\\varphiφ has exactly 2n2^n2n variable assignments, it is satisfiable if and only if the set of accepted variable assignments L(M)L(M)L(M) has at most m:=2n−1m := 2^n - 1m:=2n−1 elements.\n\nThis reduction can clearly be done in polynomial time.\n\nIntuition &amp; Example\n\nConsider the following function:\n\nφ:=(cˉ+d)(aˉ+c+dˉ)(aˉ+bˉ+d)\\varphi := (\\bar{c} + d)(\\bar{a} + c + \\bar{d})(\\bar{a} + \\bar{b} + d)φ:=(cˉ+d)(aˉ+c+dˉ)(aˉ+bˉ+d)\n\nThe cubes that describe variable assignments where φ\\varphiφ is false are **10, 1*01 and 11*0 (variable order: a,b,c,da, b, c, da,b,c,d). These three cubes make the first, second and the third clauses false, respectively.\n\nWe can visualize all the possible variable assignments with a 4-dimensional cube (as φ\\varphiφ has 4 variables):\n\n\n\nIn this cube, every edge connects assignments that differ in exactly one bit (i.e. hamming distance = 1). Any lower dimensional cubes that are subgraphs of this cube are implicants if the vertices in the subgraph cover only assignments where the function is true. If a lower dimensional cube isn’t a part of some higher dimensional cube that still covers only assignments where the function is true, such a cube is a prime implicant. In this case, if we think of CNF-clauses as implicants of the negated function, then we can visualize them the following way:\n\n\n\nThe idea of the reduction is that if we can count the amount of vertices covered by these cubes, then we can compare this amount to the total number of vertices and if it is less than 2n2^n2n where nnn is the number of variables, then the function is satisfiable, otherwise not. The problem is that implicants aren’t always disjoint. So, the satisfiability problem is essentially the problem of comparing 2n2^n2n with the size of the union of variable assignments described by cubes.\n\nThese variable assignments that are parts of some cube(s) can be accepted with a nondeterministic finite automata (NFA) with nnn states. We can create such an NFA for each clause and then union them by marking multiple states as initial. In this example, we get the following NFA:\n\n\n\nThe top row of the NFA accepts variable assignments generated by the 11*0 cube, the middle row corresponds to the 1*01 cube and the bottom one - to **10. φ\\varphiφ is satisfiable if and only if there is at least one word of length 4, such that this NFA doesn’t accept it.\n\nConverting the NFA to a BDD\n\nThe idea of this reduction can be used to compute all the satisfying assignments of φ\\varphiφ. Consider the example above - we can apply the Rabin-Scott algorithm to convert the NFA to a DFA:\n\n\n\nThe computed DFA will always be a tree (without the ∅\\varnothing∅-node), because the initial NFA had no cycles in it. The satisfying assignments are the ones that are not accepted by the NFA. Therefore, they are exactly the paths of length nnn, leading to ∅\\varnothing∅. A program can easily output all satisfying assignments with a DFS or BFS-search in this tree.\n\nIf we replace ∅\\varnothing∅ with the positive leaf and all final states with a negative leaf (the transitions after them can be removed), then the graph will become an ordered binary decision diagram (OBDD) of φ\\varphiφ:\n\n\n\nOf course, the nodes should be renamed to variable names:\n\n\n\nThe Rabin-Scott algorithm doesn’t always output minimal deterministic automations and therefore in most cases the OBDD will also not be minimal, like in this case where the redundant checks are clearly seen. In order to get a ROBDD we will still need to apply the elimination and the isomorphism rules (remove redundant checks and reuse subtrees):\n\n\n\nNP-Complete special case\n\nWe can tweak the problem defined above to make it belong to NP\\mathcal{NP}NP:\n\nName: NFA Rejected m-string\n\nInput: A nondeterministic finite automata (NFA) M:=(Z,Σ,δ,S,E)M := (Z, \\Sigma, \\delta, S, E)M:=(Z,Σ,δ,S,E) and a unary-encoded number m∈Nm \\in \\mathbb{N}m∈N.\n\nQuestion: Exists such a string α∈Σ∗\\alpha \\in \\Sigma^*α∈Σ∗ of length mmm such that α∉L(M)\\alpha \\notin L(M)α∈/​L(M)?\n\nThis problem is in NP\\mathcal{NP}NP, because a string of length mmm can be used as a certificate. Then, by using the idea of the Rabin-Scott theorem, we can test whether the given string is rejected or not in polynomial time. The NP\\mathcal{NP}NP-hardness can be shown with a reduction from CNF-SAT as follows:\n\n\n  Consider a formula φ\\varphiφ with kkk clauses and nnn variables.\n  Construct an NFA M=(Z,Σ,δ,S,E)M = (Z, \\Sigma, \\delta, S, E)M=(Z,Σ,δ,S,E) by following the same steps as in the proof of NP\\mathcal{NP}NP-hardness of NFA Language Size.\n  Set m:=nm := nm:=n.\n\n\nφ\\varphiφ is satisfiable if and only if there is a rejected string of length mmm in L(M)L(M)L(M) which is exactly some satisfying assignment for φ\\varphiφ. Clearly, this is a polynomial-time reduction.\n\nFinding any rejected string is NP-Complete\n\nWe can also define another version of the problem and proof it’s NP\\mathcal{NP}NP-completeness:\n\nName: NFA Rejected String\n\nInput: A nondeterministic finite automata (NFA) M:=(Z,Σ,δ,S,E)M := (Z, \\Sigma, \\delta, S, E)M:=(Z,Σ,δ,S,E) and a unary-encoded number m∈Nm \\in \\mathbb{N}m∈N.\n\nQuestion: Exists such a string α∈Σ∗\\alpha \\in \\Sigma^*α∈Σ∗ with ∣α∣≤m\\st \\alpha \\st \\le m∣α∣≤m such that α∉L(M)\\alpha \\notin L(M)α∈/​L(M)?\n\nThis problem is in NP\\mathcal{NP}NP, because a string of length mmm can be used as a certificate, like in the NFA Rejected m-string problem.\n\nWe will prove NP\\mathcal{NP}NP-hardness by reducing NFA Rejected m-string to this problem. Consider an NFA M:=(Z,Σ,δ,S,E)M := (Z, \\Sigma, \\delta, S, E)M:=(Z,Σ,δ,S,E) and a number m′∈Nm&#x27; \\in \\mathbb{N}m′∈N:\n\n\n  Create mmm new nodes q1,…,qm∈Zq_1, \\dots, q_m \\in Zq1​,…,qm​∈Z.\n  For all 1≤s&lt;m1 \\le s &lt; m1≤s&lt;m and a∈Σa \\in \\Sigmaa∈Σ, set δ(qs,a):={qs+1}\\delta(q_s, a) := \\{q_{s+1}\\}δ(qs​,a):={qs+1​}.\n  Mark q1q_1q1​ as initial: S:=S∪{q1}S := S \\cup \\{q_1\\}S:=S∪{q1​}.\n  Mark q1,…,qmq_1, \\dots, q_mq1​,…,qm​ as final: E:=E∪{qi:1≤i≤m}E := E \\cup \\{q_i : 1 \\le i \\le m\\}E:=E∪{qi​:1≤i≤m}.\n  Set m:=m′m := m&#x27;m:=m′.\n\n\nBy construction, the new NFA will accept all strings of length m−1m - 1m−1 or less. Thus, there is a rejected string of length mmm if and only if there is a rejected string of length at most mmm in the new NFA. Obviously, this is a polynomial-time reduction.\n\nA few words about complexity\n\nThese problems illustrate an interesting connection between NP\\mathcal{NP}NP-complete problems, that can be solved in polynomial time by nondeterministic turing machines and the problem of just counting the language size described by an NFA. By the Rabin-Scott theorem, it is possible to convert any NFA to an equivalent DFA, but the worst-case complexity of the algorithm is Θ(2n)\\Theta(2^n)Θ(2n), because a set with nnn elements has 2n2^n2n subsets and all of these subsets will be reachable in the worst-case. Would the complexity of the subset-construction be polynomial, then it would mean that P=NP\\mathcal{P}  = \\mathcal{NP}P=NP as we can just search for all paths in the DFA that lead to ∅\\varnothing∅ after exactly nnn transitions (these paths are exactly the variable assignments that satisfy φ\\varphiφ).\n\nThe reduction discussed above can also be done in reverse. Any set of cubes can be transformed to a boolean function in conjunctive normal form. So, if P=NP\\mathcal{P} = \\mathcal{NP}P=NP and the CNF-SAT problem is solvable in polynomial time, then it is also possible to compare 2n2^n2n with the size of the union of some arbitrary boolean cubes. The cube union size problem is essentially a special case of the inclusion–exclusion principle, where the formula to compute the size of a union of nnn sets is also exponentially long, because the amount of possible intersections grows exponentially.\n\nIt seems impossible to compute the size of the union of some arbitrary cubes in polynomial time, because the variable assignments that some cube describes is exponential in the length of the encoding of the cube. And the amount of ways to intersect some cubes is also exponential. Any polynomial encoding for a cube will allow us to distinguish between an exponential amount of cubes. However, the amount of ways to intersect some kkk nnn-variable-cubes is in Ω(3(3n⋅(k−1)))\\Omega(3^{(3^{n \\cdot (k - 1)})})Ω(3(3n⋅(k−1))), so it is impossible to precisely encode the union of these kkk cubes with a polynomially long encoding. However, it could be possible to divide the search space so that it is still possible to compare 2n2^n2n with the size of the union of the cubes in polynomial time. Anyway, these thoughts aren’t even close to a formal proof that P≠NP\\mathcal{P} \\neq \\mathcal{NP}P​=NP.\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/regular-language-size-np-hard/"
    },{
      
      "title": "Computer Science",
      "date": "2020-10-28 19:29:57 +0100",
      "description": "This category contains all posts that have something to do with theoretical or practical computer science.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "featured_categories",
      "url": "/blog/cs/"
    },{
      "image": "/assets/img/projects/crproxy.jpg",
      "title": "Clash Royale Proxy",
      "date": "2018-07-01 00:00:00 +0200",
      "description": "CrProxy is a NodeJs implementation of a Clash Royale proxy server. It decrypts traffic between Supercell servers and the game.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/crproxy/"
    },{
      "image": "/assets/img/projects/zeropackerjs.svg",
      "title": "ZeroPackerJs",
      "date": "2018-11-20 00:00:00 +0100",
      "description": "ZeroPackerJs is serializing / deserializing library for javascript. Data is represented in binary format.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/zeropacker/"
    },{
      "image": "/assets/img/projects/apowbmodc.svg",
      "title": "ApowBmodC",
      "date": "2018-12-07 00:00:00 +0100",
      "description": "ApowBmodC is my small implementation of the efficient a ^ b mod c calculation algorithm.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/apowbmodc/"
    },{
      "image": "/assets/img/projects/sdlgrapher.jpg",
      "title": "SDL Grapher",
      "date": "2019-02-04 00:00:00 +0100",
      
      "content": "SdlGrapher allows you to plot graphs for mathematical functions with SDL 2.0 in C++.\n\nFeatures\n\n\n  Horizontal / vertical scrolling.\n  Scaling with mouse wheel.\n  No rendering if the math function returns NaN or Infinity.\n  Movable axises. Screen =&gt; Math, Math =&gt; Screen unit converters.\n  Automatically calculate scale and axis position based on interval of the math function.\n  Pixel perfect rendering.\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/sdlgrapher/"
    },{
      "image": "/assets/img/projects/bst.jpg",
      "title": "BST",
      "date": "2019-06-08 00:00:00 +0200",
      "description": "Optimized binary search tree implementation in C++.\n",
      "content": "Note: Binary search trees are not balanced by definition. This implementation does not guarantee O(log n) complexity when searching or deleting.\n\nFeatures\n\n  Pretty good performance compared to many other implementations on the internet.\n  No recursion except for debugging purposes.\n  Node-based on-delete balancing is supported. If you don’t need it, you can easily disable it.\n  Unique / non-unique element insertion.\n  2 deletion methods are supported:\n    \n      With payload copying (efficient, when it’s size is less than 2 * sizeof(void*)).\n      With pointer rearrangement.\n    \n  \n  Debug tree printing with indentation.\n  Lightweight, only one header file.\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/bst/"
    },{
      "image": "/assets/img/projects/chainhashmap.svg",
      "title": "ChainHashMap",
      "date": "2019-06-21 00:00:00 +0200",
      "description": "This is an implementation of a closed-addressed hash map in C++ without STL.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/chainhashmap/"
    },{
      "image": "/assets/img/projects/lzz.jpg",
      "title": "LZZ",
      "date": "2019-08-26 00:00:00 +0200",
      "description": "LZZ is a URL shortener that allows changing target URL’s after they have been created.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/lzz/"
    },{
      "image": "/assets/img/projects/cstring.jpg",
      "title": "CString",
      "date": "2019-08-27 00:00:00 +0200",
      "description": "Header-only, expandable and descriptor-caching string implementation in C99.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/cstring/"
    },{
      "image": "/assets/img/projects/zerorobo/gameplay01.png",
      "title": "ZeroRobo",
      "date": "2019-10-25 00:00:00 +0200",
      "description": "This is my RoboCode robot implemented in Java. It moves around special anchor points that allow it to avoid enemy bullets. Only 1vs1 mode is supported.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/zerorobo/"
    },{
      "image": "/assets/img/projects/vkantispam.jpg",
      "title": "VkAntiSpam",
      "date": "2019-11-01 00:00:00 +0100",
      "description": "Intelligent, integrated and self-learning antispam system for filtering spam in VK groups.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/vkantispam/"
    },{
      "image": "/assets/img/projects/chrem.jpg",
      "title": "chrem",
      "date": "2020-01-18 00:00:00 +0100",
      "description": "Algorithm to solve a linear system of congruences using the Chinese remainder theorem. Works also for non-coprime divisors.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/chrem/"
    },{
      "image": "/assets/img/projects/pollardrsacracker.jpg",
      "title": "PollardRsaCracker",
      "date": "2020-02-21 00:00:00 +0100",
      "description": "RSA cracking algorithm based on Pollard factorization.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/pollardrsacracker/"
    },{
      "image": "/assets/img/projects/knife.jpg",
      "title": "Knife",
      "date": "2020-03-31 00:00:00 +0200",
      "description": "Knife is a tool that reads input grammar in BNF format and converts it to a few Java classes that can parse the given grammar through a simple interface.\n",
      "content": "Knife doesn’t require any external libraries or dependencies. All generation is done ahead-of-time. After generating the parsing classes you can just copy them into your project.\n\nAlso, as other good parser generation tools, knife uses itself to read the input grammar.\n\nFeatures\n\n\n  No runtime dependencies, knife generates pure Java code that can easily be ported to other JVM-based languages.\n  Parsing is done using push-down automata without recursion.\n  Knife uses an explicit API for accepting the token stream. It allows you to easily use knife with any (including your own) lexer. You can pause and resume parsing at any point. Parsing multiple token streams simultaneously is also possible.\n  No complete parse-trees are being built during parsing. Reduction of the tree is done on-the-fly for performance. Optimized AST’s can be built during parsing with minimal overhead.\n  If your grammar is left-recursive without A =&gt;* A derivations (aka without cycles), knife will generate an equivalent grammar without left recursion for you.\n  Syntax error recovery using panic mode approach without any additional performance overhead.\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/knife/"
    },{
      "image": "/assets/img/projects/grammax.jpg",
      "title": "Grammax",
      "date": "2020-05-21 00:00:00 +0200",
      "description": "Grammax takes a grammar in BNF format as an input and converts it to a Java-class that recognizes the language generated by the grammar. Formally speaking, this tool creates a left-to-right, rightmost derivation (LR) parser for a given grammar. That means that grammax parses the given string by constructing a reversed rightmost derivation of it.\n",
      "content": "Grammax doesn’t require any external libraries or dependencies. All generation is done ahead-of-time. After generating the parsing classes you can just copy them into your project.\n\nAlso, as other good parser generation tools, grammax uses itself to read the input grammar.\n\nFeatures\n\n\n  No runtime dependencies, only pure Java code is generated.\n  Parsing is done using a push-down automation without recursion.\n  Grammax uses an explicit API for accepting the token stream. It allows you to easily use the tool with any (including your own) lexer. You can pause and resume parsing at any point. Parsing multiple token streams simultaneously is also possible.\n  Grammax supports simple lr and canonical lr parsing algorithms.\n  Automatic warnings about possible right-recursion cycles that cause a lot of parsing stack memory consumption.\n  Types can be assigned to terminals and non-terminals. The corresponding expressions are casted automatically.\n  The %top statement allows inserting package and import automatically. Therefore grammax can be used in an automated pipeline.\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/grammax/"
    },{
      "image": "/assets/img/projects/garbageset.jpg",
      "title": "GarbageSet",
      "date": "2020-05-22 00:00:00 +0200",
      "description": "Set data structure with all operation is O(1), including initialization!\n",
      "content": "This is a set data structure implementation in C. It can be initialized in constant time what makes it different compared to typical set implementation.\n\nComplexity\n\nThe following table gives an overview of what the datastructure is capable of. All the complexities are calculated assuming memory allocation is performed in O(1).\n\n\n  \n    \n      Operation\n      Description\n      Complexity\n    \n  \n  \n    \n      garbageset_init\n      Initializes the data structure with the specified capacity.\n      O(1)\n    \n    \n      garbageset_isset\n      Checks if there is an element at a specified index.\n      O(1)\n    \n    \n      garbageset_get\n      Retrieves the element at a specified indexor returns null, if there is no element at that index.\n      O(1)\n    \n    \n      garbageset_write\n      Writes a new element at the specified index or overwrites an old one if it was defined.\n      O(1)\n    \n  \n\n\nSpace complexity\n\nThe space complexity of the data structure is in O(n). However, apart from storing the payload array itself the data structure requires additional space for redundancy checking purposes. This additional space is about 2*n*sizeof(index_t) bytes where n is the capacity and index_t is the type used for indexes. With this user-defined you can easily reduce the memory overhead.\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/garbageset/"
    },{
      "image": "/assets/img/projects/numpat.jpg",
      "title": "NumPat",
      "date": "2020-08-30 00:00:00 +0200",
      "description": "Research tool for examining integer digit structure in different remainder classes.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/numpat/"
    }
  ]
}

