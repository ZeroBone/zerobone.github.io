

{
  "pages": [
    {
      
      
      
      "content": "\n",
      "url": "/404.html"
    },{
      
      "title": "Blog",
      "description": "Alexander Mayorov’s blog about computer science.\n",
      "content": "\n",
      "url": "/blog/"
    },{
      
      "title": "Дифференциальное исчисление",
      "description": "Дифференциальное исчисление.\n",
      "content": "Содержание\n\n\n  Сводка определений\n\n",
      "url": "/math/diff/"
    },{
      
      "title": "Интегральное исчисление",
      "description": "Интегральное исчисление.\n",
      "content": "Содержание\n\n\n  Неопределённый интеграл\n  Таблица интегралов\n  Замена переменной\n  Интегрирование по частям\n  Определённый интеграл\n  Определённый интеграл как функция верхнего предела\n  Формула Ньютона-Лейбница\n  Замена переменной в определённом интеграле\n  Интегрирование по частям в определённом интеграле\n  Несобственный интеграл 1 рода\n  Несобственный интеграл 2 рода\n  Ряды\n  Положительные ряды\n\n",
      "url": "/math/int/"
    },{
      
      "title": "Welcome",
      
      "content": "Hi, I am Alexander Mayorov (aka ZeroBone) and this is my personal website. I am currently a computer science student and a backend developer.\n\nApart from studying I do research. My fields of interests:\n\n\n  Theoretical computer science, formal languages &amp; computability\n  Compiler design and programming languages\n  Formal verification and automated proof procedures\n  Group theory &amp; linear algebra\n  Graph theory\n\n\nLatest posts\n\n\n\nLatest projects\n\n\n",
      "url": "/"
    },{
      
      "title": "Математика",
      "description": "Разделы\n",
      "content": "Внимание: Этот раздел находится в разработке и ещё не завершён.\n\nРазделы\n\n  Дифференциальное исчисление — пределы, производные.\n  Интегральное исчисление — первообразные, интегралы, ряды.\n\n",
      "url": "/math/"
    },{
      
      "title": "Криволинейный интеграл 1 рода",
      "description": "Несобственный интеграл 1 рода или интеграл с бесконечными пределами интегрирования.\n",
      "content": "Содержание\n\n  Гладкая кривая\n  Определение\n  Геометрический смысл\n  Свойства    \n      Вынесение за знак интеграла\n    \n  \n\n\nГладкая кривая\n\nКривая называется гладкой, если в каждой точке она имеет непрерывно изменяющуюся касательную.\n\nОпределение\n\nПусть LLL - гладкая кривая, а f(M)f(M)f(M) - непрерывная функция, заданная в любой точке mmm этой кривой.\n\nРазобъём кривую LLL произвольным образом на nnn частей, длины которых Δl1\\Delta l_1Δl1​, Δl2\\Delta l_2Δl2​, …\\dots…, Δln\\Delta l_nΔln​.\n\nВ каждом частичном кусочке Δli\\Delta l_iΔli​ произвольно возьмём точку MiM_iMi​ и составим интегральную сумму:\n\n∑i=1nf(Mi)Δli\\sum_{i=1}^n{f(M_i)}\\Delta l_ii=1∑n​f(Mi​)Δli​\n\nКриволинейным интегралом по линии LLL 1 рода называется предел (если он существует):\n\n∫Lf(x,y,z)dl=∫Lf(M)dl=lim⁡n→∞,max⁡Δli→0∑i=1nf(Mi)Δli\\int_L{f(x,y,z)dl} =\\int_L{f(M)dl} =\n\\lim_{n \\to \\infty, \\max{\\Delta l_i} \\to 0}{\\sum_{i=1}^n{f(M_i)}\\Delta l_i}∫L​f(x,y,z)dl=∫L​f(M)dl=n→∞,maxΔli​→0lim​i=1∑n​f(Mi​)Δli​\n\nГеометрический смысл\n\nСвойства\n\nВынесение за знак интеграла\n\n∫L(αf1(M)+βf2(m))dl=α∫Lf1(M)dl+β∫Lf2(M)dl\\int_L{(\\alpha f_1(M) + \\beta f_2(m)) dl} =\n\\alpha \\int_L{f_1(M)dl} + \\beta \\int_L{f_2(M) dl}∫L​(αf1​(M)+βf2​(m))dl=α∫L​f1​(M)dl+β∫L​f2​(M)dl\n",
      "url": "/math/int/kriv-1/"
    },{
      
      "title": "Неопределённый интеграл",
      "description": "Неопределённый интеграл: его определение и свойства.\n",
      "content": "Содержание\n\n  Первообразная\n  Определение\n  Свойства    \n      Свойство 1        \n          Доказательство\n        \n      \n      Свойство 2        \n          Доказательство\n        \n      \n      Линейное свойство\n    \n  \n\n\nПервообразная\n\nF(x)F(x)F(x) называется первообразной для f(x)f(x)f(x) на множестве XXX, если ∀x∈X F′(x)=f(x)\\forall x \\in X \\space F&#x27;(x) = f(x)∀x∈X F′(x)=f(x)\n\nЕсли F(x)F(x)F(x) - первообразная функции f(x)f(x)f(x), то любая функция F(x)+CF(x) + CF(x)+C, где C=constC = constC=const также является первообразной.\n\nМножество первообразных исчерпывается функциями вида F(x)+CF(x) + CF(x)+C, то есть первообразных у функции бесконечно много с точностью до константы.\n\nЕсли F1(x)F_1(x)F1​(x) и F2(x)F_2(x)F2​(x) - первообразные f(x)f(x)f(x), тогда F1(x)−F2(x)=C=constF_1(x) - F_2(x) = C = constF1​(x)−F2​(x)=C=const.\n\nОпределение\n\nНеопределённым интегралом функции f(x)f(x)f(x) называют совокупность всех её первообразных.\n\n∫f(x)dx=F(x)+C\\int f(x)dx = F(x) + C∫f(x)dx=F(x)+C\n\nf(x)dxf(x)dxf(x)dx - подынтегральное выражение.\n\nf(x)f(x)f(x) - подынтегральная функция.\n\nСвойства\n\nСвойство 1\n\n∫dF(x)=F(x)+C\\int dF(x) = F(x) + C∫dF(x)=F(x)+C\n\nгде dF(x)dF(x)dF(x) - дифференциал функции.\n\nФормула для нахождения дифференциала:\n\ndg(x)=g′(x)dxdg(x) = g&#x27;(x)dxdg(x)=g′(x)dx\n\ndg(u)=dg(u(x))=g′(u)ux′dx=g′(u)dudg(u) = dg(u(x)) = g&#x27;(u)u_x&#x27;dx = g&#x27;(u)dudg(u)=dg(u(x))=g′(u)ux′​dx=g′(u)du\n\nДоказательство\n\n∫dF(x)=∫F′(x)dx=∫f(x)dx=F(x)+C\\int dF(x) = \\int F&#x27;(x)dx = \\int f(x)dx = F(x) + C∫dF(x)=∫F′(x)dx=∫f(x)dx=F(x)+C\n\nСвойство доказано.\n\nСвойство 2\n\nd∫f(x)dx=f(x)dxd \\int f(x)dx = f(x)dxd∫f(x)dx=f(x)dx\n\nДоказательство\n\nd∫f(x)dx=d(F(x)+C)=(F(x)+C)′dx=(F′(x)+C′)dxd \\int f(x)dx = d(F(x) + C) = (F(x) + C)&#x27;dx = (F&#x27;(x) + C&#x27;)dxd∫f(x)dx=d(F(x)+C)=(F(x)+C)′dx=(F′(x)+C′)dx\n\nC′=0⇒(F′(x)+C′)dx=F′(x)dx=f(x)dxC&#x27; = 0 \\Rightarrow (F&#x27;(x) + C&#x27;)dx = F&#x27;(x)dx = f(x)dxC′=0⇒(F′(x)+C′)dx=F′(x)dx=f(x)dx\n\nЛинейное свойство\n\nКонстанту ccc можно выносить за знак интеграла.\n\n∫cf(x)dx=c∫f(x)dx\\int cf(x)dx = c \\int f(x)dx∫cf(x)dx=c∫f(x)dx\n\nИнтеграл от суммы равен сумме интегралов.\n\n∫(f1(x)+f2(x))dx=∫f1(x)dx+∫f2(x)dx\\int (f_1(x) + f_2(x))dx = \\int f_1(x)dx + \\int f_2(x)dx∫(f1​(x)+f2​(x))dx=∫f1​(x)dx+∫f2​(x)dx\n",
      "url": "/math/int/neopr/"
    },{
      
      "title": "Несобственный интеграл 1 рода",
      "description": "Несобственный интеграл 1 рода или интеграл с бесконечными пределами интегрирования.\n",
      "content": "Содержание\n\n  Определение\n  Геометрический смысл\n  Эталонный интеграл    \n      Доказательство\n    \n  \n\n\nОпределение\n\nПусть f(x)f(x)f(x) непрерывна на [a,∞)[a, \\infty)[a,∞).\n\nТогда несобственным интегралом 1 рода или интегралом с бесконечными пределами интегрирования называется предел:\n\n∫a∞f(x)dx=lim⁡b→∞∫abf(x)dx\\int_{a}^{\\infty}{f(x) dx} = \\lim_{b \\to \\infty}{\\int_{a}^{b}{f(x) dx}}∫a∞​f(x)dx=b→∞lim​∫ab​f(x)dx\n\nЕсли этот предел существует и конечен, несобственный интеграл называется сходящимся.\n\nЕсли этот предел не существует или бесконечен, несобственный интеграл называется расходящимся.\n\n∫a∞f(x)dx=F(x)∣a∞=lim⁡x→∞F(x)−F(a)\\int_a^{\\infty}{f(x) dx} = F(x) \\Big|_a^{\\infty} = \\lim_{x \\to \\infty}{F(x)} - F(a)∫a∞​f(x)dx=F(x)∣∣∣∣​a∞​=x→∞lim​F(x)−F(a)\n\nНижний предел также может быть бесконечным:\n\n∫−∞af(x)dx=lim⁡b→−∞∫abf(x)dx\\int_{-\\infty}^{a}{f(x) dx} = \\lim_{b \\to -\\infty}{\\int_a^b{f(x) dx}}∫−∞a​f(x)dx=b→−∞lim​∫ab​f(x)dx\n\nОба предела интегрирования могут быть бесконечными - тогда необходимо разбить интеграл на 2 несобственных интеграла 1 рода.\n\n∫−∞∞f(x)dx=∫−∞cf(x)dx+∫c∞f(x)dx\\int_{-\\infty}^{\\infty}{f(x) dx} =\n\\int_{-\\infty}^{c}{f(x) dx} + \\int_{c}^{\\infty}{f(x) dx}∫−∞∞​f(x)dx=∫−∞c​f(x)dx+∫c∞​f(x)dx\n\nЭтот интеграл сходится тогда, когда оба слагаемых сходятся.\n\nГеометрический смысл\n\nЕсли f(x)≥0 ∀x∈[a,∞)f(x) \\ge 0 \\space \\forall x \\in [a, \\infty)f(x)≥0 ∀x∈[a,∞) то несобственный интеграл равен площади бесконечной криволинейной трапеции:\n\n∫a∞f(x)dx=Sбеск.крив.трапец.\\int_a^{\\infty}{f(x) dx} = S_{беск.крив.трапец.}∫a∞​f(x)dx=Sбеск.крив.трапец.​\n\n\n\nЭталонный интеграл\n\nРассмотрим следующий интеграл\n\n∫a∞dxxα\\int_a^{\\infty}{\\frac{dx}{x^{\\alpha}}}∫a∞​xαdx​\n\nОн сходится, если α&gt;1\\alpha &gt; 1α&gt;1.\nОн расходится, если α≤1\\alpha \\le 1α≤1.\n\nДоказательство\n\nПусть α=1\\alpha = 1α=1. Тогда:\n\n∫a∞dxx=ln⁡∣x∣∣a∞=lim⁡x→∞ln⁡∣x∣−ln⁡∣a∣=∞\\int_a^{\\infty}{\\frac{dx}{x}} = \\ln{|x|}\\Big|_a^{\\infty} =\n\\lim_{x \\to \\infty}{\\ln |x|} - \\ln |a| = \\infty∫a∞​xdx​=ln∣x∣∣∣∣∣​a∞​=x→∞lim​ln∣x∣−ln∣a∣=∞\n\nТаким образом, при α=1\\alpha = 1α=1 интеграл расходится.\n\nПусть α&gt;1\\alpha &gt; 1α&gt;1. Тогда:\n\n∫a∞dxxα=∫a∞x−αdx=x−α+1−α+1∣a∞==1(−α+1)xα−1∣a∞=0−1(−α+1)aα−1=−1(−α+1)aα−1\\int_a^{\\infty}{\\frac{dx}{x^{\\alpha}}} =\n\\int_a^{\\infty}{x^{-\\alpha} dx} =\n\\frac{x^{-\\alpha + 1}}{-\\alpha + 1} \\Bigg|_a^{\\infty} = \\\\\n= \\frac{1}{(-\\alpha + 1)x^{\\alpha - 1}} \\Bigg|_a^{\\infty} =\n0 - \\frac{1}{(-\\alpha + 1)a^{\\alpha - 1}} = - \\frac{1}{(-\\alpha + 1)a^{\\alpha - 1}}∫a∞​xαdx​=∫a∞​x−αdx=−α+1x−α+1​∣∣∣∣∣∣​a∞​==(−α+1)xα−11​∣∣∣∣∣∣​a∞​=0−(−α+1)aα−11​=−(−α+1)aα−11​\n\nПолучили конечное число, следовательно, при α&gt;1\\alpha &gt; 1α&gt;1 интеграл сходится.\n\nПусть α&lt;1\\alpha &lt; 1α&lt;1. Тогда:\n\n∫a∞dxxα=∫a∞x−αdx=x−α+1−α+1∣a∞==∞−a−α+1−α+1=∞\\int_a^{\\infty}{\\frac{dx}{x^{\\alpha}}} =\n\\int_a^{\\infty}{x^{-\\alpha} dx} =\n\\frac{x^{-\\alpha + 1}}{-\\alpha + 1} \\Bigg|_a^{\\infty} = \\\\\n= \\infty - \\frac{a^{-\\alpha + 1}}{-\\alpha + 1} = \\infty∫a∞​xαdx​=∫a∞​x−αdx=−α+1x−α+1​∣∣∣∣∣∣​a∞​==∞−−α+1a−α+1​=∞\n\nПоличили бесконечность, следовательно при α&lt;1\\alpha &lt; 1α&lt;1 интеграл расходится.\n\nСходимость эталонного интеграла доказана.\n",
      "url": "/math/int/nes-1/"
    },{
      
      "title": "Несобственный интеграл 2 рода",
      "description": "Несобственный интеграл 2 рода или интеграл с бесконечной функцией.\n",
      "content": "Содержание\n\n  Определение\n  Геометрический смысл\n  Эталонный интеграл    \n      Доказательство\n    \n  \n\n\nОпределение\n\nПусть f(x)f(x)f(x) непрерывна на [a,c)[a, c)[a,c) и терпит бесконечный разрыв в точке ccc.\n\nТогда несобственным интегралом 2 рода или интегралом с бесконечной функцией называется предел:\n\n∫acf(x)dx=lim⁡b→c−0∫abf(x)dx\\int_{a}^{c}{f(x) dx} = \\lim_{b \\to c - 0}{\\int_{a}^{b}{f(x) dx}}∫ac​f(x)dx=b→c−0lim​∫ab​f(x)dx\n\nЕсли этот предел существует и конечен, несобственный интеграл называется сходящимся.\n\nЕсли этот предел не существует или бесконечен, несобственный интеграл называется расходящимся.\n\nФункция может терпеть бесконечный разрыв и в нижнем пределе интегрирования.\n\n∫cbf(x)dx=lim⁡a→c+0∫abf(x)dx\\int_{c}^{b}{f(x) dx} = \\lim_{a \\to c + 0}{\\int_a^b{f(x) dx}}∫cb​f(x)dx=a→c+0lim​∫ab​f(x)dx\n\nЕсли точка разрыва ccc лежит внутри интервала, задаваемого пределами интегрирования, то есть c∈(a,b)c \\in (a, b)c∈(a,b), такой интеграл нужно разбить на 2 несобственных интеграла 2 рода.\n\n∫abf(x)dx=∫acf(x)dx+∫cbf(x)dx\\int_{a}^{b}{f(x) dx} =\n\\int_{a}^{c}{f(x) dx} + \\int_{c}^{b}{f(x) dx}∫ab​f(x)dx=∫ac​f(x)dx+∫cb​f(x)dx\n\nЭтот интеграл сходится тогда, когда оба слагаемых сходятся.\n\nГеометрический смысл\n\nЕсли f(x)≥0 ∀x∈[a,c]f(x) \\ge 0 \\space \\forall x \\in [a, c]f(x)≥0 ∀x∈[a,c] то несобственный интеграл равен площади бесконечной криволинейной трапеции:\n\n∫acf(x)dx=Sбеск.крив.трапец.\\int_a^c{f(x) dx} = S_{беск.крив.трапец.}∫ac​f(x)dx=Sбеск.крив.трапец.​\n\n\n\nЭталонный интеграл\n\nРассмотрим следующий интеграл\n\n∫acdx(x−c)m\\int_a^c{\\frac{dx}{(x-c)^m}}∫ac​(x−c)mdx​\n\nОн сходится, если m&lt;1m &lt; 1m&lt;1.\nОн расходится, если m≥1m \\ge 1m≥1.\n\nДоказательство\n\nПусть m=1m = 1m=1. Тогда:\n\n∫acdxx−c=ln⁡∣x−c∣∣ac=lim⁡x→c+0ln⁡∣x−c∣−ln⁡∣a−c∣=∞\\int_a^c{\\frac{dx}{x - c}} = \\ln{|x - c|}\\Big|_a^c =\n\\lim_{x \\to c + 0}{\\ln |x - c|} - \\ln |a - c| = \\infty∫ac​x−cdx​=ln∣x−c∣∣∣∣∣​ac​=x→c+0lim​ln∣x−c∣−ln∣a−c∣=∞\n\nТаким образом, при m=1m = 1m=1 интеграл расходится.\n\nПусть m&gt;1m &gt; 1m&gt;1. Тогда:\n\n∫acdx(x−c)m=(x−c)−m+1−m+1∣ac=1(−m+1)(x−c)m−1∣ac=∞\\int_a^c{\\frac{dx}{(x - c)^m}} =\n\\frac{(x-c)^{-m + 1}}{-m + 1} \\Bigg|_a^c = \\frac{1}{(-m + 1)(x-c)^{m - 1}} \\Bigg|_a^c = \\infty∫ac​(x−c)mdx​=−m+1(x−c)−m+1​∣∣∣∣∣∣​ac​=(−m+1)(x−c)m−11​∣∣∣∣∣∣​ac​=∞\n\nПолучили бесконечность, следовательно, при m&gt;1m &gt; 1m&gt;1 интеграл расходится.\n\nПусть m&lt;1m &lt; 1m&lt;1. Тогда:\n\n∫acdx(x−c)m=(x−c)−m+1−m+1∣ac=0−(a−c)−m+1−m+1=D,D=const\\int_a^c{\\frac{dx}{(x - c)^m}} =\n\\frac{(x-c)^{-m + 1}}{-m + 1} \\Bigg|_a^c =\n0 - \\frac{(a - c)^{-m + 1}}{-m + 1} = D, D = const∫ac​(x−c)mdx​=−m+1(x−c)−m+1​∣∣∣∣∣∣​ac​=0−−m+1(a−c)−m+1​=D,D=const\n\nПоличили конечное число, следовательно при m&lt;1m &lt; 1m&lt;1 интеграл сходится.\n\nСходимость эталонного интеграла доказана.\n",
      "url": "/math/int/nes-2/"
    },{
      
      "title": "Формула Ньютона-Лейбница",
      "description": "Формула Ньютона-Лейбница.\n",
      "content": "Содержание\n\n  Формула\n  Доказательство\n  Пример\n\n\nФормула\n\n∫abf(x)dx=F(b)−F(a)\\int_{a}^{b}{f(x) dx} = F(b) - F(a)∫ab​f(x)dx=F(b)−F(a)\n\nF(x)F(x)F(x) - первообразная от f(x)f(x)f(x).\n\nДоказательство\n\nПоскольку F(x)F(x)F(x) - первообразная f(x)f(x)f(x), F′(x)=f(x)F&#x27;(x) = f(x)F′(x)=f(x).\n\nРассмотрим определённый интеграл как функцию верхнего предела.\n\nΦ′(x)=(∫axf(t)dt)′=f(x)\\Phi&#x27;(x) = \\Big( \\int_a^x{f(t) dt} \\Big)&#x27; = f(x)Φ′(x)=(∫ax​f(t)dt)′=f(x)\n\nЗначит, Φ(x)\\Phi(x)Φ(x) - тоже первообразная f(x)f(x)f(x), то есть Φ(x)=F(x)+C\\Phi(x) = F(x) + CΦ(x)=F(x)+C.\n\nСледовательно:\n\n∫axf(t)dt=F(x)+C\\int_a^x{f(t) dt} = F(x) + C∫ax​f(t)dt=F(x)+C\n\nПусть x=ax = ax=a:\n\n∫aaf(t)dt=F(a)+C\\int_a^a{f(t) dt} = F(a) + C∫aa​f(t)dt=F(a)+C\n\nПоскольку определённый интеграл с одинаковыми пределами интегрирования равен 0 мы можем показать, что:\n\nC=−F(a)C = -F(a)C=−F(a)\n\nСледовательно:\n\n∫axf(t)dt=F(x)−F(a)\\int_a^x{f(t) dt} = F(x) - F(a)∫ax​f(t)dt=F(x)−F(a)\n\nТо есть, если x=bx = bx=b, формула примет следующий вид.\n\n∫abf(t)dt=F(b)−F(a)\\int_a^b{f(t) dt} = F(b) - F(a)∫ab​f(t)dt=F(b)−F(a)\n\nИли как в определении формулы:\n\n∫abf(x)dx=F(b)−F(a)\\int_a^b{f(x) dx} = F(b) - F(a)∫ab​f(x)dx=F(b)−F(a)\n\nПример\n\n∫03xdx=12(32−02)=92\\int_0^3{xdx} = \\frac{1}{2}(3^2 - 0^2) = \\frac{9}{2}∫03​xdx=21​(32−02)=29​\n",
      "url": "/math/int/newton-leibniz/"
    },{
      
      
      
      "content": "\n",
      "url": "/offline.html"
    },{
      
      "title": "Интегрирование по частям в определённом интеграле",
      "description": "Интегрирование по частям в определённом интеграле\n",
      "content": "Содержание\n\n  Вывод\n  Формула\n  Пример\n\n\nВывод\n\nПусть u(x)u(x)u(x), v(x)v(x)v(x) непрерывны на [a,b][a, b][a,b].\n\nd(uv)=vdu+udvudv=d(uv)−vdu∫abudv=∫abd(uv)−∫abvdu==(uv)∣ab−∫abvdud(uv) = vdu + udv \\\\\nudv = d(uv) - vdu \\\\\n\\int_a^b{udv} = \\int_a^b{d(uv)} - \\int_a^b{vdu} = \\\\\n= (uv) \\Big|_a^b - \\int_a^b{vdu}d(uv)=vdu+udvudv=d(uv)−vdu∫ab​udv=∫ab​d(uv)−∫ab​vdu==(uv)∣∣∣∣​ab​−∫ab​vdu\n\nФормула\n\n∫abudv=uv∣ab−∫abvdu\\int_a^b{udv} = uv \\Big|_a^b - \\int_a^b{vdu}∫ab​udv=uv∣∣∣∣​ab​−∫ab​vdu\n\nПример\n\n∫0π2xsin⁡xdx=[u=xdu=dxdv=sin⁡xdxv=−cos⁡x]==−xcos⁡x∣0π2−∫0π2cos⁡xdx==−π2cos⁡π2+0cos⁡0+sin⁡x∣0π2==sin⁡π2−sin⁡0=1\\int_{0}^{\\frac{\\pi}{2}}{x \\sin{x} dx} = \n\\left[ \\begin{array}{ll}\nu = x &amp; du = dx \\\\\ndv = \\sin x dx &amp; v = -\\cos x\n\\end{array} \\right] = \\\\\n= -x \\cos{x} \\Big|_0^{\\frac{\\pi}{2}} - \\int_{0}^{\\frac{\\pi}{2}}{\\cos{x} dx} = \\\\\n= -\\frac{\\pi}{2} \\cos{\\frac{\\pi}{2}} + 0\\cos{0} + \\sin{x} \\Big|_0^{\\frac{\\pi}{2}} = \\\\\n= \\sin{\\frac{\\pi}{2}} - \\sin{0} = 1∫02π​​xsinxdx=[u=xdv=sinxdx​du=dxv=−cosx​]==−xcosx∣∣∣∣​02π​​−∫02π​​cosxdx==−2π​cos2π​+0cos0+sinx∣∣∣∣​02π​​==sin2π​−sin0=1\n",
      "url": "/math/int/opr-parts/"
    },{
      
      "title": "Замена переменной в определённом интеграле",
      "description": "Замена переменной в определённом интеграле\n",
      "content": "Содержание\n\n  Определение\n  Пример\n\n\nОпределение\n\nРассмотрим интеграл\n\n∫abf(x)dx\\int_a^b{f(x) dx}∫ab​f(x)dx\n\nf(x)f(x)f(x) непрерывна на [a,b][a, b][a,b].\n\nВведём новую переменную ttt, которая связана с xxx через: x=φ(t)x = \\varphi(t)x=φ(t).\n\nПусть выполняются следующие условия:\n\n\n  φ(t)\\varphi(t)φ(t) непрерывна на [a,b][a, b][a,b].\n  φ(α)=a\\varphi(\\alpha) = aφ(α)=a, φ(β)=b\\varphi(\\beta) = bφ(β)=b.\n  φ′(t)\\varphi&#x27;(t)φ′(t) непрерывна на [α,β][\\alpha, \\beta][α,β].\n  При изменении ttt от α\\alphaα до β\\betaβ, φ(t)\\varphi(t)φ(t) принимает все значения из [a,b][a, b][a,b].\n\n\nТогда справедлива следующая формула.\n\n∫abf(x)dx=∫αβf(φ(t))φ′(t)dt\\int_a^b{f(x)dx} = \\int_{\\alpha}^{\\beta}{f(\\varphi(t)) \\varphi&#x27;(t) dt}∫ab​f(x)dx=∫αβ​f(φ(t))φ′(t)dt\n\nПример\n\n∫27xx+2dx=[x+2=t2x=t2−2dx=2tdtx=2⇒t=2x=7⇒t=3]==2∫23(t4−2t2)dt=2(355−2×333−255+2×233)\\int_{2}^{7}{x \\sqrt{x+2} dx} = \n\\left[ \\begin{array}{ll}\nx+2=t^2 &amp; x = t^2 - 2 \\\\\ndx = 2tdt \\\\\nx = 2 \\Rightarrow t = 2 &amp; x = 7 \\Rightarrow t = 3\n\\end{array} \\right] = \\\\\n= 2\\int_{2}^{3}{(t^4 - 2t^2) dt} =\n2(\\frac{3^5}{5} - \\frac{2 \\times 3^3}{3} - \\frac{2^5}{5} + \\frac{2 \\times 2^3}{3})∫27​xx+2​dx=⎣⎢⎡​x+2=t2dx=2tdtx=2⇒t=2​x=t2−2x=7⇒t=3​⎦⎥⎤​==2∫23​(t4−2t2)dt=2(535​−32×33​−525​+32×23​)\n",
      "url": "/math/int/opr-replace/"
    },{
      
      "title": "Определённый интеграл как функция верхнего предела",
      "description": "Определённый интеграл как функция верхнего предела.\n",
      "content": "Содержание\n\n  Определение\n  Теорема\n  Доказательство\n\n\nОпределение\n\nРассмотрим функцию Ψ(x)\\Psi(x)Ψ(x).\n\nΨ(x)=∫axf(t)dt\\Psi(x) = \\int_{a}^{x}{f(t)dt}Ψ(x)=∫ax​f(t)dt\n\nПромежуток [a,x][a, x][a,x] находится внутри промежутка [a,b][a, b][a,b].\n\n\n\nТеорема\n\nΨ′(x)=(∫axf(t)dt)′=f(x)\\Psi&#x27;(x) = \\Big(\\int_a^x{f(t) dt}\\Big)&#x27; = f(x)Ψ′(x)=(∫ax​f(t)dt)′=f(x)\n\nДоказательство\n\nПусть xxx получило приращение Δx\\Delta xΔx.\n\nТогда Ψ(x)\\Psi(x)Ψ(x) пусть получило приращение ΔΨ\\Delta \\PsiΔΨ.\n\nΔΨ=Ψ(x+Δx)−Ψ(x)==∫ax+Δxf(t)dt−∫axf(t)dt==∫axf(t)dt+∫xx+Δxf(t)dt−∫axf(t)dt==∫xx+Δxf(t)dt\\Delta \\Psi = \\Psi(x + \\Delta x) - \\Psi (x) = \\\\\n= \\int_a^{x+\\Delta x}{f(t) dt} - \\int_a^x{f(t) dt} = \\\\\n= \\int_a^x{f(t) dt} + \\int_x^{x + \\Delta x}{f(t) dt} - \\int_a^x{f(t) dt} = \\\\\n= \\int_x^{x + \\Delta x}{f(t) dt}ΔΨ=Ψ(x+Δx)−Ψ(x)==∫ax+Δx​f(t)dt−∫ax​f(t)dt==∫ax​f(t)dt+∫xx+Δx​f(t)dt−∫ax​f(t)dt==∫xx+Δx​f(t)dt\n\nПо теореме о среднем:\n\n∫xx+Δxf(t)dt=f(ξ)(x+Δx−x)=f(ξ)Δx\\int_x^{x + \\Delta x}{f(t) dt} = f(\\xi)(x + \\Delta x - x) = f(\\xi)\\Delta x∫xx+Δx​f(t)dt=f(ξ)(x+Δx−x)=f(ξ)Δx\n\nТо есть:\n\nΔΨ=f(ξ)Δx\\Delta \\Psi = f(\\xi)\\Delta xΔΨ=f(ξ)Δx\n\nТочка ξ∈[x,x+Δx]\\xi \\in [x, x + \\Delta x]ξ∈[x,x+Δx]\n\nΨ′(x)=lim⁡Δx→0ΔΨΔx=lim⁡Δx→0f(ξ)ΔxΔx\\Psi&#x27;(x) = \\lim_{\\Delta x \\to 0}{\\frac{\\Delta \\Psi}{\\Delta x}} =\n\\lim_{\\Delta x \\to 0}{\\frac{f(\\xi) \\Delta x}{\\Delta x}}Ψ′(x)=Δx→0lim​ΔxΔΨ​=Δx→0lim​Δxf(ξ)Δx​\n\nПоскольку Δx→0⇒ξ→x\\Delta x \\to 0 \\Rightarrow \\xi \\to xΔx→0⇒ξ→x\n\nlim⁡Δx→0f(ξ)ΔxΔx=lim⁡ξ→xf(ξ)=f(x)\\lim_{\\Delta x \\to 0}{\\frac{f(\\xi) \\Delta x}{\\Delta x}} =\n\\lim_{\\xi \\to x}{f(\\xi)} = f(x)Δx→0lim​Δxf(ξ)Δx​=ξ→xlim​f(ξ)=f(x)\n\nСледовательно:\n\nΨ′(x)=(∫axf(t)dt)′=f(x)\\Psi&#x27;(x) = \\Big(\\int_a^x{f(t) dt} \\Big)&#x27; = f(x)Ψ′(x)=(∫ax​f(t)dt)′=f(x)\n\nТеорема доказана.\n",
      "url": "/math/int/opr-top-lim-f/"
    },{
      
      "title": "Определённый интеграл",
      "description": "Неопределённый интеграл: его определение и свойства.\n",
      "content": "Содержание\n\n  Интегральная сумма\n  Определение\n  Геометрический смысл\n  Свойства    \n      Вынесение константы        \n          Доказательство\n        \n      \n      Интеграл суммы        \n          Доказательство\n        \n      \n      Сравнение функций        \n          Доказательство\n        \n      \n      Описанный прямоугольник        \n          Доказательство\n          Геометрический смысл\n        \n      \n      Теорема о среднем        \n          Геометрический смысл\n        \n      \n      Смена пределов интегрирования\n      Одинаковые пределы интегрирования\n      Разбиение на части\n    \n  \n\n\nИнтегральная сумма\n\nРассмотрим функцию f(x)f(x)f(x), которая непрерывна на [a,b][a, b][a,b].\n\n\n\nРазобъём промежуток [a,b][a,b][a,b] на участки Δxi\\Delta x_iΔxi​ произвольным образом.\n\nДлина одного участка: Δxi=xi+1−xi\\Delta x_i = x_{i+1} - x_iΔxi​=xi+1​−xi​\n\nВ каждом таком участке произвольным образом возьмём точку ξi\\xi_iξi​, то есть ξi∈[xi,xi+1]\\xi_i \\in [x_i, x_{i+1}]ξi​∈[xi​,xi+1​].\n\nСоставим интегральную сумму.\n\nSn=∑i=0n−1f(ξi)ΔxiS_n = \\sum_{i=0}^{n-1}{f(\\xi_i) \\Delta x_i}Sn​=i=0∑n−1​f(ξi​)Δxi​\n\nПри этом 0≤i≤n−10 \\le i \\le n-10≤i≤n−1, обозначим max⁡Δxi=λ\\max{\\Delta x_i} = \\lambdamaxΔxi​=λ.\n\nОпределение\n\nЕсли существует предел последовательности интегральных сумм SnS_nSn​, не зависящих от способа разбиения и не зависящих от выбора точек внутри частичных промежутков, то этот предел называется определённым интегралом и обозначается:\n\n∫abf(x)dx=lim⁡n→∞,λ→0∑i=0n−1f(ξi)Δxi\\int_{a}^{b}{f(x) dx} =\n\\lim_{\nn \\to \\infin, \\lambda \\to 0\n}\n\\sum_{i=0}^{n-1}{f(\\xi_i) \\Delta x_i}∫ab​f(x)dx=n→∞,λ→0lim​i=0∑n−1​f(ξi​)Δxi​\n\nГеометрический смысл\n\nПусть f(x)≥0∀x∈[a,b]f(x) \\ge 0 \\forall x \\in [a, b]f(x)≥0∀x∈[a,b]\n\nТогда интегральная сумма будет равна площади ступенчатой фигуры.\n\nSn=∑i=0n−1f(ξi)Δxi=Sступен.фигурыS_n = \\sum_{i=0}^{n-1}{f(\\xi_i) \\Delta x_i} = S_{ступен. фигуры}Sn​=i=0∑n−1​f(ξi​)Δxi​=Sступен.фигуры​\n\nПри n→∞n \\to \\inftyn→∞ получится площадь криволинейной фигуры (криволинейной трапеции).\n\nn→∞,λ→0⇒Sступен.фигуры→Sкрив.трапец.n \\to \\infty, \\lambda \\to 0 \\Rightarrow S_{ступен. фигуры} \\to S_{крив. трапец.}n→∞,λ→0⇒Sступен.фигуры​→Sкрив.трапец.​\n\n∫abf(x)dx=Sкрив.трапец.\\int_{a}^{b}{f(x) dx} = S_{крив. трапец.}∫ab​f(x)dx=Sкрив.трапец.​\n\nТаким образом, определённый интеграл равен площади криволинейной трапеции.\n\n\n\nСвойства\n\nВынесение константы\n\n∫abAf(x)dx=A∫abf(x)dx\\int_{a}^{b}{A f(x) dx} = A \\int_{a}^{b}{f(x) dx}∫ab​Af(x)dx=A∫ab​f(x)dx\n\nДоказательство\n\n∫abAf(x)dx=lim⁡n→∞,λ→0∑i=0n−1Af(ξi)Δxi==Alim⁡n→∞,λ→0∑i=0n−1f(ξi)Δxi=A∫abf(x)dx\\int_{a}^{b}{A f(x) dx} =\n\\lim_{n \\to \\infty, \\lambda \\to 0}{\n\\sum_{i=0}^{n-1}{A f(\\xi_i) \\Delta x_i}\n} = \\\\ =\nA \\lim_{n \\to \\infty, \\lambda \\to 0}{\n\\sum_{i=0}^{n-1}{f(\\xi_i) \\Delta x_i}\n} =\nA \\int_{a}^{b}{f(x) dx}∫ab​Af(x)dx=n→∞,λ→0lim​i=0∑n−1​Af(ξi​)Δxi​==An→∞,λ→0lim​i=0∑n−1​f(ξi​)Δxi​=A∫ab​f(x)dx\n\nИнтеграл суммы\n\n∫ab(f1(x)+f2(x))dx=∫abf1(x)dx+∫abf2(x)dx\\int_{a}^{b}{(f_1(x) + f_2(x)) dx} =\n\\int_{a}^{b}{f_1(x) dx} + \\int_{a}^{b}{f_2(x) dx}∫ab​(f1​(x)+f2​(x))dx=∫ab​f1​(x)dx+∫ab​f2​(x)dx\n\nДоказательство\n\nДоказательство аналогично доказательству предыдущего свойства.\n\nСравнение функций\n\nПусть f(x),g(x)f(x), g(x)f(x),g(x) на [a,b][a,b][a,b] удовлетворяют неравенству f(x)≤g(x)f(x) \\le g(x)f(x)≤g(x).\n\nТогда:\n\n∫abf(x)dx≤∫abg(x)dx\\int_{a}^{b}{f(x) dx} \\le \\int_{a}^{b}{g(x) dx}∫ab​f(x)dx≤∫ab​g(x)dx\n\nДоказательство\n\nРассмотрим f(x)−g(x)f(x) - g(x)f(x)−g(x) на [a,b][a,b][a,b]: f(x)−g(x)≥0f(x) - g(x) \\ge 0f(x)−g(x)≥0\n\nТогда:\n\n∫ab(g(x)−f(x))dx=Sкрив.трапец.≥0⇒∫ab(g(x)−f(x))dx≥0\\int_{a}^{b}{(g(x) - f(x)) dx} =\nS_{крив. трапец.} \\ge 0 \\\\\n\\Rightarrow \\int_{a}^{b}{(g(x) - f(x)) dx} \\ge 0∫ab​(g(x)−f(x))dx=Sкрив.трапец.​≥0⇒∫ab​(g(x)−f(x))dx≥0\n\nПо второму свойству:\n\n∫abg(x)dx−∫abf(x)dx≥0\\int_{a}^{b}{g(x) dx} - \\int_{a}^{b}{f(x) dx} \\ge 0∫ab​g(x)dx−∫ab​f(x)dx≥0\n\nТо есть:\n\n∫abg(x)dx≥∫abf(x)dx\\int_{a}^{b}{g(x) dx} \\ge \\int_{a}^{b}{f(x) dx}∫ab​g(x)dx≥∫ab​f(x)dx\n\nОписанный прямоугольник\n\nПуть mmm, MMM - соответственно наименьшее и наибольшее значение f(x)f(x)f(x) на [a,b][a, b][a,b]\n\nТогда:\n\nm(b−a)≤∫abf(x)dx≤M(b−a)m(b - a) \\le\n\\int_{a}^{b}{f(x) dx} \\le\nM(b-a)m(b−a)≤∫ab​f(x)dx≤M(b−a)\n\nДоказательство\n\nПоскольку m≤f(x)≤Mm \\le f(x) \\le Mm≤f(x)≤M, ∫abmdx≤∫abf(x)dx≤∫abMdx\\int_{a}^{b}{mdx} \\le \\int_{a}^{b}{f(x) dx} \\le \\int_{a}^{b}{Mdx}∫ab​mdx≤∫ab​f(x)dx≤∫ab​Mdx.\n\nm∫abdx≤∫abf(x)dx≤M∫abdxm \\int_{a}^{b}{dx} \\le \\int_{a}^{b}{f(x) dx} \\le M \\int_{a}^{b}{dx}m∫ab​dx≤∫ab​f(x)dx≤M∫ab​dx\n\n∫abdx=b−a\\int_{a}^{b}{dx} = b - a∫ab​dx=b−a\n\nСвойство доказано.\n\nГеометрический смысл\n\n\n\nSaADb≤SABab≤SACBbS_{aADb} \\le S_{ABab} \\le S_{ACBb}SaADb​≤SABab​≤SACBb​\n\nТеорема о среднем\n\nНа промежутке [a,b][a,b][a,b] найдётся хотя-бы одна точка ξ\\xiξ такая, что интеграл равен (b−a)f(ξ)(b-a)f(\\xi)(b−a)f(ξ).\n\n∫abf(x)dx=(b−a)f(ξ),ξ∈[a,b]\\int_{a}^{b}{f(x) dx} = (b-a)f(\\xi), \\xi \\in [a, b]∫ab​f(x)dx=(b−a)f(ξ),ξ∈[a,b]\n\nГеометрический смысл\n\n\n\nНа данном графике красные заштрихованные площади равны и компенсируют друг друга (точка ξ\\xiξ совершенно не обязательно находится посередине между aaa и bbb).\n\nСмена пределов интегрирования\n\n∫abf(x)dx=−∫baf(x)dx\\int_{a}^{b}{f(x) dx} = - \\int_{b}^{a}{f(x) dx}∫ab​f(x)dx=−∫ba​f(x)dx\n\nОдинаковые пределы интегрирования\n\n∫aaf(x)dx=0\\int_{a}^{a}{f(x) dx} = 0∫aa​f(x)dx=0\n\nРазбиение на части\n\nДля любых a,b,ca, b, ca,b,c справедливо следующее:\n\n∫abf(x)dx=∫acf(x)dx+∫cbf(x)dx\\int_{a}^{b}{f(x) dx} =\n\\int_{a}^{c}{f(x) dx} + \\int_{c}^{b}{f(x) dx}∫ab​f(x)dx=∫ac​f(x)dx+∫cb​f(x)dx\n",
      "url": "/math/int/opr/"
    },{
      
      "title": "Интегрирование по частям",
      "description": "Интегирование по частям..\n",
      "content": "Содержание\n\n  Формула\n  Как получилась эта формула?\n  Интегралы, берущиеся по частям    \n      1 род\n      2 род\n    \n  \n  Примеры    \n      Пример 1\n      Пример 2\n      Пример 3\n    \n  \n\n\nФормула\n\n∫udv=uv−∫vdu\\int udv = uv - \\int vdu∫udv=uv−∫vdu\n\nКак получилась эта формула?\n\nРассмотрим следующий дифференциал: d(uv)d(uv)d(uv)\n\nКак известно, d(uv)=vdu+udvd(uv) = vdu + udvd(uv)=vdu+udv (производная произведения, записанная с помощью дифференциалов).\n\nПроинтегрируем: ∫d(uv)=∫vdu+∫udv\\int d(uv) = \\int vdu + \\int udv∫d(uv)=∫vdu+∫udv\n\nПо 1 свойству ∫d(uv)=uv\\int d(uv) = uv∫d(uv)=uv\n\nСледовательно, ∫udv=uv−∫vdu\\int udv = uv - \\int vdu∫udv=uv−∫vdu\n\nИнтегралы, берущиеся по частям\n\n1 род\n\n∫P(x)sin⁡βxdx\\int{P(x)\\sin{\\beta x} dx}∫P(x)sinβxdx\n\n∫P(x)cos⁡βxdx\\int{P(x)\\cos{\\beta x} dx}∫P(x)cosβxdx\n\n∫P(x)aβxdx\\int{P(x)a^{\\beta x} dx}∫P(x)aβxdx\n\n∫P(x)eβxdx\\int{P(x)e^{\\beta x} dx}∫P(x)eβxdx\n\nВ данных интегралах за uuu нужно брать многочлен P(x)P(x)P(x), а в качестве dvdvdv нужно брать всё остальное, то есть функцию и dxdxdx.\n\n2 род\n\n∫arcsinxP(x)dx\\int{arcsin{x} P(x) dx}∫arcsinxP(x)dx\n\n∫arctgxP(x)dx\\int{arctg{x} P(x) dx}∫arctgxP(x)dx\n\n∫log⁡axP(x)dx\\int{\\log_a{x} P(x) dx}∫loga​xP(x)dx\n\n∫ln⁡(x)nP(x)dx\\int{\\ln(x)^n P(x) dx}∫ln(x)nP(x)dx\n\nВ данных интегралах за dvdvdv следует брать многочлен P(x)dxP(x) dxP(x)dx, а в качестве uuu нужно брать функцию.\n\nПримеры\n\nПример 1\n\nРешим интеграл ∫x3xdx\\int{x 3^x dx}∫x3xdx.\n\n∫x3xdx=[u=xdu=dxdv=3xdxv=3xln⁡3]=x3xln⁡3−∫3xln⁡3dx=x3xln⁡3−3x(ln⁡3)2+C\\int{x 3^x dx} = \\left[ \\begin{array}{ll} u=x &amp; du = dx \\\\ dv = 3^{x}dx &amp; v=\\frac{3^x}{\\ln{3}} \\end{array} \\right] = \\frac{x 3^x}{\\ln{3}} - \\int{\\frac{3^x}{\\ln{3}} dx} = \\frac{x 3^x}{\\ln{3}} - \\frac{3^x}{(\\ln{3})^2} + C∫x3xdx=[u=xdv=3xdx​du=dxv=ln33x​​]=ln3x3x​−∫ln33x​dx=ln3x3x​−(ln3)23x​+C\n\nПример 2\n\nРешим интеграл ∫ln⁡xdx\\int{\\ln{x} dx}∫lnxdx\n\n∫ln⁡xdx=[u=ln⁡xdu=dxxdv=dxv=x]=xln⁡x−∫xdxx=xln⁡x−x+C\\int{\\ln{x} dx} = \\left[ \\begin{array}{ll} u=\\ln{x} &amp; du = \\frac{dx}{x} \\\\ dv = dx &amp; v=x \\end{array} \\right] = x \\ln{x} - \\int{\\frac{xdx}{x}} = x \\ln{x} - x + C∫lnxdx=[u=lnxdv=dx​du=xdx​v=x​]=xlnx−∫xxdx​=xlnx−x+C\n\nПример 3\n\nРешим интеграл ∫x3+2x2+3x+3x4e−xdx\\int{\\frac{x^3+2x^2+3x+3}{x^4} e^{-x} dx}∫x4x3+2x2+3x+3​e−xdx\n\nРазложим на сумму интегралов.\n\n∫x3+2x2+3x+3x4e−xdx=∫e−xxdx+2∫e−xx2dx+3∫e−xx3dx+3∫e−xx4dx\\int{\\frac{x^3+2x^2+3x+3}{x^4} e^{-x} dx} = \n\\int{\\frac{e^{-x}}{x}dx} +\n2 \\int{\\frac{e^{-x}}{x^2} dx} +\n3 \\int{\\frac{e^{-x}}{x^3} dx} +\n3 \\int{\\frac{e^{-x}}{x^4} dx}∫x4x3+2x2+3x+3​e−xdx=∫xe−x​dx+2∫x2e−x​dx+3∫x3e−x​dx+3∫x4e−x​dx\n\nИнтегрируем первый интеграл в получившейся сумме по частям.\n\n∫e−xxdx=[u=1xdu=−dxx2dv=e−xdxv=−e−x]=−e−xx−∫e−xx2dx\\int{\\frac{e^{-x}}{x} dx} = \\left[ \\begin{array}{ll} u=\\frac{1}{x} &amp; du = - \\frac{dx}{x^2} \\\\ dv = e^{-x} dx &amp; v=-e^{-x} \\end{array} \\right] =\n-\\frac{e^{-x}}{x} - \\int{\\frac{e^{-x}}{x^2} dx}∫xe−x​dx=[u=x1​dv=e−xdx​du=−x2dx​v=−e−x​]=−xe−x​−∫x2e−x​dx\n\nЗамечаем, что получившийся интеграл совпадает со вторым слагаемым в разложении исходного интеграла на сумму.\n\nБерём этот интеграл по частям ещё раз.\n\n∫e−xx2dx=[u=1x2du=−2x3dxdv=e−xdxv=−e−x]=−e−xx2−2∫e−xx3dx\\int{\\frac{e^{-x}}{x^2} dx} = \\left[ \\begin{array}{ll} u=\\frac{1}{x^2} &amp; du = - \\frac{2}{x^3}dx \\\\ dv = e^{-x} dx &amp; v=-e^{-x} \\end{array} \\right] =\n-\\frac{e^{-x}}{x^2} - 2\\int{\\frac{e^{-x}}{x^3} dx}∫x2e−x​dx=[u=x21​dv=e−xdx​du=−x32​dxv=−e−x​]=−x2e−x​−2∫x3e−x​dx\n\nОпять же, получившийся интеграл совпадает с третьим слагаемым в разложении исходного интеграла на сумму.\n\nБерём этот интеграл по частям ещё раз.\n\n∫e−xx3dx=[u=1x3du=−3x4dxdv=e−xdxv=−e−x]=−e−xx3−3∫e−xx4dx\\int{\\frac{e^{-x}}{x^3} dx} = \\left[ \\begin{array}{ll} u=\\frac{1}{x^3} &amp; du = - \\frac{3}{x^4}dx \\\\ dv = e^{-x} dx &amp; v=-e^{-x} \\end{array} \\right] =\n-\\frac{e^{-x}}{x^3} - 3\\int{\\frac{e^{-x}}{x^4} dx}∫x3e−x​dx=[u=x31​dv=e−xdx​du=−x43​dxv=−e−x​]=−x3e−x​−3∫x4e−x​dx\n\nМы видим, что чем дальше мы интегрируем по частям, тем больше растёт степень xxx.\n\nПолучившийся интеграл также совпадает с последним слагаемым в разложении исходного интеграла на сумму.\n\nОбозначим буквой III следующий интеграл:\n\nI=∫e−xx4dxI = \\int{\\frac{e^{-x}}{x^4} dx}I=∫x4e−x​dx\n\nТогда:\n\n∫e−xx3dx=−e−xx3−3I\\int{\\frac{e^{-x}}{x^3} dx} =\n-\\frac{e^{-x}}{x^3} - 3I∫x3e−x​dx=−x3e−x​−3I\n\n∫e−xx2dx=−e−xx2−2(−e−xx3−3I)=−e−xx2+2e−xx3+6I\\int{\\frac{e^{-x}}{x^2} dx} =\n-\\frac{e^{-x}}{x^2} - 2(-\\frac{e^{-x}}{x^3} - 3I) =\n-\\frac{e^{-x}}{x^2} + \\frac{2e^{-x}}{x^3} + 6I∫x2e−x​dx=−x2e−x​−2(−x3e−x​−3I)=−x2e−x​+x32e−x​+6I\n\n∫e−xxdx=−e−xx−(−e−xx2+2e−xx3+6I)=−e−xx+e−xx2−2e−xx3−6I\\int{\\frac{e^{-x}}{x} dx} =\n-\\frac{e^{-x}}{x}\n-(-\\frac{e^{-x}}{x^2} + \\frac{2e^{-x}}{x^3} + 6I) =\n-\\frac{e^{-x}}{x} + \\frac{e^{-x}}{x^2} - 2\\frac{e^{-x}}{x^3} - 6I∫xe−x​dx=−xe−x​−(−x2e−x​+x32e−x​+6I)=−xe−x​+x2e−x​−2x3e−x​−6I\n\nВернёмся к исходному интегралу.\n\n∫x3+2x2+3x+3x4e−xdx=−e−xx+e−xx2−2e−xx3−6I+2(−e−xx2+2e−xx3+6I)+3(−e−xx3−3I)+3I\\int{\\frac{x^3+2x^2+3x+3}{x^4} e^{-x} dx} = \\\\\n-\\frac{e^{-x}}{x} + \\frac{e^{-x}}{x^2} - 2\\frac{e^{-x}}{x^3} - 6I\n\n  2(-\\frac{e^{-x}}{x^2} + 2\\frac{e^{-x}}{x^3} + 6I)\n  3(-\\frac{e^{-x}}{x^3} - 3I) + 3I&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;∫x4x3+2x2+3x+3​e−xdx=−xe−x​+x2e−x​−2x3e−x​−6I+2(−x2e−x​+2x3e−x​+6I)+3(−x3e−x​−3I)+3I&lt;/span&gt;&lt;/span&gt;\n\n\nУпрощаем полученное выражение - при этом все III сокращаются.\n\nТаким образом, получаем ответ:\n\n∫x3+2x2+3x+3x4e−xdx=−e−xx−e−xx2−e−xx3+C\\int{\\frac{x^3+2x^2+3x+3}{x^4} e^{-x} dx} =\n-\\frac{e^{-x}}{x} - \\frac{e^{-x}}{x^2} - \\frac{e^{-x}}{x^3} + C∫x4x3+2x2+3x+3​e−xdx=−xe−x​−x2e−x​−x3e−x​+C\n",
      "url": "/math/int/parts/"
    },{
      
      "title": "Posts",
      
      "content": "\n",
      "url": "/posts/"
    },{
      
      "title": "Projects",
      "description": "Most of my open-source projects are listed on this page. Every project has a link to a GitHub repo with all the details and the source code.\n",
      "content": "\n",
      "url": "/projects/"
    },{
      
      "title": "Замена переменной",
      "description": "Метод интегрирования заменой переменной\n",
      "content": "Содержание\n\n  Определение\n\n\nОпределение\n\nВо многих случаях удаётся упростить интеграл с помощью замены переменной на новую функцию x=φ(t)x = \\varphi(t)x=φ(t), где φ(t)\\varphi(t)φ(t) - непрерывна, монотонна и имеет непрерывную производную.\n\nТогда имеет место формула замены переменной в неопределённом интеграле.\n\n∫f(x)dx=∫f(φ(t))φ′(t)dt\\int{f(x)dx} = \\int{f(\\varphi(t)) \\varphi&#x27;(t) dt}∫f(x)dx=∫f(φ(t))φ′(t)dt\n",
      "url": "/math/int/replace/"
    },{
      
      "title": "Resume",
      "description": "Alexander Mayorov’s resume as a software engineer.\n",
      "content": "\n",
      "url": "/resume/"
    },{
      
      "title": "Положительные ряды",
      "description": "Положительные ряды: определение, признаки сходимости.\n",
      "content": "Содержание\n\n  Положительный ряд\n  Теорема о сходимости    \n      Доказательство        \n          Необходимость\n          Достаточность\n        \n      \n    \n  \n  Признаки сходимости    \n      Признак сравнения        \n          Доказательство\n        \n      \n      Предельный признак сравнения        \n          Доказательство\n        \n      \n    \n  \n\n\nПоложительный ряд\n\nРяд называется положительным, если an≥0a_n \\ge 0an​≥0 для любого nnn.\n\nПоследовательность частичных сумм в таких рядах является монотонно возрастающей последовательностью.\n\nSn+1=Sn+an+1≥SnS_{n+1} = S_n + a_{n+1} \\ge S_nSn+1​=Sn​+an+1​≥Sn​\n\nТеорема о сходимости\n\nДля того, чтобы положительный ряд сходился, необходимо и достаточно, чтобы последовательность частичных сумм была ограниченной сверху.\n\nДоказательство\n\nНеобходимость\n\nПусть ряд сходится. Тогда существует предел последовательности частичных сумм, равный конечному числу SSS.\n\nЕсли предел монотонно возрастающей последовательности равен конечному числу, эта последовательность ограничена сверху.\n\nТо есть SnS_nSn​ ограничена сверху, Sn≤SS_n \\le SSn​≤S.\n\nДостаточность\n\nПусть Sn≤SS_n \\le SSn​≤S, SnS_nSn​ - монотонно возрастает.\n\nТогда, по теореме, существует предел последовательности частичных сумм, равный SSS, а значит, ряд сходится.\n\nПризнаки сходимости\n\nПризнак сравнения\n\nПусть ряды ∑n=1∞an\\sum_{n=1}^{\\infty}{a_n}∑n=1∞​an​ и ∑n=1∞bn\\sum_{n=1}^{\\infty}{b_n}∑n=1∞​bn​ положительные и начиная с некоторого n≥Nn \\ge Nn≥N выполняется неравенство: an≤bna_n \\le b_nan​≤bn​.\n\nТогда:\n\n\n  Если ∑n=1∞bn\\sum_{n=1}^{\\infty}{b_n}∑n=1∞​bn​ сходится, то ∑n=1∞an\\sum_{n=1}^{\\infty}{a_n}∑n=1∞​an​ сходится.\n  Если ∑n=1∞an\\sum_{n=1}^{\\infty}{a_n}∑n=1∞​an​ расходится, то ∑n=1∞bn\\sum_{n=1}^{\\infty}{b_n}∑n=1∞​bn​ расходится.\n\n\nДоказательство\n\nОбозначим nnn-ые суммы частичных рядов AnA_nAn​ и BnB_nBn​: An≤BnA_n \\le B_nAn​≤Bn​\n\nПусть ∑n=1∞bn\\sum_{n=1}^{\\infty}{b_n}∑n=1∞​bn​ сходится. Тогда Bn≤BB_n \\le BBn​≤B.\n\nСледовательно, An≤Bn≤BA_n \\le B_n \\le BAn​≤Bn​≤B, то есть AnA_nAn​ ограничена.\n\nЗначит, ∑n=1∞an\\sum_{n=1}^{\\infty}{a_n}∑n=1∞​an​ сходится.\n\nПусть ∑n=1∞an\\sum_{n=1}^{\\infty}{a_n}∑n=1∞​an​ расходится.\n\nПредельный признак сравнения\n\nПусть ∑n=1∞an\\sum_{n=1}^{\\infty}{a_n}∑n=1∞​an​, ∑n=1∞bn\\sum_{n=1}^{\\infty}{b_n}∑n=1∞​bn​ - положительные ряды.\n\nЕсли существует предел отношения ana_nan​ к bnb_nbn​, не равный нулю, ряды ∑n=1∞an\\sum_{n=1}^{\\infty}{a_n}∑n=1∞​an​, ∑n=1∞bn\\sum_{n=1}^{\\infty}{b_n}∑n=1∞​bn​ называются эквивалентными.\n∃lim⁡n→∞anbn=q≠0\\exists \\lim_{n \\to \\infty}{\\frac{a_n}{b_n}} = q \\ne 0∃limn→∞​bn​an​​=q​=0\nЭквивалентные ряды одинаковы в плане сходимости, то есть они либо сходятся одновременно, либо расходятся одновременно.\n\nДоказательство\n\nИзвестно, что существует предел отношения ana_nan​ к bnb_nbn​. Распишем определение этого предела.\n∀ε&gt;0,ε&lt;q ∃Nε:∀n&gt;Nε⇒∣anbn−q∣&lt;ε\\forall \\varepsilon &gt; 0, \\varepsilon &lt; q \\space \\exists N_\\varepsilon :\n\\forall n &gt; N_\\varepsilon \\Rightarrow \\vert \\frac{a_n}{b_n} - q \\vert &lt; \\varepsilon∀ε&gt;0,ε&lt;q ∃Nε​:∀n&gt;Nε​⇒∣bn​an​​−q∣&lt;ε\nРаскроем модуль:\n∣anbn−q∣&lt;ε⇔−ε&lt;anbn−q&lt;ε\\vert \\frac{a_n}{b_n} - q \\vert &lt; \\varepsilon \\Leftrightarrow\n-\\varepsilon &lt; \\frac{a_n}{b_n} - q &lt; \\varepsilon∣bn​an​​−q∣&lt;ε⇔−ε&lt;bn​an​​−q&lt;ε\nКо всем частям неравенства прибавим qqq:\nq−ε&lt;anbn&lt;ε+qq - \\varepsilon &lt; \\frac{a_n}{b_n} &lt; \\varepsilon + qq−ε&lt;bn​an​​&lt;ε+q\nУмножим на bnb_nbn​.\n(q−ε)bn&lt;an&lt;(q+ε)bn(q - \\varepsilon)b_n &lt; a_n &lt; (q + \\varepsilon)b_n(q−ε)bn​&lt;an​&lt;(q+ε)bn​\n",
      "url": "/math/int/series-positive/"
    },{
      
      "title": "Ряды",
      "description": "Ряды: определение, числовой ряд, геометрический ряд, свойства.\n",
      "content": "Содержание\n\n  Числовой ряд\n  Частичная сумма ряда\n  Гармонический ряд\n  Простейшие ряды    \n      Единичный ряд\n      Знакочередующийся единичный ряд\n    \n  \n  Геометрический ряд    \n      Сходимость        \n          Доказательство\n        \n      \n    \n  \n  Свойства сходящихся рядов    \n      Умножение на число\n      Сумма общих членов\n      Принцип отбрасывания        \n          Доказательство\n        \n      \n    \n  \n  Необходимое условие сходимости ряда\n  Достаточное условие расходимости ряда    \n      Пример\n    \n  \n\n\nЧисловой ряд\n\nПусть a1,a2,…,an,…a_1, a_2, \\dots, a_n, \\dotsa1​,a2​,…,an​,… - последовательность чисел.\n\nТогда сумма a1+a2+⋯+an+…a_1 + a_2 + \\dots + a_n + \\dotsa1​+a2​+⋯+an​+… называется числовым рядом, где a1,a2,…a_1, a_2, \\dotsa1​,a2​,… называются членами ряда, а ana_nan​ - общий член ряда.\n\nРяд считается заданным, если определён общий член ряда как функция его номера nnn: an=f(n)a_n = f(n)an​=f(n).\n\nРяд обозначается:\n\n∑n=1∞an=∑n=1∞f(n)\\sum_{n=1}^{\\infty}{a_n} = \\sum_{n=1}^{\\infty}{f(n)}n=1∑∞​an​=n=1∑∞​f(n)\n\nЧастичная сумма ряда\n\nnnn-ой частичной суммой ряда называется сумма первых nnn членов ряда.\n\nПостроим последовательность частичных сумм ряда.\n\nS1=a1S2=a1+a2S3=a1+a2+a3⋯Sn=a1+a2+a3+⋯+anS_1 = a_1 \\\\\nS_2 = a_1 + a_2 \\\\\nS_3 = a_1 + a_2 + a_3 \\\\\n\\cdots \\\\\nS_n = a_1 + a_2 + a_3 + \\dots + a_nS1​=a1​S2​=a1​+a2​S3​=a1​+a2​+a3​⋯Sn​=a1​+a2​+a3​+⋯+an​\n\nЕсли существует конечный предел последовательности частичных сумм при n→∞n \\to \\inftyn→∞, то ряд ana_nan​ называется сходящимся.\n\nЕсли предел бесконечный или не существует, ряд называется расходящимся.\n\nЕсли ряд сходится, то он сходится к сумме ряда SSS:\n\n∑n=1∞an=S\\sum_{n = 1}^{\\infty}{a_n} = Sn=1∑∞​an​=S\n\nГармонический ряд\n\nГармоническим называется ряд:\n\n∑n=1∞1n=1+12+13+⋯+1n+…\\sum_{n = 1}^{\\infty}{\\frac{1}{n}} = 1 + \\frac{1}{2} + \\frac{1}{3} + \\dots + \\frac{1}{n} + \\dotsn=1∑∞​n1​=1+21​+31​+⋯+n1​+…\n\nЭтот ряд расходится.\n\nПростейшие ряды\n\nЕдиничный ряд\n\nРассмотрим ряд  1+1+1+…1 + 1 + 1 + \\dots1+1+1+….\n\nПостроим последовательность частичных сумм:\n\nS1=1S2=2S3=3…Sn=nS_1 = 1 \\\\\nS_2 = 2 \\\\\nS_3 = 3 \\\\\n\\dots \\\\\nS_n = nS1​=1S2​=2S3​=3…Sn​=n\n\nlim⁡n→∞Sn=lim⁡n→∞n=∞\\lim_{n \\to \\infty}{S_n} = \\lim_{n \\to \\infty}{n} = \\inftyn→∞lim​Sn​=n→∞lim​n=∞\n\nСледовательно, ряд расходится.\n\nЗнакочередующийся единичный ряд\n\nРассмотрим ряд  1−1+1−1+⋯+1−…1 - 1 + 1 - 1 + \\dots + 1 - \\dots1−1+1−1+⋯+1−….\n\nПостроим последовательность частичных сумм:\n\nS1=1S2=0S3=1S4=0…S_1 = 1 \\\\\nS_2 = 0 \\\\\nS_3 = 1 \\\\\nS_4 = 0 \\\\\n\\dotsS1​=1S2​=0S3​=1S4​=0…\n\nПредел SnS_nSn​ не существует, следовательно ряд расходится.\n\nГеометрический ряд\n\nГеометрический ряд представляет собой ряд, похожий на геометрическую прогрессию.\n\n∑n=0∞aqn=a+aq+aq2+⋯+aqn+…\\sum_{n = 0}^{\\infty}{a q^n} = a + aq + aq^2 + \\dots + aq^n + \\dotsn=0∑∞​aqn=a+aq+aq2+⋯+aqn+…\n\nСходимость\n\n∑n=0∞aqn\\sum_{n = 0}^{\\infty}{a q^n}n=0∑∞​aqn\n\nЭтот ряд сходится, если ∣q∣&lt;1\\vert q \\vert &lt; 1∣q∣&lt;1.\nЭтот ряд расходится, если ∣q∣≥1\\vert q \\vert \\ge 1∣q∣≥1.\n\nДоказательство\n\nSn=b1(1−qn)1−q=a(1−qn)1−qS_n = \\frac{b_1 (1 - q^n)}{1 - q} = \\frac{a (1 - q^n)}{1 - q}Sn​=1−qb1​(1−qn)​=1−qa(1−qn)​\n\nРассмотрим 3 случая:\n\nПусть ∣q∣&lt;1\\vert q \\vert &lt; 1∣q∣&lt;1. Тогда qn→0q ^ n \\to 0qn→0 при n→∞n \\to \\inftyn→∞. Следовательно:\n\nlim⁡n→∞a(1−qn)1−q=lim⁡n→∞a1−q\\lim_{n \\to \\infty}{\\frac{a (1 - q^n)}{1 - q}} =\n\\lim_{n \\to \\infty}{\\frac{a}{1 - q}}n→∞lim​1−qa(1−qn)​=n→∞lim​1−qa​\n\nПолучили конечное число, значит ряд сходится.\n\nПусть ∣q∣&gt;1\\vert q \\vert &gt; 1∣q∣&gt;1. Тогда qn→∞q^n \\to \\inftyqn→∞ при n→∞n \\to \\inftyn→∞. Следовательно:\n\nlim⁡n→∞a(1−qn)1−q=∞\\lim_{n \\to \\infty}{\\frac{a (1 - q^n)}{1 - q}} = \\inftyn→∞lim​1−qa(1−qn)​=∞\n\nПолучили бесконечность, значит ряд расходится.\n\nПусть ∣q∣=1\\vert q \\vert = 1∣q∣=1. Тогда мы получаем ряд a+a+a+…a + a + a + \\dotsa+a+a+….\n\nЭтот ряд расходится, так как предел последовательности частичных сумм равен ∞\\infty∞ (см пример).\n\nСвойства сходящихся рядов\n\nУмножение на число\n\nЕсли ряд умножить на число, не равное 000, его сходимость не изменится.\n\n∑n=1∞kan=k∑n=1∞an\\sum_{n = 1}^{\\infty}{ka_n} = k\\sum_{n = 1}^{\\infty}{a_n}n=1∑∞​kan​=kn=1∑∞​an​\n\nСумма общих членов\n\nПусть ряд ana_nan​ сходится к сумме AAA и ряд bnb_nbn​ сходится к сумме BBB (AAA и BBB - конечные числа).\n\n∑n=1∞an=A∑n=1∞bn=B\\sum_{n = 1}^{\\infty}{a_n} = A \\\\\n\\sum_{n = 1}^{\\infty}{b_n} = Bn=1∑∞​an​=An=1∑∞​bn​=B\n\nТогда ряд, составленный из суммы общих членов сходится к A+BA + BA+B:\n\n∑n=1∞(an+bn)=∑n=1∞an+∑n=1∞bn=A+B\\sum_{n = 1}^{\\infty}{(a_n + b_n)} =\n\\sum_{n = 1}^{\\infty}{a_n} + \\sum_{n = 1}^{\\infty}{b_n} = A + Bn=1∑∞​(an​+bn​)=n=1∑∞​an​+n=1∑∞​bn​=A+B\n\nПринцип отбрасывания\n\nРассмотрим следующий ряд:\n\n∑n=1∞an=a1+a2+a3+⋯+an+…\\sum_{n = 1}^{\\infty}{a_n} = a_1 + a_2 + a_3 + \\dots + a_n + \\dotsn=1∑∞​an​=a1​+a2​+a3​+⋯+an​+…\n\nМы можем отбросить определённое количество первых слагаемых ряда:\n\n∑n=k+1∞an=ak+1+ak+2+⋯+an+…\\sum_{n = k + 1}^{\\infty}{a_n} = a_{k+1} + a_{k+2} + \\dots + a_n + \\dotsn=k+1∑∞​an​=ak+1​+ak+2​+⋯+an​+…\n\nПолучившийся ряд называется kkk-ым остатком ряда.\n\nkkk-ый остаток ряда и сам ряд имеют одинаковую сходимость.\n\nДоказательство\n\nПусть ρn\\rho_nρn​ - nnn-ая частичная сумма остатка ряда.\n\nρn=ak+1+ak+2+⋯+ak+n=Sk+n−Sk\\rho_n = a_{k+1} + a_{k+2} + \\dots + a_{k+n} = S_{k+n} - S_kρn​=ak+1​+ak+2​+⋯+ak+n​=Sk+n​−Sk​\n\n(Sk+nS_{k+n}Sk+n​ - частичная сумма исходного ряда).\n\nПо условию ряд ana_nan​ сходится, а значит предел частичной суммы исходного ряда равен конечному числу SSS:\n\nlim⁡n→∞Sk+n=S\\lim_{n \\to \\infty}{S_{k + n}} = Sn→∞lim​Sk+n​=S\n\nТогда:\n\nlim⁡n→∞ρn=lim⁡n→∞(Sk+n−Sk)=S−Sk\\lim_{n \\to \\infty}{\\rho_n} = \\lim_{n \\to \\infty}{(S_{k+n} - S_k)} = S - S_kn→∞lim​ρn​=n→∞lim​(Sk+n​−Sk​)=S−Sk​\n\nSSS и SkS_kSk​ - конечные числа, значит ряд сходится.\n\nНеобходимое условие сходимости ряда\n\nЕсли ряд сходится, то an→0a_n \\to 0an​→0 при n→∞n \\to \\inftyn→∞, то есть lim⁡n→∞an=0\\lim_{n \\to \\infty}{a_n} = 0limn→∞​an​=0.\n\nЭто не является достаточным условием сходимости ряда, то есть нельзя сказать, что если общий член стремится к нулю, то ряд сходится.\n\nДостаточное условие расходимости ряда\n\nЕсли общий член не стремится к 000, ряд расходится.\n\nПример\n\nРассмотрим следующий ряд:\n\n∑n=0∞2n+32n+1\\sum_{n = 0}^{\\infty}{\\frac{2n + 3}{2n + 1}}n=0∑∞​2n+12n+3​\n\nlim⁡n→∞an=lim⁡n→∞2n+32n+1=[∞∞]=lim⁡n→∞22=1≠0\\lim_{n \\to \\infty}{a_n} = \\lim_{n \\to \\infty}{\\frac{2n + 3}{2n + 1}} = \\Big[\\frac{\\infty}{\\infty} \\Big] = \\lim_{n \\to \\infty}{\\frac{2}{2}} = 1 \\ne 0n→∞lim​an​=n→∞lim​2n+12n+3​=[∞∞​]=n→∞lim​22​=1​=0\n\nСледовательно, ряд расходится.\n",
      "url": "/math/int/series/"
    },{
      
      "title": "Сводка определений",
      "description": "Сводка определений по дифференциальному исчислению.\n",
      "content": "Содержание\n\n  Функция\n  Точная верхняя и нижняя границы\n  Предел функции по Коши\n  Предел функции по Гейне\n  Предел последовательности\n  Бесконечно малые функции\n  Бесконечно большие функции\n  Эквивалентные функции\n  Функции одного порядка\n  Непрерывная функция\n  Производная\n  Дифференциал\n  Касательная\n\n\nФункция\n\nПусть даны два множества: XXX и YYY.\n\nФункцией fff называется любое правило, которое каждому элементу множества XXX ставит в соответствие некоторый элемент множества YYY.\n\nТочная верхняя и нижняя границы\n\nЧисло MMM называется верхней границей множества AAA, если:\n\n∀x∈A:x≤M\\forall x \\in A : x \\le M∀x∈A:x≤M\n\nЧисло MMM называется точной верхней границей множества AAA, если оно является наименьшей из верхних границ:\n\nsup⁡A=min⁡M\\sup{A} = \\min{M}supA=minM\n\nТочная верхняя граница называется супремумом (супремум).\n\nЧисло mmm называется нижней границей множества AAA, если:\n\n∀x∈A:x≥m\\forall x \\in A : x \\ge m∀x∈A:x≥m\n\nЧисло mmm называется точной нижней границей множества AAA, если оно является наибольшей из нижних границ:\n\ninf⁡A=max⁡m\\inf{A} = \\max{m}infA=maxm\n\nТочная верхняя граница называется инфимумом (инфимум).\n\nПредел функции по Коши\nЧисло AAA называется пределом функции f(x)f(x)f(x) в точке x0x_0x0​, то есть при x→x0x \\to x_0x→x0​ (xxx стремящемся к x0x_0x0​), если для любого ε≥0\\varepsilon \\ge 0ε≥0 существует δε≥0\\delta_{\\varepsilon} \\ge 0δε​≥0, зависящая от ε\\varepsilonε такая, что для любого x∈Xx \\in Xx∈X, такого что 0≤∣x−x0∣≤δε0 \\le |x - x_0| \\le \\delta_{\\varepsilon}0≤∣x−x0​∣≤δε​, выполняется неравенство ∣f(x)−A∣≤ε|f(x) - A| \\le \\varepsilon∣f(x)−A∣≤ε.\n\nlim⁡x→x0f(x)=A⇔∀ε&gt;0 ∃δε&gt;0:∀x∈X:0&lt;∣x−x0∣&lt;δε⇒∣f(x)−A∣&lt;ε\\lim_{x \\to x_0}{f(x)} = A \\Leftrightarrow \n\\forall \\varepsilon &gt; 0 \\space \\exists \\delta_{\\varepsilon} &gt; 0 : \\forall x \\in X : 0 &lt; |x - x_0| &lt; \\delta_{\\varepsilon} \\Rightarrow |f(x) - A| &lt; \\varepsilonx→x0​lim​f(x)=A⇔∀ε&gt;0 ∃δε​&gt;0:∀x∈X:0&lt;∣x−x0​∣&lt;δε​⇒∣f(x)−A∣&lt;ε\n\nПредел функции по Гейне\n\nЧисло AAA называется пределом функции f(x)f(x)f(x) в точке x0x_0x0​, если для любой последовательности {xn}n=1∞\\{x_n\\}_{n = 1}^{\\infty}{xn​}n=1∞​, такой что xn≠x0x_n \\ne x_0xn​​=x0​ для любого nnn, и последовательность xnx_nxn​ стремится к x0x_0x0​ при n→∞n \\to \\inftyn→∞, следует, что и последовательность {f(xn)}n=1∞\\{f(x_n)\\}_{n=1}^{\\infty}{f(xn​)}n=1∞​ стремится к AAA при n→∞n \\to \\inftyn→∞.\n\nlim⁡x→x0f(x)=A⇔∀{xn},xn≠0:xn→x0,n→∞⇒f(xn)→A\\lim_{x \\to x_0}{f(x)} = A \\Leftrightarrow \\forall \\{x_n\\}, x_n \\ne 0 : x_n \\to x_0, n \\to \\infty \\Rightarrow f(x_n) \\to Ax→x0​lim​f(x)=A⇔∀{xn​},xn​​=0:xn​→x0​,n→∞⇒f(xn​)→A\n\nПредел последовательности\nЧисло AAA называется пределом последовательности {xn}n=1∞\\{x_n\\}_{n=1}^{\\infty}{xn​}n=1∞​ если для любого ε&gt;0\\varepsilon &gt; 0ε&gt;0 существует число NNN, зависящее от ε\\varepsilonε, такое что для любого натурального числа n&gt;Nn &gt; Nn&gt;N будет выполняться неравенство ∣xn−A∣&lt;ε|x_n - A| &lt; \\varepsilon∣xn​−A∣&lt;ε.\n\nБесконечно малые функции\n\nФункция f(x)f(x)f(x) называется бесконечно малой при x→x0x \\to x_0x→x0​ по отношению к функции g(x)g(x)g(x), если:\n\nlim⁡x→x0f(x)g(x)=0\\lim_{x \\to x_0}{\\frac{f(x)}{g(x)}} = 0x→x0​lim​g(x)f(x)​=0\n\nФункция f(x)f(x)f(x) называется бесконечно малой (то есть бесконечно малой по отношению к функции, тождественно равной единице) при x→x0x \\to x_0x→x0​, если:\n\nlim⁡x→x0f(x)=0\\lim_{x \\to x_0}{f(x)} = 0x→x0​lim​f(x)=0\n\nБесконечно большие функции\n\nФункция f(x)f(x)f(x) называется бесконечно большой при x→x0x \\to x_0x→x0​ по отношению к функции g(x)g(x)g(x), если:\n\nlim⁡x→x0f(x)g(x)=∞\\lim_{x \\to x_0}{\\frac{f(x)}{g(x)}} = \\inftyx→x0​lim​g(x)f(x)​=∞\n\nЭквивалентные функции\n\nФункции f(x)f(x)f(x) и g(x)g(x)g(x) называются эквивалентными при x→x0x \\to x_0x→x0​, если:\n\nlim⁡x→x0f(x)g(x)=1⇔f(x)∼g(x),x→x0\\lim_{x \\to x_0}{\\frac{f(x)}{g(x)}} = 1 \\Leftrightarrow f(x) \\sim g(x), x \\to x_0x→x0​lim​g(x)f(x)​=1⇔f(x)∼g(x),x→x0​\n\nФункции одного порядка\n\nФункции f(x)f(x)f(x) и g(x)g(x)g(x) называются функциями одного порядка при x→x0x \\to x_0x→x0​, если:\n\nlim⁡x→x0f(x)g(x)=M,M≠0,M≠∞\\lim_{x \\to x_0}{\\frac{f(x)}{g(x)}} = M, M \\ne 0, M \\ne \\inftyx→x0​lim​g(x)f(x)​=M,M​=0,M​=∞\n\nНепрерывная функция\nФункция f(x)f(x)f(x) называется непрерывной в точке x0x_0x0​, если для любого ε&gt;0\\varepsilon &gt; 0ε&gt;0 существует δε&gt;0\\delta_{\\varepsilon} &gt; 0δε​&gt;0, такая что для любого xxx, если выполняется условие ∣x−x0∣&lt;δε|x - x_0| &lt; \\delta_{\\varepsilon}∣x−x0​∣&lt;δε​ то выполняется условие ∣f(x)−f(x0)∣&lt;ε|f(x) - f(x_0)| &lt; \\varepsilon∣f(x)−f(x0​)∣&lt;ε.\n\n∀ε&gt;0 ∃δε:∀x,∣x−x0∣&lt;δε⇒∣f(x)−f(x0)∣&lt;ε\\forall \\varepsilon &gt; 0 \\space \\exists \\delta_{\\varepsilon} : \\forall x, |x - x_0| &lt; \\delta_{\\varepsilon} \\Rightarrow |f(x) - f(x_0)| &lt; \\varepsilon∀ε&gt;0 ∃δε​:∀x,∣x−x0​∣&lt;δε​⇒∣f(x)−f(x0​)∣&lt;ε\n\nФактически это определение предела, равного f(x0)f(x_0)f(x0​).\n\nЛюбая дифференцируемая функция является непрерывной во всех точках. Не всякая непрерывная функция является дифференцируемой во всех точках.\n\nФункция f(x)f(x)f(x) называется непрерывной на множестве XXX, если она непрерывна в любой точке x0x_0x0​ множества XXX.\n\nПроизводная\n\nЕсли следующий предел существует, то он называется производной f′(x)f&#x27;(x)f′(x).\n\nf′(x)=lim⁡Δx→0ΔyΔx=lim⁡Δx→0f(x+Δx)−f(x)Δxf&#x27;(x) = \\lim_{\\Delta x \\to 0}{\\frac{\\Delta y}{\\Delta x}} = \\lim_{\\Delta x \\to 0}{\\frac{f(x + \\Delta x) - f(x)}{\\Delta x}}f′(x)=Δx→0lim​ΔxΔy​=Δx→0lim​Δxf(x+Δx)−f(x)​\n\nДифференциал\n\nПусть функция f(x)f(x)f(x) такова, что её приращение в точке x0x_0x0​ может быть представлено в виде:\n\nΔf(x0)=A⋅Δx+β(x0,Δx)\\Delta f(x_0) = A \\cdot \\Delta x + \\beta(x_0, \\Delta x)Δf(x0​)=A⋅Δx+β(x0​,Δx)\n\nA=A(x0)A = A(x_0)A=A(x0​) - некое число.\n\nПусть также справедливо, что:\n\nlim⁡Δx→0β(x0,Δx)Δx=0\\lim_{\\Delta x \\to 0}{\\frac{\\beta(x_0, \\Delta x)}{\\Delta x}} = 0Δx→0lim​Δxβ(x0​,Δx)​=0\n\nТогда функция f(x)f(x)f(x) называется дифференцируемой в точке x0x_0x0​, выражение A⋅ΔxA \\cdot \\Delta xA⋅Δx называется дифференциалом функции f(x)f(x)f(x) в точке x0x_0x0​.\n\nДифференциал функции - это линейная часть приращения функции.\n\nКасательная\n\nПусть на кривой выбраны точка MMM и точка M1M_1M1​, а также проведена прямая (секущая) MM1M M_1MM1​. Если перемещать точку M1M_1M1​ вдоль по кривой, то прямая MM1M M_1MM1​ будет вращаться вокруг точки MMM. Касательной к кривой в точке MMM называется предельное положение MTMTMT секущей MM1M M_1MM1​, когда точка M1M_1M1​ вдоль по кривой стремится к совпадению с MMM.\n\nУравнение касательной к графику функции f(x)f(x)f(x) в точке x0x_0x0​:\n\ny−y0=f′(x0)(x−x0)y - y_0 = f&#x27;(x_0)(x - x_0)y−y0​=f′(x0​)(x−x0​)\n\nгде y0=f(x0)y_0 = f(x_0)y0​=f(x0​).\n",
      "url": "/math/diff/summary/"
    },{
      
      "title": "Таблица интегралов",
      "description": "Таблица интегралов - обращение таблицы производных. Формулы длинного логарифма, высокого логарифма.\n",
      "content": "Содержание\n\n  Обращение таблицы производных\n  Основные табличные интегралы    \n      Высокий логарифм\n      Длинный логарифм\n    \n  \n\n\nОбращение таблицы производных\n\n∫dx=x+C\\int dx = x + C∫dx=x+C\n\n∫0dx=C\\int 0dx = C∫0dx=C\n\n∫xmdx=xm+1m+1+C,m≠−1\\int x^mdx = \\frac{x^{m+1}}{m+1} + C, m \\neq -1∫xmdx=m+1xm+1​+C,m​=−1\n\n∫dxx=ln⁡∣x∣+C\\int \\frac{dx}{x} = \\ln|x| + C∫xdx​=ln∣x∣+C\n\n∫cos⁡xdx=sin⁡x+C\\int \\cos x dx = \\sin x + C∫cosxdx=sinx+C\n\n∫sin⁡xdx=−cos⁡x+C\\int \\sin x dx = -\\cos x + C∫sinxdx=−cosx+C\n\n∫dx1+x2=arctg(x)+C=−arcctg(x)+C\\int \\frac{dx}{1+x^2} = arctg(x) + C = -arcctg(x) + C∫1+x2dx​=arctg(x)+C=−arcctg(x)+C\n\n∫dx1−x2=arcsin(x)+C=−arccos(x)+C\\int \\frac{dx}{\\sqrt{1-x^2}} = arcsin(x) + C = -arccos(x) + C∫1−x2​dx​=arcsin(x)+C=−arccos(x)+C\n\n∫axdx=axln⁡a+C\\int a^xdx = \\frac{a^x}{\\ln a} + C∫axdx=lnaax​+C\n\n∫exdx=ex+C\\int e^x dx = e^x + C∫exdx=ex+C\n\n∫sec2(x)dx=∫dxcos⁡2x=tg(x)+C\\int sec^2(x)dx = \\int \\frac{dx}{\\cos^2 x} = tg(x) + C∫sec2(x)dx=∫cos2xdx​=tg(x)+C\n\n∫cosec2(x)dx=∫dxsin⁡2x=−ctg(x)+C\\int cosec^2(x)dx = \\int \\frac{dx}{\\sin^2x} = -ctg(x) + C∫cosec2(x)dx=∫sin2xdx​=−ctg(x)+C\n\n∫sh(x)dx=ch(x)+C\\int sh(x)dx = ch(x) + C∫sh(x)dx=ch(x)+C\n\n∫ch(x)dx=sh(x)+C\\int ch(x)dx = sh(x) + C∫ch(x)dx=sh(x)+C\n\n∫dxch2(x)=th(x)+C\\int \\frac{dx}{ch^2(x)} = th(x) + C∫ch2(x)dx​=th(x)+C\n\n∫dxsh2(x)=−cth(x)+C\\int \\frac{dx}{sh^2(x)} = -cth(x) + C∫sh2(x)dx​=−cth(x)+C\n\nОсновные табличные интегралы\n\n∫dxx2+a2=1aarctgxa+C\\int \\frac{dx}{x^2 + a^2} = \\frac{1}{a} arctg \\frac{x}{a} + C∫x2+a2dx​=a1​arctgax​+C\n\nВысокий логарифм\n\n∫dxx2−a2=12aln⁡∣x−ax+a∣+C\\int \\frac{dx}{x^2 - a^2} = \\frac{1}{2a}\\ln|\\frac{x-a}{x+a}| + C∫x2−a2dx​=2a1​ln∣x+ax−a​∣+C\n\nДлинный логарифм\n\n∫dxx2±a2=ln⁡∣x+x2±a2∣+C\\int \\frac{dx}{\\sqrt{x^2 \\pm a^2}} = \\ln|x + \\sqrt{x^2 \\pm a^2}| + C∫x2±a2​dx​=ln∣x+x2±a2​∣+C\n\n∫dxa2−x2=arcsinxa+C\\int \\frac{dx}{\\sqrt{a^2 - x^2}} = arcsin \\frac{x}{a} + C∫a2−x2​dx​=arcsinax​+C\n",
      "url": "/math/int/table/"
    }
  ], 
  "documents": [
    {
      "image": "../../assets/img/blog/call-stack-buffer-overflow.svg",
      "title": "Call Stack - buffer overflow vulnerability",
      "date": "2019-06-30 00:00:00 +0200",
      
      "content": "Buffer overflows are a kind of call stack vulnerability that occur when buffers are created on the stack, but accessed improperly. Buffer underruns are typically not so dangerous, because writing in the current stack frame or beyond the stack pointer will only affect local variables on that stack frame. On the other side, buffer overruns can allow the attacker to overwrite the return address and thus even modify the program’s behaviour.\n\nBuffer overflow\n\nC programmers often allocate buffers on the stack to handle user input. If the input reading logic is implemented incorrectly and has now buffer length checks, a underflow/overflow can happen. If the user input is long enouph, it will overwrite the saved ebp register of the previous stack frame and, what matters most, the return address.\n\n\n\nExample\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nvoid __attribute__((noinline)) fun(int a, int b, int c) {\n\t\n\tchar buffer[16] = {0};\n\t\n\tint* prevEbp = &amp;a - 2;\n\tint* ret = &amp;a - 1;\n\t\n\tprintf(\"Buffer start: %p Buffer start pointer address: %p\\n\", buffer, &amp;buffer);\n\tprintf(\"Previous EBP: %p Value: %d Value as hex: %x\\n\", prevEbp, *prevEbp, *prevEbp);\n\tprintf(\"Return address: %p Value: %x\\n\", ret, *ret);\n\tprintf(\"Buffer end: %p\\n\", buffer + 16);\n\t\n\tfflush(stdout);\n\t\n}\n\nint main() {\n\tprintf(\"Ptr size: %d bytes\\n\", sizeof(void*));\n\tfun(1, 2, 3)\n\treturn 0;\n}\n\n\nWe can calculate the return address position by taking addresses of the buffer and the function arguments. In this case we only take the pointer to the first argument, because it is added to the stack last. The previous base pointer size as well as the return address size are 4 bytes, so we can just subtract 1 (4 bytes) from the pointer to get the return address and 2 (8 bytes) to get the base pointer.\n\nWe can now compile the program with the -fno-stack-protector flag to disable stack protecting canary that gcc adds by default:\n\n$ gcc main.c -o viewret -fno-stack-protector\n\n\nBy running the program I got:\n\nPtr size: 4 bytes\nBuffer start: 0061FEE8 Buffer start pointer address: 0061FEE8\nPrevious EBP: 0061FF08 Value: 6422312 Value as hex: 61ff28\nReturn address: 0061FF0C Value: 401508\nBuffer end: 0061FEF8\n\n\nWe can easly alter the return address value now:\n\nvoid __attribute__((noinline)) fun(int a, int b, int c) {\n\t\n\tchar buffer[16] = {0};\n\t\n\tint* prevEbp = &amp;a - 2;\n\tint* ret = &amp;a - 1;\n\t\n\tprintf(\"Buffer start: %p Buffer start pointer address: %p\\n\", buffer, &amp;buffer);\n\tprintf(\"Previous EBP: %p Value: %d Value as hex: %x\\n\", prevEbp, *prevEbp, *prevEbp);\n\tprintf(\"Return address: %p Value: %x\\n\", ret, *ret);\n\tprintf(\"Buffer end: %p\\n\", buffer + 16);\n\t\n\tfflush(stdout);\n\t\n\t*ret = 0xcafeefac;\n\t\n}\n\n\nNow, if we run the program we will get a segmentation fault error because the function will try to jump back to the calee using an invalid address.\n\nWe can examine exactly how it works by running the GDB debugger:\n\n$ gdb viewret.exe\n\n\nOf course, we need to set the breakpoint at the fun function:\n\n(gdb) $ br fun\n\n\n[New Thread 3388.0x3368]\n[New Thread 3388.0x1a2c]\nPtr size: 4 bytes\n\nBreakpoint 1, 0x00401416 in fun ()\n\n\nBy using the frame command we can view the saved registers if the current stack frame.\n\n(gdb) $ info frame\n\n\nStack level 0, frame at 0x61ff10:\n eip = 0x401416 in fun; saved eip 0x401508\n called by frame at 0x61ff30\n Arglist at 0x61ff08, args:\n Locals at 0x61ff08, Previous frame's sp is 0x61ff10\n Saved registers:\n  ebp at 0x61ff08, eip at 0x61ff0c\n\n\nThe ebp register of the previous stack frame is at address 0x61ff08, the return address - at 0x61ff0c. The values are the same as generated by the program above.\n\n(gdb) $ c\n\n\nContinuing.\nBuffer start: 0061FEE8 Buffer start pointer address: 0061FEE8\nPrevious EBP: 0061FF08 Value: 6422312 Value as hex: 61ff28\nReturn address: 0061FF0C Value: 401508\nBuffer end: 0061FEF8\n\nProgram received signal SIGSEGV, Segmentation fault.\n0xcafeefac in ?? ()\n\n\nBy stepping over the breakpoint we can see the invalid return address that caused the segmentation fault.\n\nAltering variables\n\nLet’s examine another program that reads data from the standart input stream:\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main() {\n\t\n\tvolatile int zero;\n\t\n\tchar buffer[64];\n\t\n\tzero = 0;\n\t\n\tgets(buffer);\n\t\n\tif (zero) {\n\t\tprintf(\"You changed the zero variable to %d (hex: %x)!\", zero, zero);\n\t}\n\telse {\n\t\tputs(\"Variable not changed.\");\n\t}\n\t\n\treturn 0;\n}\n\n\nThe zero variable is marked as volatile to prevent the compiler from optimizing it’s usage, e.g. by caching it’s value in one of the general-purpose registers.\n\nBy dissassembling with GDB we get:\n\n0x00401410 &lt;+0&gt;:     push   ebp ; save the previous ebp register\n0x00401411 &lt;+1&gt;:     mov    ebp,esp ; initializing ebp of the new stack frame\n0x00401413 &lt;+3&gt;:     and    esp,0xfffffff0 ; memory aligning\n0x00401416 &lt;+6&gt;:     sub    esp,0x60 ; memory allocation on the stack\n0x00401419 &lt;+9&gt;:     call   0x401980 &lt;__main&gt;\n0x0040141e &lt;+14&gt;:    mov    DWORD PTR [esp+0x5c],0x0 ; assign to zero\n; eax = esp + 0x1c\n0x00401426 &lt;+22&gt;:    lea    eax,[esp+0x1c]\n; the address calculated with the previous instruction gets saved on the stack\n0x0040142a &lt;+26&gt;:    mov    DWORD PTR [esp],eax\n0x0040142d &lt;+29&gt;:    call   0x403ae8 &lt;gets&gt; ; gets() call\n; load the value from the memory for comparison\n0x00401432 &lt;+34&gt;:    mov    eax,DWORD PTR [esp+0x5c]\n0x00401436 &lt;+38&gt;:    test   eax,eax ; test if it is zero\n0x00401438 &lt;+40&gt;:    je     0x401458 &lt;main+72&gt; \n0x0040143a &lt;+42&gt;:    mov    edx,DWORD PTR [esp+0x5c]\n; commands needed for printf\n0x0040143e &lt;+46&gt;:    mov    eax,DWORD PTR [esp+0x5c]\n0x00401442 &lt;+50&gt;:    mov    DWORD PTR [esp+0x8],edx\n0x00401446 &lt;+54&gt;:    mov    DWORD PTR [esp+0x4],eax\n0x0040144a &lt;+58&gt;:    mov    DWORD PTR [esp],0x405044\n0x00401451 &lt;+65&gt;:    call   0x403ac8 &lt;printf&gt; ; success print\n0x00401456 &lt;+70&gt;:    jmp    0x401464 &lt;main+84&gt; ; jump over the else branch\n0x00401458 &lt;+72&gt;:    mov    DWORD PTR [esp],0x405073\n0x0040145f &lt;+79&gt;:    call   0x403ac0 &lt;puts&gt; ; error print\n; return with exit code 0\n0x00401464 &lt;+84&gt;:    mov    eax,0x0\n0x00401469 &lt;+89&gt;:    leave\n0x0040146a &lt;+90&gt;:    ret\n0x0040146b &lt;+91&gt;:    nop\n0x0040146c &lt;+92&gt;:    xchg   ax,ax\n0x0040146e &lt;+94&gt;:    xchg   ax,ax\n\n\nWe can set 2 breakpoints - before and after the gets() call.\n\n(gdb) $ br *0x0040142d\n(gdb) $ br *0x00401432\n\n\nWith gdb we can define what commands to run when these breakpoints are reached:\n\n(gdb) $ define hook-stop\n&gt;info registers\n&gt;x/24wx $esp\n&gt;x/2i $eip\n&gt;end\n\n\nWith the commands above we will see the register state, 24 machine words on the stack and two next instuctions after the instruction pointer:\n\neax            0x61fedc 6422236\necx            0x4018f0 4200688\nedx            0x50000018       1342177304\nebx            0x2d2000 2957312\nesp            0x61fec0 0x61fec0\nebp            0x61ff28 0x61ff28\nesi            0x4012d0 4199120\nedi            0x4012d0 4199120\neip            0x40142d 0x40142d &lt;main+29&gt;\neflags         0x202    [ IF ]\ncs             0x23     35\nss             0x2b     43\nds             0x2b     43\nes             0x2b     43\nfs             0x53     83\ngs             0x2b     43\n0x61fec0:       0x0061fedc      0x00000008      0x772c8023      0x772c801a\n0x61fed0:       0xb3b6879d      0x004012d0      0x004012d0      0x00000000\n0x61fee0:       0x004018f0      0x0061fed0      0x0061ff08      0x0061ffcc\n0x61fef0:       0x772cdd70      0xc4e6dd59      0xfffffffe      0x772c801a\n0x61ff00:       0x772c810d      0x004018f0      0x0061ff50      0x0040195b\n0x61ff10:       0x004018f0      0x00000000      0x002d2000      0x00000000\n=&gt; 0x40142d &lt;main+29&gt;:  call   0x403ae8 &lt;gets&gt;\n   0x401432 &lt;main+34&gt;:  mov    eax,DWORD PTR [esp+0x5c]\n\nBreakpoint 1, 0x0040142d in main ()\n\n\nNow we can examine how the input affects the stack:\n\n(gdb) $ c\nContinuing.\n0000000000000000000000000000000000000000000\n\n\neax            0x61fedc 6422236\necx            0x772eb098       1999548568\nedx            0xa      10\nebx            0x2d2000 2957312\nesp            0x61fec0 0x61fec0\nebp            0x61ff28 0x61ff28\nesi            0x4012d0 4199120\nedi            0x4012d0 4199120\neip            0x401432 0x401432 &lt;main+34&gt;\neflags         0x216    [ PF AF IF ]\ncs             0x23     35\nss             0x2b     43\nds             0x2b     43\nes             0x2b     43\nfs             0x53     83\ngs             0x2b     43\n0x61fec0:       0x0061fedc      0x00000008      0x772c8023      0x772c801a\n0x61fed0:       0xb3b6879d      0x004012d0      0x004012d0      0x30303030\n0x61fee0:       0x30303030      0x30303030      0x30303030      0x30303030\n0x61fef0:       0x30303030      0x30303030      0x30303030      0x30303030\n0x61ff00:       0x30303030      0x00303030      0x0061ff50      0x0040195b\n0x61ff10:       0x004018f0      0x00000000      0x002d2000      0x00000000\n=&gt; 0x401432 &lt;main+34&gt;:  mov    eax,DWORD PTR [esp+0x5c]\n   0x401436 &lt;main+38&gt;:  test   eax,eax\n\nBreakpoint 2, 0x00401432 in main ()\n\n\nAs we see, 43 zero-characters (ascii code 0x30) was not enouph to get to the zero value that we want ti akter. In order to get to the value, we need 64 bytes (because the buffer size is 64). For demonstration purpuses we will use the following string as the input:\n\n000011111111111111112222222222222222333333333333333344444444444456\n\n\nThis string contains 66 characters, so the 2 last characters 5 and 6 should overwrite the 2 least significant bytes (because memory endianness is little-endian) of the variable.\n\n(gdb) $ c\nContinuing.\n000011111111111111112222222222222222333333333333333344444444444456\n\n\neax            0x61fedc 6422236\necx            0x772eb098       1999548568\nedx            0xa      10\nebx            0x3f9000 4165632\nesp            0x61fec0 0x61fec0\nebp            0x61ff28 0x61ff28\nesi            0x4012d0 4199120\nedi            0x4012d0 4199120\neip            0x401432 0x401432 &lt;main+34&gt;\neflags         0x216    [ PF AF IF ]\ncs             0x23     35\nss             0x2b     43\nds             0x2b     43\nes             0x2b     43\nfs             0x53     83\ngs             0x2b     43\n0x61fec0:       0x0061fedc      0x00000008      0x772c8023      0x772c801a\n0x61fed0:       0xe53b01b1      0x004012d0      0x004012d0      0x30303030\n0x61fee0:       0x31313131      0x31313131      0x31313131      0x31313131\n0x61fef0:       0x32323232      0x32323232      0x32323232      0x32323232\n0x61ff00:       0x33333333      0x33333333      0x33333333      0x33333333\n0x61ff10:       0x34343434      0x34343434      0x34343434      0x00003635\n=&gt; 0x401432 &lt;main+34&gt;:  mov    eax,DWORD PTR [esp+0x5c]\n   0x401436 &lt;main+38&gt;:  test   eax,eax\n\nBreakpoint 2, 0x00401432 in main ()\n\n\nBy continuing we see that the variable now contains 0x3635 or 13877 in decimal.\n\n(gdb) $ c\n\n\nContinuing.\nYou changed the zero variable to 13877 (hex: 3635)![Inferior 1 (process 4848) exited normally]\nError while running hook_stop:\nThe program has no registers now.\n\n\nIn order to alter the zero variable we need to represent the number in the little endian form and write the corresponding bytes to the 65, 66, 67 and 68 offsets in in buffer.\n\nProtection against buffer overflows\n\nCompilers and operating systems have some techniques to prevent such stack exploits. In gcc, for example, if the function allocates a buffer on the stack, an additional so-called stack canary is added. A stack canary is just a random integer generated when the function is called. Before returning the function makes sure that the canary has the same value. If the canary has been altered, the program is terminated with a fatal Stack smashing detected error.\n\nAnother technique used by operating systems is restricting code evaluation on the stack. When the stack overflow is exploited, hackers will try to overwrite the return address so that it points at the buffer location with the malicious code injected. Even if the exact address is not known, it is possible to construct a NO-OP-instruction slide in the stack buffer so that a jump at any address within this slide will lead to malicious code execution. Exact stack addresses are typically different after every program run because operating systems push environmental variables onto it.\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/call-stack-buffer-overflow/"
    },{
      "image": "../../assets/img/blog/extended-euklidian-code.jpg",
      "title": "Extended Euclidean algorithm without stack or recursion",
      "date": "2020-02-21 00:00:00 +0100",
      
      "content": "Typical implementation of the extended Euclidean algorithm on the internet will just iteratively calculate modulo until 0 is reached. However, sometimes you also need to calculate the linear combination coefficients for the greatest common divisor.\n\nExtended Euclidean algorithm\n\nThe extended Euclidean algorithm allows us not only to calculate the gcd (greatest common divisor) of 2 numbers, but gives us also a representation of the result in a form of a linear combination:\n\ngcd⁡(a,b)=u⋅a+v⋅bu,v∈Z\\gcd(a, b) = u \\cdot a + v \\cdot b \\quad u,v \\in \\mathbb{Z}gcd(a,b)=u⋅a+v⋅bu,v∈Z\n\ngcd of more than 2 numbers can always be done by iteratively calculating the gcd of 2 numbers.\n\nFor example, let’s calculate gcd⁡(14,5)\\gcd(14, 5)gcd(14,5):\n\n14=5⋅2+45=4⋅1+14=1⋅4+0\\begin{aligned}\n14 &amp;= 5 \\cdot 2 + 4 \\\\\n5 &amp;= 4 \\cdot 1 + 1 \\\\\n4 &amp;= 1 \\cdot 4 + 0\n\\end{aligned}1454​=5⋅2+4=4⋅1+1=1⋅4+0​\n\nSo the greatest common divisor of 141414 and 555 is 111.\n\nWe can find the linear combination coefficients by writing 111 in terms of 141414 and 555:\n\n1=5−4⋅1=5−(14−5⋅2)⋅1=5−14+5⋅2=3⋅5+(−1)⋅14\\begin{aligned}\n1 &amp;= 5 - 4 \\cdot 1 \\\\\n&amp;= 5 - (14 - 5 \\cdot 2) \\cdot 1 \\\\\n&amp;= 5 - 14 + 5 \\cdot 2 \\\\\n&amp;= 3 \\cdot 5 + (-1) \\cdot 14\n\\end{aligned}1​=5−4⋅1=5−(14−5⋅2)⋅1=5−14+5⋅2=3⋅5+(−1)⋅14​\n\nSo in this case u=3u = 3u=3 and v=−1v = -1v=−1:\n\ngcd⁡(14,5)=(−1)⋅14+3⋅5=1\\gcd(14, 5) = (-1) \\cdot 14 + 3 \\cdot 5 = 1gcd(14,5)=(−1)⋅14+3⋅5=1\n\nWe can calculate the linear combination coefficients by doing back substitution. But it is not so easy to implement this without recursion, because the back substitution is done when we are climbing out of the recursive calls. We will implement the algorithm recursively first.\n\nRecursive implementation\n\nThe formula\n\ngcd⁡(a,b)={b,if a=0gcd⁡(b mod a,a),otherwise\\gcd(a, b) =\n\t\\begin{cases}\n\tb, &amp; \\text{if}\\ a = 0 \\\\\n\t\\gcd(b \\bmod a, a), &amp; \\text{otherwise}\n\t\\end{cases}gcd(a,b)={b,gcd(bmoda,a),​if a=0otherwise​\n\nallows us to describe the algorithm in a functional way:\n\n\n  If a=0a = 0a=0, then the greatest common divisor is bbb. Coefficients u=0u = 0u=0 and v=0v = 0v=0.\n  Else, we make the problem simpler by calculating gcd⁡(b mod a,a)\\gcd(b \\bmod a, a)gcd(bmoda,a). We can calculate the new coefficients based on the coefficients of the simpler problem.\n\n\nSo, how can we calculate uuu and vvv so that\n\ngcd⁡(a,b)=u⋅a+v⋅b\\gcd(a, b) = u \\cdot a + v \\cdot bgcd(a,b)=u⋅a+v⋅b\n\nby knowing u′u&#x27;u′ and v′v&#x27;v′ with:\n\ngcd⁡(b mod a,a)=u′⋅(b mod a)+v′⋅a\\gcd(b \\bmod a, a) = u&#x27; \\cdot (b \\bmod a) + v&#x27; \\cdot agcd(bmoda,a)=u′⋅(bmoda)+v′⋅a\n\nIn order to do that we can write b mod ab \\bmod abmoda in terms of initial aaa and bbb:\n\ngcd⁡(b mod a,a)=u′⋅(b mod a)+v′⋅a=u′⋅(b−⌊ba⌋⋅a)+v′⋅a=u′⋅b−u′⋅⌊ba⌋⋅a+v′⋅a=(v′−u′⋅⌊ba⌋)⋅a+u′⋅b\\begin{aligned}\n\t\\gcd(b \\bmod a, a)\n    \t&amp;= u&#x27; \\cdot (b \\bmod a) + v&#x27; \\cdot a \\\\\n    \t&amp;= u&#x27; \\cdot (b - \\left\\lfloor \\frac{b}{a} \\right\\rfloor \\cdot a) + v&#x27; \\cdot a \\\\\n    \t&amp;= u&#x27; \\cdot b - u&#x27; \\cdot \\left\\lfloor \\frac{b}{a} \\right\\rfloor \\cdot a + v&#x27; \\cdot a \\\\\n    \t&amp;= (v&#x27; - u&#x27; \\cdot \\left\\lfloor \\frac{b}{a} \\right\\rfloor) \\cdot a + u&#x27; \\cdot b\n\\end{aligned}gcd(bmoda,a)​=u′⋅(bmoda)+v′⋅a=u′⋅(b−⌊ab​⌋⋅a)+v′⋅a=u′⋅b−u′⋅⌊ab​⌋⋅a+v′⋅a=(v′−u′⋅⌊ab​⌋)⋅a+u′⋅b​\n\nSo the new linear combination coefficients are:\n\nu=v′−u′⋅⌊ba⌋v=u′\\begin{aligned}\n    u &amp;= v&#x27; - u&#x27; \\cdot \\left\\lfloor \\frac{b}{a} \\right\\rfloor \\\\\n    v &amp;= u&#x27;\n\\end{aligned}uv​=v′−u′⋅⌊ab​⌋=u′​\n\nWith this formula we are now ready to implement the algorithm:\n\nclass GCD_Result: # Representation of the result\n    def __init__(self, gcd, u, v):\n        self.gcd = gcd\n        self.u = u\n        self.v = v\n\ndef extended_gcd(a, b):\n    if a == 0:\n        return GCD_Result(b, 0, 1)\n    result = extended_gcd(b % a, a)\n    u = result.u # save u'\n    result.u = result.v - (b // a) * result.u # u = v' - u' * (b // a)\n    result.v = u # v = u'\n    return result\n\n\nNon-recursive implementation\n\nThe recursion in the algorithm above cannot be easily eliminated because the function is not tail-recursive.\n\nIn order to implement the algorithm with a loop we need to define a sequence of division remainders and then update the corresponding remainers as we calculate the remainders. Formally, we can define f finite sequence rnr_nrn​:\n\nr1=ar2=brn+2=rn mod rn+1\\begin{aligned}\nr_1 &amp;= a \\\\\nr_2 &amp;= b \\\\\nr_{n+2} &amp;= r_n \\bmod r_{n+1}\n\\end{aligned}r1​r2​rn+2​​=a=b=rn​modrn+1​​\n\nIf rn+1=0r_{n+1} = 0rn+1​=0, rn+2r_{n+2}rn+2​ is not defined. We can write each rnr_nrn​ as a linear combination of uuu and vvv. Now we are interested in how uuu and vvv change as we calculate remainders. To do this formally, we will need to define two new finite sequences unu_nun​ and vnv_nvn​ which will represent the linear combination coefficients:\n\nrn=un⋅a+vn⋅br_n = u_n \\cdot a + v_n \\cdot brn​=un​⋅a+vn​⋅b\n\nBy definition, r1=ar_1  = ar1​=a and r2=br_2 = br2​=b, so we can directly write the linear combination coefficients for r1r_1r1​ and r2r_2r2​:\n\nu1=1v1=0u2=0v2=1\\begin{aligned}\n    u_1 &amp;= 1 \\\\\n    v_1 &amp;= 0 \\\\\n    u_2 &amp;= 0 \\\\\n    v_2 &amp;= 1\n\\end{aligned}u1​v1​u2​v2​​=1=0=0=1​\n\nLet qnq_nqn​ be the finite sequence of integer divisions in rnr_nrn​:\n\nrn=rn+1⋅qn+2+rn+2r_n = r_{n+1} \\cdot q_{n+2} + r_{n+2}rn​=rn+1​⋅qn+2​+rn+2​\n\nNow we can write unu_nun​ and vnv_nvn​ in terms of qnq_nqn​:\n\nrn+2=rn−rn+1⋅qn+2=un⋅a+vn⋅b−rn+1⋅qn+2=un⋅a+vn⋅b−(un+1⋅a+vn+1⋅b)⋅qn+2=un⋅a+vn⋅b−un+1⋅a⋅qn+2−vn+1⋅b⋅qn+2=(un−un+1⋅qn+2)⋅a+(vn−vn+1⋅qn+2)⋅b\\begin{aligned} \n    r_{n+2} &amp;= r_n - r_{n+1} \\cdot q_{n+2} \\\\\n    &amp;= u_n \\cdot a + v_n \\cdot b - r_{n+1} \\cdot q_{n+2} \\\\\n    &amp;= u_n \\cdot a + v_n \\cdot b - (u_{n+1} \\cdot a + v_{n+1} \\cdot b) \\cdot q_{n+2} \\\\\n    &amp;= u_n \\cdot a + v_n \\cdot b - u_{n+1} \\cdot a \\cdot q_{n+2} - v_{n+1} \\cdot b \\cdot q_{n+2} \\\\\n    &amp;= (u_n - u_{n+1} \\cdot q_{n+2}) \\cdot a + (v_n - v_{n+1} \\cdot q_{n+2}) \\cdot b\n\\end{aligned}rn+2​​=rn​−rn+1​⋅qn+2​=un​⋅a+vn​⋅b−rn+1​⋅qn+2​=un​⋅a+vn​⋅b−(un+1​⋅a+vn+1​⋅b)⋅qn+2​=un​⋅a+vn​⋅b−un+1​⋅a⋅qn+2​−vn+1​⋅b⋅qn+2​=(un​−un+1​⋅qn+2​)⋅a+(vn​−vn+1​⋅qn+2​)⋅b​\n\nTo get the formula for unu_nun​ and vnv_nvn​ we can just substitute nnn instead of n+2n + 2n+2:\n\nun=un−2−qn⋅un−1vn=vn−2−qn⋅vn−1\\begin{aligned}\n    u_n &amp;= u_{n-2} - q_n \\cdot u_{n-1} \\\\\n    v_n &amp;= v_{n-2} - q_n \\cdot v_{n-1}\n\\end{aligned}un​vn​​=un−2​−qn​⋅un−1​=vn−2​−qn​⋅vn−1​​\n\nWith this formula and the initial values of the unu_nun​ and vnv_nvn​ sequences we can now implement the extended Euclidean algorithm without recursion:\n\ndef extended_gcd(a, b):\n    if a == 0:\n        # The algorithm will work correctly without this check\n        # But it will take one iteration of the inner loop\n        return GCD_Result(b, 0, 1)\n\n    unPrev = 1\n    vnPrev = 0\n    unCur = 0\n    vnCur = 1\n\n    while b != 0:\n        # Calculate new element of the qn sequence\n        qn = a // b\n        \n        # Calculate new element of the rn sequence\n        newRemainder = a % b\n        a = b\n        b = newRemainder\n\n        # Calculate new coefficients with the formula above\n        unNew = unPrev - qn * unCur\n        vnNew = vnPrev - qn * vnCur\n\n        # Shift coefficients\n        unPrev = unCur\n        vnPrev = vnCur\n        unCur = unNew\n        vnCur = vnNew\n\n    return GCD_Result(a, unPrev, vnPrev)\n\n\nExample\n\nWe can visualize the finite sequences we defined and see how the algorithm works with a table. We will calculate gcd⁡(104,47)\\gcd(104, 47)gcd(104,47) and it’s linear combination coefficients:\n\ngcd⁡(104,47)=u⋅104+v⋅47\\gcd(104, 47) = u \\cdot 104 + v \\cdot 47gcd(104,47)=u⋅104+v⋅47\n\n\n  \n    \n      rnr_nrn​\n      qnq_nqn​\n      unu_nun​\n      vnv_nvn​\n    \n  \n  \n    \n      104\n      -\n      1\n      0\n    \n    \n      47\n      -\n      0\n      1\n    \n    \n      10\n      2\n      1\n      -2\n    \n    \n      7\n      4\n      -4\n      9\n    \n    \n      3\n      1\n      5\n      -11\n    \n    \n      1\n      2\n      -14\n      31\n    \n    \n      0\n      3\n      33\n      20\n    \n  \n\n\nAt each step we first calculate the next element from the qnq_nqn​ sequence and then use it to calculate new linear combination coefficients unu_nun​ and vnv_nvn​.\n\nThe result of the algorithm:\n\ngcd⁡(104,47)=−14⋅104+31⋅47=1\\gcd(104, 47) = -14 \\cdot 104 + 31 \\cdot 47 = 1gcd(104,47)=−14⋅104+31⋅47=1\n\nImprovement of the non-recusive solution\n\nAs we see in the example above, we don’t need to calculate the last row of the table because we aren’t interested in the linear combination that forms zero. We can terminate the algorithm directly after calculating the new element of the rnr_nrn​ sequence:\n\ndef extended_gcd(a, b):\n    if a == 0: # Optional check\n        return GCD_Result(b, 0, 1)\n\n    if b == 0: # Without this check the first iteration will divide by zero\n        return GCD_Result(a, 1, 0)\n\n    unPrev = 1\n    vnPrev = 0\n    unCur = 0\n    vnCur = 1\n\n    while True:\n        qn = a // b\n        newR = a % b\n        a = b\n        b = newR\n\n        if b == 0:\n            return GCD_Result(a, unCur, vnCur)\n\n        # Update coefficients\n        unNew = unPrev - qn * unCur\n        vnNew = vnPrev - qn * vnCur\n\n        # Shift coefficients\n        unPrev = unCur\n        vnPrev = vnCur\n        unCur = unNew\n        vnCur = vnNew\n\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/non-recursive-extended-euklidian-algorithm/"
    },{
      "image": "../../assets/img/blog/dfa-radix2-modulo4.svg",
      "title": "Numbers in congruence classes are regular languages",
      "date": "2020-08-29 00:00:00 +0200",
      
      "content": "In this post we will consider natural Radix-b numbers in positional number systems. The congruence class of any such arbitrary natural number can be determined by a finite automata, and thus, intuitively speaking, the language of all Radix-b numbers that satisfy some fixed properties modulo b is regular.\n\nRadix-b numbers divisible by m\n\nThe key idea behind the automation construction is that after reading a digit, the new congruence class depends only on the current read digit and on the previous congruence class. There are only m&lt;∞m &lt; \\inftym&lt;∞ congruence classes so we can construct a finite automata that accepts all numbers divisible by m:\n\nA=(Z,Σ,δ,z0,E)Z:={0,…,m−1}Σ:={0,…,b−1}E:={0}z0:=0δ(r,d):=r⋅b+d mod m\\begin{aligned}\nA &amp;= (Z,\\Sigma,\\delta, z_0, E) \\\\\nZ &amp;:= \\{0,\\dots, m-1\\} \\\\\n\\Sigma &amp;:= \\{0,\\dots, b-1\\} \\\\\nE &amp;:= \\{0\\} \\\\\nz_0 &amp;:= 0 \\\\\n\\delta(r,d) &amp;:= r \\cdot b + d \\bmod{m}\n\\end{aligned}AZΣEz0​δ(r,d)​=(Z,Σ,δ,z0​,E):={0,…,m−1}:={0,…,b−1}:={0}:=0:=r⋅b+dmodm​\n\nThe correctness of the transition function can be seen as follows: when the automation is in state rrr, the number that has been read is in the congruence class rrr modulo mmm. So we can write it as mk+rmk+rmk+r. By multiplying with bbb (i.e. shift the number by 1 digit to the left) and adding ddd we get the new congruence class:\n\nδ(r,d)=(mk+r)⋅b+d mod m=mkb+rb+d mod m=rb+d mod m\\begin{aligned}\n\\delta(r,d) &amp;= (mk + r)\\cdot b + d \\bmod{m} \\\\\n&amp;= mkb + rb + d \\bmod{m} \\\\\n&amp;= rb + d \\bmod{m}\n\\end{aligned}δ(r,d)​=(mk+r)⋅b+dmodm=mkb+rb+dmodm=rb+dmodm​\n\nOf course, by altering the set of final states EEE we can accept not only multiples of mmm, but any such number nnn with n mod m∈En \\bmod{m} \\in Enmodm∈E for any E⊆ZE \\subseteq ZE⊆Z.\n\nBinary numbers modulo 4\n\nFor example, we can construct a finite automation that accepts all binary (b=2b = 2b=2) numbers divisible by 4 (m=4m = 4m=4):\n\n\n\nThe transitions are obtained as follows:\n\n0⋅2 mod 4=0  ⟹  δ(0,0)=0,δ(0,1)=11⋅2 mod 4=2  ⟹  δ(1,0)=2,δ(1,1)=32⋅2 mod 4=0  ⟹  δ(2,0)=0,δ(2,1)=13⋅2 mod 4=2  ⟹  δ(3,0)=2,δ(3,1)=3\\begin{aligned}\n0 \\cdot 2 \\bmod{4} = 0 &amp;\\implies \\delta(0, 0) = 0, \\delta(0, 1) = 1 \\\\\n1 \\cdot 2 \\bmod{4} = 2 &amp;\\implies \\delta(1, 0) = 2, \\delta(1, 1) = 3 \\\\\n2 \\cdot 2 \\bmod{4} = 0 &amp;\\implies \\delta(2, 0) = 0, \\delta(2, 1) = 1 \\\\\n3 \\cdot 2 \\bmod{4} = 2 &amp;\\implies \\delta(3, 0) = 2, \\delta(3, 1) = 3\n\\end{aligned}0⋅2mod4=01⋅2mod4=22⋅2mod4=03⋅2mod4=2​⟹δ(0,0)=0,δ(0,1)=1⟹δ(1,0)=2,δ(1,1)=3⟹δ(2,0)=0,δ(2,1)=1⟹δ(3,0)=2,δ(3,1)=3​\n\nIn this particular case the constructed automation is not minimal. States s1 and s3 are equivalent (this can be formally proven with the Myhill-Nerode theorem) and can be replaced by one state:\n\n\n\nAs languages accepted by DFA’s are exactly the regular languages, we can transform any DFA in a regular expression to see the exact structure of numbers divisible, for example, by 4. Unfortunately such regular expressions are very long when constructed with the Kleene or with the Arden method by a computer. These regular expressions must be massively simplified in order to be readable. With the Kleene construction I’ve implemented in this project we get the following regular expression:\n\nε|0|(ε|0)0*(ε|0)|(1|(ε|0)0*1)(1|0*1)*0*(ε|0)|(1|(ε|0)0*1)(1|0*1)*0((1|00*1)(1|0*1)*0)*(0|00*(ε|0)|(1|00*1)(1|0*1)*0*(ε|0))\n\n\nIt can be simplified by computer heuristics down to:\n\nε|0|1(1|01)*00|(0|ε|1(1|01)*00)(0|1(1|01)*00)*(0|ε|1(1|01)*00)\n\n\nStill, the regular expression is not so readable. By transforming it further by hand, we can prove that it is equivalent to:\n\nε|0|1(1|01)*00|(0|ε|1(1|01)*00)(0|1(1|01)*00)*(0|ε|1(1|01)*00) =\nε|0|1(1|01)*00|(ε|0|1(1|01)*00)(0|1(1|01)*00)*(ε|0|1(1|01)*00) =\nε|0|1(1|01)*00|(0|1(1|01)*00)*(ε|0|1(1|01)*00) =\nε|0|1(1|01)*00|(0|1(1|01)*00)* =\nε|0|(0|1(1|01)*00)* =\nε|0|(0|1(1|0)*00)* =\nε|0|0*(1(1|0)*000*)* =\nε|0|0*(1(1|0)*0*00)* =\nε|0|0*(1(1|0)*00)* =\nε|0|0*(1(0|1)*00)* =\nε|0|0*(1(0|1)*00|ε) =\nε|0|0*|0*1(0|1)*00 =\nε|0|0*|0*(0|1)*00 =\nε|0|0*(0|1)*00 =\nε|0|(0|1)*00\n\n\nSo, any binary number divisible by 4 must be zero or end with 00.\n\nOther examples\n\nDecimal numbers divisible by 20\n\n\n\nDecimal numbers divisible by 75\n\n\n\nHexadecimal numbers divisible by 24\n\n\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/numbers-are-regular-languages/"
    },{
      "image": "../../assets/img/blog/dfa-radix10-modulo75-min.svg",
      "title": "Efficient compression of congruence class automations",
      "date": "2020-09-01 00:00:00 +0200",
      
      "content": "As already discussed in the previous post, any radix-b number nnn with n mod m∈E⊆Zn \\bmod{m} \\in E \\subseteq Znmodm∈E⊆Z can be accepted by finite automata in a digit-by-digit manner. However, the construction is not always optimal. The amount of states required is not always the amount of congruence classes. In this post we will examine when exactly the finite automata can be simplified by combining states. Reducing the amount of states will also help produce a much simpler regular expression, for example, with the Kleene construction.\n\nGeneral way to optimize an automation\n\nOf course, we can optimize the DFA with the well-known algorithm based on the Myhill-Nerode theorem. Unfortunately, even an optimized implementation is not efficient enough to do the optimization for large mmm and bbb, because the complexity of the algorithm expressed in these terms is O(b⋅m2)O(b \\cdot m^2)O(b⋅m2), as the algorithm needs to iterate over all m2m^2m2 pairs of states and consider all the outgoing transitions (bbb in each state). With this tool we can run the algorithm and get the following results for b=10b = 10b=10 and 1≤m≤201 \\le m \\le 201≤m≤20:\n\nm= 1 |Z|= 1  Z = [[0]]\nm= 2 |Z|= 2  Z = [[0], [1]]\nm= 3 |Z|= 3  Z = [[0], [1], [2]]\nm= 4 |Z|= 3  Z = [[0], [3, 1], [2]]\nm= 5 |Z|= 2  Z = [[0], [2, 1, 3, 4]]\nm= 6 |Z|= 4  Z = [[0], [4, 1], [5, 2], [3]]\nm= 7 |Z|= 7  Z = [[0], [1], [2], [3], [4], [5], [6]]\nm= 8 |Z|= 5  Z = [[0], [5, 1], [6, 2], [7, 3], [4]]\nm= 9 |Z|= 9  Z = [[0], [1], [2], [3], [4], [5], [6], [7], [8]]\nm=10 |Z|= 2  Z = [[0], [5, 4, 3, 2, 7, 6, 9, 8, 1]]\nm=11 |Z|=11  Z = [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\nm=12 |Z|= 7  Z = [[0], [7, 1], [8, 2], [9, 3], [10, 4], [11, 5], [6]]\nm=13 |Z|=13  Z = [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12]]\nm=14 |Z|= 8  Z = [[0], [8, 1], [9, 2], [10, 3], [11, 4], [12, 5], [13, 6], [7]]\nm=15 |Z|= 4  Z = [[0], [13, 10, 7, 4, 1], [5, 2, 8, 11, 14], [9, 6, 12, 3]]\nm=16 |Z|= 9  Z = [[0], [9, 1], [10, 2], [11, 3], [12, 4], [13, 5], [14, 6], [15, 7], [8]]\nm=17 |Z|=17  Z = [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16]]\nm=18 |Z|=10  Z = [[0], [10, 1], [11, 2], [12, 3], [13, 4], [14, 5], [15, 6], [16, 7], [17, 8], [9]]\nm=19 |Z|=19  Z = [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18]]\nm=20 |Z|= 3  Z = [[0], [13, 11, 15, 17, 5, 3, 7, 9, 19, 1], [12, 10, 14, 16, 4, 2, 6, 8, 18]]\n\n\nHere, ZZZ is the set of states in the new, minimal DFA. ZZZ is a set of equivalence classes that represent which states can be combined into one state. These equivalence classes have been computed for E:={0}E := \\{0\\}E:={0}. That is why, for example, for m=8m = 8m=8 states 0 and 4 aren’t in one equivalence class. They can’t be equivalent, because state 4 is intermediate while state 0 is final.\n\nComputing equivalence classes ahead-of-time\n\nAs you can see, there is clearly a pattern in the equivalence states above. For example, we can see that no states are equivalent when mmm is prime. By further examining the data above we can even conclude that the DFA probably can’t be simplified if gcd⁡(b,m)=1\\gcd(b, m) = 1gcd(b,m)=1 i.e. if bbb and mmm are coprime.\n\nAfter formally examining when the states can be combined I came up with the following result:\n\nTheorem\n\nIf m≤bm \\le bm≤b and E≠∅E \\neq \\varnothingE​=∅, then the minimum finite automation can be constructed as follows:\n\nZ=⋃A∈Z′⋅{A∩E,A\\E}\\{∅}Z = \\overset{\\cdot}{\\bigcup_{A\\in Z&#x27;}} \\{A \\cap E, A \\backslash E\\}\\backslash\\{\\varnothing\\}Z=A∈Z′⋃​⋅​{A∩E,A&lt;/span&gt;E}&lt;/span&gt;{∅}\n\nwhere Z′Z&#x27;Z′ is the set of equivalence classes of the following equivalence relation:\n\nx∼y⇔x≡ymod  mgcd⁡(b,m)x \\sim y \\Leftrightarrow x \\equiv y \\mod{\\frac{m}{\\gcd(b, m)}}x∼y⇔x≡ymodgcd(b,m)m​\n\nProof\n\nBy definition of δ\\deltaδ, we know that:\n\nδ(r,d)=k  ⟹  δ(r,d+1 mod b)=k+1 mod m\\delta(r, d) = k \\implies \\delta(r, d + 1 \\bmod b) = k + 1 \\bmod mδ(r,d)=k⟹δ(r,d+1modb)=k+1modm\n\nBecause m≤bm \\le bm≤b, it follows that the mapping δ(x,Σ)\\delta(x, \\Sigma)δ(x,Σ) is surjective. In other words, m≤bm \\le bm≤b implies that every state has at least one transition to any other state. Any change to this mapping will shift it. As E≠∅E \\neq \\varnothingE​=∅, any shifted mapping δ′\\delta&#x27;δ′ will lead to at least 1 digit ddd such that δ(x,d)∈E\\delta(x, d) \\in Eδ(x,d)∈E and δ′(x,d)∉E\\delta&#x27;(x, d) \\notin Eδ′(x,d)∈/​E.\n\nThus, 2 states x,y∈Zx,y \\in Zx,y∈Z are equivalent if and only if they have equivalent mappings which is equivalent to:\n\nδ(x,Σ)=δ(y,Σ)⇔δ(x,d)=δ(y,d)∀d∈Σ⇔xb+d mod m=yb+d mod m⇔xb+d≡yb+dmod  m⇔xb≡ybmod  m⇔xb−yb≡0mod  m⇔(x−y)⋅b≡0mod  m⇔x−y≡0mod  mgcd⁡(b,m)⇔x≡ymod  mgcd⁡(b,m)\\begin{aligned}\n\\delta(x, \\Sigma) = \\delta(y, \\Sigma) &amp;\\Leftrightarrow \\delta(x, d) = \\delta(y, d) \\quad \\forall d \\in \\Sigma \\\\\n&amp;\\Leftrightarrow xb + d \\bmod m = yb + d \\bmod m \\\\\n&amp;\\Leftrightarrow xb + d \\equiv yb + d \\mod{m} \\\\\n&amp;\\Leftrightarrow xb \\equiv yb \\mod{m} \\\\\n&amp;\\Leftrightarrow xb - yb \\equiv 0 \\mod{m} \\\\\n&amp;\\Leftrightarrow (x-y) \\cdot b \\equiv 0 \\mod{m} \\\\\n&amp;\\Leftrightarrow x-y \\equiv 0 \\mod{\\frac{m}{\\gcd(b, m)}} \\\\\n&amp;\\Leftrightarrow x \\equiv y \\mod{\\frac{m}{\\gcd(b, m)}}\n\\end{aligned}δ(x,Σ)=δ(y,Σ)​⇔δ(x,d)=δ(y,d)∀d∈Σ⇔xb+dmodm=yb+dmodm⇔xb+d≡yb+dmodm⇔xb≡ybmodm⇔xb−yb≡0modm⇔(x−y)⋅b≡0modm⇔x−y≡0modgcd(b,m)m​⇔x≡ymodgcd(b,m)m​​\n\nFirst corollary\n\nIt follows, that if m≤bm \\le bm≤b, E≠∅E \\neq \\varnothingE​=∅ and gcd⁡(b,m)=1\\gcd(b, m) = 1gcd(b,m)=1, then no states can be combined and the minimal automation has mmm states.\n\nSecond corollary\n\nIf m≤bm \\le bm≤b and E≠∅E \\neq \\varnothingE​=∅, then the amount of states Z′Z&#x27;Z′ (before splitting each equivalence class in final states and non final ones as shown in the theorem) is equal to the following set of orbits:\n\nZ′=(Z/m)/⟨gcd⁡(b,m)⟩Z&#x27; = (\\mathbb{Z}/m)/\\langle \\gcd(b, m) \\rangleZ′=(Z/m)/⟨gcd(b,m)⟩\n\nExample implementation\n\nThis Java method uses the results above to compute the equivalence classes efficiently:\n\npublic static List&lt;List&lt;Integer&gt;&gt; computeEquivalenceClasses(int b, int m, HashSet&lt;Integer&gt; finalStates) {\n    assert m &lt;= b;\n    assert !finalStates.isEmpty();\n\n    // Union-Find datastructure, preferrably with union-by-rank and path compression\n    UnionFind equivalenceClasses = new UnionFind(m);\n\n    int bmgcd = Euklidian.gcd(b, m);\n\n    if (bmgcd == 1) {\n        return equivalenceClasses.getDisjointSets();\n    }\n\n    int optimizedM = m / bmgcd;\n\n    // loop through every set in the new set of equivalence classes\n    for (int anchor = 0; anchor &lt; optimizedM; anchor++) {\n\n        int current = anchor; // [anchor] is the equivalence class\n        // oppositeAnchor is the element that is final if anchor is intermediate\n        // and intermediate if anchor is final\n        // if oppositeAnchor == anchor, then it is considered as not yet found\n        int oppositeAnchor = anchor;\n\n        boolean anchorFinal = finalStates.contains(anchor);\n\n        for (;;) {\n            current = (current + optimizedM) % m;\n\n            if (current == anchor) {\n                break;\n            }\n\n            boolean currentFinal = finalStates.contains(current);\n\n            if (currentFinal == anchorFinal) {\n                equivalenceClasses.union(current, anchor);\n            }\n            else if (oppositeAnchor == anchor) {\n                // \"initialize\" oppositeAnchor\n                oppositeAnchor = current;\n            }\n            else {\n                equivalenceClasses.union(current, oppositeAnchor);\n            }\n        }\n\n    }\n\n    return equivalenceClasses.getDisjointSets();\n}\n\n\nIf we use a union-find datastructure with union in O(1)O(1)O(1) (e.g. union-by-rank with path compression), then the complexity of the algorithm is O(m)O(m)O(m) which is much better than O(b⋅m2)O(b \\cdot m^2)O(b⋅m2).\n\nCase when m &gt; b\n\nIn case m&gt;bm &gt; bm&gt;b the equivalence relation depends very much on the set of final states EEE. With the Myhill Nerode theorem we get:\n\nx∼y⇔(xc∈L⇔yc∈L∀c∈Σ∗)⇔(x⋅b∣c∣+c mod m∈E⇔y⋅b∣c∣+c mod m∈E)\\begin{aligned}\nx \\sim y &amp;\\Leftrightarrow (xc \\in L \\Leftrightarrow yc \\in L \\quad \\forall c \\in \\Sigma^*) \\\\\n&amp;\\Leftrightarrow (x \\cdot b^{|c|} + c \\bmod m \\in E \\Leftrightarrow y \\cdot b^{|c|} + c \\bmod m \\in E)\n\\end{aligned}x∼y​⇔(xc∈L⇔yc∈L∀c∈Σ∗)⇔(x⋅b∣c∣+cmodm∈E⇔y⋅b∣c∣+cmodm∈E)​\n\nConclusion\n\nWith the above theorem it is easy to implement a much faster algorithm that computes equivalent states. It also gives an intuition, why for example it is harder to test whether a decimal number is divisible by 9 than to test whether a decimal number is divisible by 5, if we measure “hardness” by the amount of states in the minimal DFA. It is the case because gcd⁡(5,10)=5\\gcd(5, 10) = 5gcd(5,10)=5 and gcd⁡(9,10)=1\\gcd(9, 10) = 1gcd(9,10)=1.\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/compressing-congruence-automata/"
    },{
      "image": "../../assets/img/blog/kadane-example.svg",
      "title": "Kadane's algorithm and the idea behind it",
      "date": "2020-09-19 00:00:00 +0200",
      
      "content": "People often refer to Kadane’s algorithm only in the context of the maximum subarray problem. However, the idea behind this algorithm allows one to use it for solving a variety of problems that have something to do with finding a continuous subarray with a given property. The algorithm can also be used in 2d or multidimensional arrays but in this post we will only consider regular one-dimensional arrays.\n\nMotivation &amp; idea\n\nIf we are searching for a subarray with some property, the easiest solution would be to try all possible intervals. A naive algorithm can do that in O(n3)O(n^3)O(n3) time, but we can improve that by computing solutions for intervals of increasing length and reusing already computed solutions (aka dynamic programming). In this case the complexity of the algorithm is O(n2)O(n^2)O(n2). Of course, this will work not for all problems. It will work, for example, for the computation of any binary associative operation for all intervals in the array. Another example for such an algorithm would be finding all palindromes in a given string:\n\n\n  Mark all letters as palindromes of length 1\n  Mark all adjacent equal letters as palindromes of length 2\n  For every fixed length kkk, starting with k=3k = 3k=3 traverse all substrings of length kkk in the string and mark the current substring as a palindrome if the letters at the start and at the end match and if the middle part is a palindrome.\n\n\nO(n2)O(n^2)O(n2) is the optimal worst-case complexity if the problem cannot be solved without traversing the entire search space. For example, this is the case for the problem of computing all palindromes of a given string (a worst-case example is an∈Σ∗a^n \\in \\Sigma^*an∈Σ∗ where the amount of palindromes is ∑i=1ni=n⋅(n+1)2∈Ω(n2)\\sum_{i=1}^{n}i =\\frac{n \\cdot (n + 1)}{2} \\in \\Omega(n^2)∑i=1n​i=2n⋅(n+1)​∈Ω(n2)).\n\nThe key question is: How can we traverse only some subset of the search space and still benefit from dynamic programming?\n\nWell, we can identify a problem with only one side of the interval in the array. We will choose the right side of the interval because that is what is commonly used in real algorithms. That way it is possible to construct a linear time algorithm the following way:\n\n\n  Create a recursive function f(k)f(k)f(k) that computes the trivial solution if k=1k = 1k=1 and computes the new solution based on the already computed result, e.g. f(k−1)f(k-1)f(k−1).\n  Find the best solution among {f(k):0≤k&lt;n}\\{f(k) : 0 \\le k &lt; n\\}{f(k):0≤k&lt;n}.\n\n\nBoth parts take linear (O(n)O(n)O(n)) time if we cache and reuse the result of f(k)f(k)f(k) or if we use dynamic programming which is better most of the times.\n\nMaximum sum subarray\n\nA good example for a construction of such an algorithm is the maximum sum subarray problem - given an array AAA of integers the algorithm should find such indices a,b∈{1,…,n−1}a,b \\in \\{1, \\dots, n-1\\}a,b∈{1,…,n−1} with a≤ba \\le ba≤b such that ∑i=abA[i]\\sum_{i=a}^b {A[i]}∑i=ab​A[i] is maximal.\n\nWe can define the problem only in terms of the right border kkk - “what is the maximum subarray ending at kkk”?\n\nClearly, the maximum subarray of the whole array is the maximum of subarrays ending at kkk for all 0≤k&lt;n0 \\le k &lt; n0≤k&lt;n. Also, the maximum sum subarray ending at k is either A[k]A[k]A[k] itself or the maximum sum subarray ending at k−1k - 1k−1 combined with A[k]A[k]A[k]. So we can now write the algorithm formally with pseudocode:\n\nmaxSumSubarrayEndingAt(A, k) {\n    if (k == 0) {\n        return (A[0], 1);\n    }\n    (sum, left) = maxSumSubarrayEndingAt(k - 1);\n    if (sum &gt;= 0) { /* sum + A[k] &gt;= A[k] */\n        /* the max subarray (ending at k) is the previous subarray together with this element */\n        return (sum + A[k], left);\n    }\n    else {\n        /* the max subarray (ending at k) is the current element */\n        return (A[k], k);\n    }\n}\n\n\nAnd the maximum subarray sum and indices can be computed with a simple maximim-search algorithm:\n\nmaxSumSubarray(A) {\n    n = size(A);\n    maxSum = A[0];\n    maxLeft = 0;\n    maxRight = 0;\n    for (r = 1; r &lt; n; r++) {\n        (s, l) = maxSumSubarrayEndingAt(A, r);\n        if (s &gt; maxSum) {\n            maxSum = s;\n            maxLeft = l;\n            maxRight = r;\n        }\n    }\n    return (maxSum, maxLeft, maxRight);\n}\n\n\nThis intermediate pseudocode solution doesn’t cache maxSumSubarrayEndingAt results and is therefore inefficient “as-is”. But we can remove recursion and rewrite the same solution with dynamic programming (Java):\n\npublic static void maxSumSubarray(int[] a) {\n    int maxSum = a[0];\n    int maxLeft = 0;\n    int maxRight = 0;\n\n    int currentSum = a[0];\n    int currentLeft = 0;\n\n    for (int r = 1; r &lt; a.length; r++) {\n\n        if (currentSum &gt;= 0) {\n            currentSum += a[r];\n        }\n        else {\n            currentSum = a[r];\n            currentLeft = r;\n        }\n\n        if (currentSum &gt; maxSum) {\n            maxSum = currentSum;\n            maxLeft = currentLeft;\n            maxRight = r;\n        }\n    }\n\n    // the sum between A[maxLeft] and A[maxRight] (inclusive) is equal maxSum and maximal\n    System.out.printf(\"Max sum: %5d Indices from %5d to %5d.\\n\", maxSum, maxLeft, maxRight);\n}\n\n\nThis is the efficient Θ(n)\\Theta(n)Θ(n) time and Θ(1)\\Theta(1)Θ(1) space solution that uses the idea of Kadane’s algorithm to compute the maximum sum subarray.\n\nExample\n\nConsider the array {-2, 1, -3, 4, -1, 2, 1, -5, -2, 5}. By running the algorithm we get the following maximum subarrays ending at a specific index:\n\n\n\nThe maximum subarray is marked red.\n\nOther problems that can be solved analogously\n\n\n  Smallest sum subarray problem\n  Largest product subarray problem\n  Smallest product subarray problem\n  Maximum circular sum\n\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/kadane-algorithm/"
    },{
      "image": "../../assets/img/blog/bt-full-15-node-0.svg",
      "title": "Computing the lowest common ancestor in a full binary tree",
      "date": "2020-09-23 00:00:00 +0200",
      
      "content": "The lowest common ancestor (LCA) problem is important in many applications of binary trees. For example, by knowing the lowest common ancestor we can easily compute the shortest path between any two vertices in a tree. The most common way to compute the lca of vertices uuu and vvv is to iteratively go up until we get to the root of the subtree containing both uuu and vvv. This method works only if uuu and vvv are on the same level. If not, we can first measure the difference of heights ddd between uuu and vvv and then find the lowest common ancestor of the ddd-th parent of the lowest vertex and the higher vertex.\n\nLCA in a full binary tree\n\nFull binary trees are often represented implicitly in memory. That means, parent-child relations are determined by looking at the positions of nodes in the array. For example, in this tree the nodes are numbered the way they will be positioned in the array:\n\n\n\nIn a full binary tree the parent of node xxx is p(x):=⌊x−12⌋p(x):=\\left\\lfloor\\frac{x-1}{2}\\right\\rfloorp(x):=⌊2x−1​⌋, and children are 2⋅x+12 \\cdot x + 12⋅x+1 and 2⋅x+22 \\cdot x + 22⋅x+2. Formally speaking, for nodes aaa and bbb on the same level we would like to find the value of pn(a)p^n(a)pn(a) such that pn(a)=pn(b)p^n(a) = p^n(b)pn(a)=pn(b) for n minimal. In binary representation, dividing by 2 and discarding the remainder is equivalent to shifting the number by 1 bit to the right. In order to use this we can just add 1 to each node index:\n\n\n\nWith this change we can implement the lca algorithm:\n\nuint32_t lca_sameLevel(uint32_t a, uint32_t b) {\n    while (a != b) {\n        a &gt;&gt;= 1u;\n        b &gt;&gt;= 1u;\n    }\n    return a;\n}\n\n\nThis algorithm works because the lowest common ancestor is the longest common prefix of the binary representation of both nodes.\n\nIf we address nodes starting with one, then any nodewith level lll will be greater than or equal to 2l2^l2l. Therefore, the amount of leading zeroes in the binary representation of nodes in the same level is equal. Moreover, the difference of amounts of leading zeroes is equal to the difference of levels. With this idea we can now implement the algorithm that correctly finds the lowest common ancestor for any pair of nodes.\n\nuint32_t lca(uint32_t a, uint32_t b) {\n    \n    uint32_t aLeadingZeroes = __builtin_clz(a);\n    uint32_t bLeadingZeroes = __builtin_clz(b);\n    \n    while (aLeadingZeroes &gt; bLeadingZeroes) {\n        b &gt;&gt;= 1u;\n        bLeadingZeroes++;\n    }\n    \n    while (bLeadingZeroes &gt; aLeadingZeroes) {\n        a &gt;&gt;= 1u;\n        aLeadingZeroes++;\n    }\n    \n    while (a != b) {\n        a &gt;&gt;= 1u;\n        b &gt;&gt;= 1u;\n    }\n    \n    return a;\n}\n\n\nIt is also easy to modify the algorithm slightly so that it works for elements indexed starting from zero.\n\n#include &lt;stdint.h&gt;\n\nuint32_t lca(uint32_t a, uint32_t b) {\n    a++;\n    b++;\n    \n    uint32_t aLeadingZeroes = __builtin_clz(a);\n    uint32_t bLeadingZeroes = __builtin_clz(b);\n    \n    while (aLeadingZeroes &gt; bLeadingZeroes) {\n        b &gt;&gt;= 1u;\n        bLeadingZeroes++;\n    }\n    \n    while (bLeadingZeroes &gt; aLeadingZeroes) {\n        a &gt;&gt;= 1u;\n        aLeadingZeroes++;\n    }\n    \n    while (a != b) {\n        a &gt;&gt;= 1u;\n        b &gt;&gt;= 1u;\n    }\n    \n    return a - 1u;\n}\n\n\nComplexity: O(log⁡(n))O(\\log(n))O(log(n)) where nnn is the amount if nodes in the tree.\n\nExample\n\nIf the we want to find the lowest common ancestor of 8 and 10 (indexed from zero), then we add 1 to both of them and find the longest common prefix. In this case it is the longest common prefix of 1001 and 1011 which is 10 = 2 in decimal. 2 is the lowest common ancestor in the tree with increased indices, so in the original tree the lowest common ancestor is 2 - 1 = 1.\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/lowest-common-ancestor/"
    },{
      "image": "../../assets/img/blog/4d-boolean-cube-cnf.svg",
      "title": "Measuring the size of a regular language is NP-Hard",
      "date": "2020-10-15 00:00:00 +0200",
      
      "content": "In this post we will examine an interesting connection between the NP\\mathcal{NP}NP-complete CNF-SAT problem and the problem of computing the amount of words generated by some efficient representation of a formal language. Here, I call a way of representing a formal language efficient, if it has a polynomially-long encoding but can possibly describe an exponentially-large formal language. Examples of such efficient representations are nondeteministic finite automations and regular expressions.\n\nFormal definition of the problem\n\nWe can formally define the problem of determining the language size the following way:\n\nName: NFA Language Size\n\nInput: A nondeterministic finite automata (NFA) M:=(Z,Σ,δ,S,E)M := (Z, \\Sigma, \\delta, S, E)M:=(Z,Σ,δ,S,E) and a number m∈Nm \\in \\mathbb{N}m∈N.\n\nQuestion: Is ∣L(M)∣≤m\\st L(M) \\st \\le m∣L(M)∣≤m?\n\nProof of NP-hardness\n\nWe will construct a reduction from the NP\\mathcal{NP}NP-complete CNF-SAT problem. Consider a formula φ\\varphiφ with kkk clauses and nnn variables:\n\n\n  Create an NFA M:=(Z,Σ,δ,S,E)M := (Z, \\Sigma, \\delta, S, E)M:=(Z,Σ,δ,S,E) with the alphabet Σ:={0,1}\\Sigma := \\{0, 1\\}Σ:={0,1}.\n  For every variable 0≤v≤n0 \\le v \\le n0≤v≤n and clause 1≤c≤k1 \\le c \\le k1≤c≤k create a state z(v,c)∈Zz(v, c) \\in Zz(v,c)∈Z. Intuitively, if the NFA is in the state z(v,c)z(v, c)z(v,c), it means that it has already read vvv symbols of some variable assignment where clause ccc is zero.\n  For each clause 1≤c≤k1 \\le c \\le k1≤c≤k of the formula, construct a boolean cube ψ:V→{0,1,∗}\\psi : V \\to \\{0, 1, *\\}ψ:V→{0,1,∗} with ψ−1(1)\\psi^{-1}(1)ψ−1(1) containing variables that are negated in the clause and ψ−1(0)\\psi^{-1}(0)ψ−1(0) containing positive variables (other variables are mapped to ∗*∗). By doing this, we essentially construct a cube C(ψ):=(⋀ψ(x)=1x)∧(⋀ψ(x)=0xˉ)C(\\psi) := (\\bigwedge_{\\psi(x) = 1}{x}) \\wedge (\\bigwedge_{\\psi(x) = 0}{\\bar{x}})C(ψ):=(⋀ψ(x)=1​x)∧(⋀ψ(x)=0​xˉ) that is the negation of the clause. In other words, all full variable assignments ψ′:V→{0,1}\\psi&#x27; : V \\to \\{0, 1\\}ψ′:V→{0,1} such that ψ(x)≠∗⇒ψ′(x)=ψ(x)∀x∈V\\psi(x) \\neq * \\Rightarrow \\psi&#x27;(x) = \\psi(x) \\quad\\forall x \\in Vψ(x)​=∗⇒ψ′(x)=ψ(x)∀x∈V will make the clause (and the whole formula φ\\varphiφ) false. For all 0≤v&lt;n0 \\le v &lt; n0≤v&lt;n create the following transitions:\n    \n      Set δ(z(v,c),0):={z(v+1,c)}\\delta(z(v,c), 0) := \\{z(v + 1,c)\\}δ(z(v,c),0):={z(v+1,c)} if ψ(v+1)=0\\psi(v + 1) = 0ψ(v+1)=0.\n      Set δ(z(v,c),1):={z(v+1,c)}\\delta(z(v,c), 1) := \\{z(v + 1,c)\\}δ(z(v,c),1):={z(v+1,c)} if ψ(v+1)=1\\psi(v + 1) = 1ψ(v+1)=1.\n      Set δ(z(v,c),0):={z(v+1,c)}\\delta(z(v,c), 0) := \\{z(v + 1,c)\\}δ(z(v,c),0):={z(v+1,c)} and δ(z(v,c),1):={z(v+1,c)}\\delta(z(v,c), 1) := \\{z(v + 1,c)\\}δ(z(v,c),1):={z(v+1,c)} if ψ(v+1)=∗\\psi(v + 1) = *ψ(v+1)=∗.\n    \n  \n  Mark all states with v=0v = 0v=0 as initial: S:={z(0,c):1≤c≤k}S := \\{z(0, c) : 1 \\le c \\le k\\}S:={z(0,c):1≤c≤k}.\n  Mark all states with v=nv = nv=n as final: E:={z(n,c):1≤c≤k}E := \\{z(n, c) : 1 \\le c \\le k\\}E:={z(n,c):1≤c≤k}.\n\n\nBy construction, MMM will accept any variable assignment a1,…,an∈Σna_1,\\dots,a_n \\in \\Sigma^na1​,…,an​∈Σn where f(a1,…,an)=0f(a_1, \\dots, a_n) = 0f(a1​,…,an​)=0. As φ\\varphiφ has exactly 2n2^n2n variable assignments, it is satisfiable if and only if the set of accepted variable assignments L(M)L(M)L(M) has at most m:=2n−1m := 2^n - 1m:=2n−1 elements.\n\nThis reduction can clearly be done in polynomial time.\n\nIntuition &amp; Example\n\nConsider the following function:\n\nφ:=(cˉ+d)(aˉ+c+dˉ)(aˉ+bˉ+d)\\varphi := (\\bar{c} + d)(\\bar{a} + c + \\bar{d})(\\bar{a} + \\bar{b} + d)φ:=(cˉ+d)(aˉ+c+dˉ)(aˉ+bˉ+d)\n\nThe cubes that describe variable assignments where φ\\varphiφ is false are **10, 1*01 and 11*0 (variable order: a,b,c,da, b, c, da,b,c,d). These three cubes make the first, second and the third clauses false, respectively.\n\nWe can visualize all the possible variable assignments with a 4-dimensional cube (as φ\\varphiφ has 4 variables):\n\n\n\nIn this cube, every edge connects assignments that differ in exactly one bit (i.e. hamming distance = 1). Any lower dimensional cubes that are subgraphs of this cube are implicants if the vertices in the subgraph cover only assignments where the function is true. If a lower dimensional cube isn’t a part of some higher dimensional cube that still covers only assignments where the function is true, such a cube is a prime implicant. In this case, if we think of CNF-clauses as implicants of the negated function, then we can visualize them the following way:\n\n\n\nThe idea of the reduction is that if we can count the amount of vertices covered by these cubes, then we can compare this amount to the total number of vertices and if it is less than 2n2^n2n where nnn is the number of variables, then the function is satisfiable, otherwise not. The problem is that implicants aren’t always disjoint. So, the satisfiability problem is essentially the problem of comparing 2n2^n2n with the size of the union of variable assignments described by cubes.\n\nThese variable assignments that are parts of some cube(s) can be accepted with a nondeterministic finite automata (NFA) with nnn states. We can create such an NFA for each clause and then union them by marking multiple states as initial. In this example, we get the following NFA:\n\n\n\nThe top row of the NFA accepts variable assignments generated by the 11*0 cube, the middle row corresponds to the 1*01 cube and the bottom one - to **10. φ\\varphiφ is satisfiable if and only if there is at least one word of length 4, such that this NFA doesn’t accept it.\n\nConverting the NFA to a BDD\n\nThe idea of this reduction can be used to compute all the satisfying assignments of φ\\varphiφ. Consider the example above - we can apply the Rabin-Scott algorithm to convert the NFA to a DFA:\n\n\n\nThe computed DFA will always be a tree (without the ∅\\varnothing∅-node), because the initial NFA had no cycles in it. The satisfying assignments are the ones that are not accepted by the NFA. Therefore, they are exactly the paths of length nnn, leading to ∅\\varnothing∅. A program can easily output all satisfying assignments with a DFS or BFS-search in this tree.\n\nIf we replace ∅\\varnothing∅ with the positive leaf and all final states with a negative leaf (the transitions after them can be removed), then the graph will become an ordered binary decision diagram (OBDD) of φ\\varphiφ:\n\n\n\nOf course, the nodes should be renamed to variable names:\n\n\n\nThe Rabin-Scott algorithm doesn’t always output minimal deterministic automations and therefore in most cases the OBDD will also not be minimal, like in this case where the redundant checks are clearly seen. In order to get a ROBDD we will still need to apply the elimination and the isomorphism rules (remove redundant checks and reuse subtrees):\n\n\n\nNP-Complete special case\n\nWe can tweak the problem defined above to make it belong to NP\\mathcal{NP}NP:\n\nName: NFA Rejected m-string\n\nInput: A nondeterministic finite automata (NFA) M:=(Z,Σ,δ,S,E)M := (Z, \\Sigma, \\delta, S, E)M:=(Z,Σ,δ,S,E) and a unary-encoded number m∈Nm \\in \\mathbb{N}m∈N.\n\nQuestion: Exists such a string α∈Σ∗\\alpha \\in \\Sigma^*α∈Σ∗ of length mmm such that α∉L(M)\\alpha \\notin L(M)α∈/​L(M)?\n\nThis problem is in NP\\mathcal{NP}NP, because a string of length mmm can be used as a certificate. Then, by using the idea of the Rabin-Scott theorem, we can test whether the given string is rejected or not in polynomial time. The NP\\mathcal{NP}NP-hardness can be shown with a reduction from CNF-SAT as follows:\n\n\n  Consider a formula φ\\varphiφ with kkk clauses and nnn variables.\n  Construct an NFA M=(Z,Σ,δ,S,E)M = (Z, \\Sigma, \\delta, S, E)M=(Z,Σ,δ,S,E) by following the same steps as in the proof of NP\\mathcal{NP}NP-hardness of NFA Language Size.\n  Set m:=nm := nm:=n.\n\n\nφ\\varphiφ is satisfiable if and only if there is a rejected string of length mmm in L(M)L(M)L(M) which is exactly some satisfying assignment for φ\\varphiφ. Clearly, this is a polynomial-time reduction.\n\nFinding any rejected string is NP-Complete\n\nWe can also define another version of the problem and proof it’s NP\\mathcal{NP}NP-completeness:\n\nName: NFA Rejected String\n\nInput: A nondeterministic finite automata (NFA) M:=(Z,Σ,δ,S,E)M := (Z, \\Sigma, \\delta, S, E)M:=(Z,Σ,δ,S,E) and a unary-encoded number m∈Nm \\in \\mathbb{N}m∈N.\n\nQuestion: Exists such a string α∈Σ∗\\alpha \\in \\Sigma^*α∈Σ∗ with ∣α∣≤m\\st \\alpha \\st \\le m∣α∣≤m such that α∉L(M)\\alpha \\notin L(M)α∈/​L(M)?\n\nThis problem is in NP\\mathcal{NP}NP, because a string of length mmm can be used as a certificate, like in the NFA Rejected m-string problem.\n\nWe will prove NP\\mathcal{NP}NP-hardness by reducing NFA Rejected m-string to this problem. Consider an NFA M:=(Z,Σ,δ,S,E)M := (Z, \\Sigma, \\delta, S, E)M:=(Z,Σ,δ,S,E) and a number m′∈Nm&#x27; \\in \\mathbb{N}m′∈N:\n\n\n  Create mmm new nodes q1,…,qm∈Zq_1, \\dots, q_m \\in Zq1​,…,qm​∈Z.\n  For all 1≤s&lt;m1 \\le s &lt; m1≤s&lt;m and a∈Σa \\in \\Sigmaa∈Σ, set δ(qs,a):={qs+1}\\delta(q_s, a) := \\{q_{s+1}\\}δ(qs​,a):={qs+1​}.\n  Mark q1q_1q1​ as initial: S:=S∪{q1}S := S \\cup \\{q_1\\}S:=S∪{q1​}.\n  Mark q1,…,qmq_1, \\dots, q_mq1​,…,qm​ as final: E:=E∪{qi:1≤i≤m}E := E \\cup \\{q_i : 1 \\le i \\le m\\}E:=E∪{qi​:1≤i≤m}.\n  Set m:=m′m := m&#x27;m:=m′.\n\n\nBy construction, the new NFA will accept all strings of length m−1m - 1m−1 or less. Thus, there is a rejected string of length mmm if and only if there is a rejected string of length at most mmm in the new NFA. Obviously, this is a polynomial-time reduction.\n\nA few words about complexity\n\nThese problems illustrate an interesting connection between NP\\mathcal{NP}NP-complete problems, that can be solved in polynomial time by nondeterministic turing machines and the problem of just counting the language size described by an NFA. By the Rabin-Scott theorem, it is possible to convert any NFA to an equivalent DFA, but the worst-case complexity of the algorithm is Θ(2n)\\Theta(2^n)Θ(2n), because a set with nnn elements has 2n2^n2n subsets and all of these subsets will be reachable in the worst-case. Would the complexity of the subset-construction be polynomial, then it would mean that P=NP\\mathcal{P}  = \\mathcal{NP}P=NP as we can just search for all paths in the DFA that lead to ∅\\varnothing∅ after exactly nnn transitions (these paths are exactly the variable assignments that satisfy φ\\varphiφ).\n\nThe reduction discussed above can also be done in reverse. Any set of cubes can be transformed to a boolean function in conjunctive normal form. So, if P=NP\\mathcal{P} = \\mathcal{NP}P=NP and the CNF-SAT problem is solvable in polynomial time, then it is also possible to compare 2n2^n2n with the size of the union of some arbitrary boolean cubes. The cube union size problem is essentially a special case of the inclusion–exclusion principle, where the formula to compute the size of a union of nnn sets is also exponentially long, because the amount of possible intersections grows exponentially.\n\nIt seems impossible to compute the size of the union of some arbitrary cubes in polynomial time, because the variable assignments that some cube describes is exponential in the length of the encoding of the cube. And the amount of ways to intersect some cubes is also exponential. Any polynomial encoding for a cube will allow us to distinguish between an exponential amount of cubes. However, the amount of ways to intersect some kkk nnn-variable-cubes is in Ω(3(3n⋅(k−1)))\\Omega(3^{(3^{n \\cdot (k - 1)})})Ω(3(3n⋅(k−1))), so it is impossible to precisely encode the union of these kkk cubes with a polynomially long encoding. However, it could be possible to divide the search space so that it is still possible to compare 2n2^n2n with the size of the union of the cubes in polynomial time. Anyway, these thoughts aren’t even close to a formal proof that P≠NP\\mathcal{P} \\neq \\mathcal{NP}P​=NP.\n",
      "categories": ["cs"],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/cs/regular-language-size-np-hard/"
    },{
      
      "title": "Computer Science",
      "date": "2020-10-22 18:33:40 +0200",
      "description": "This category contains all posts that have something to do with theoretical or practical computer science.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "featured_categories",
      "url": "/blog/cs/"
    },{
      "image": "/assets/img/projects/crproxy.jpg",
      "title": "Clash Royale Proxy",
      "date": "2018-07-01 00:00:00 +0200",
      "description": "CrProxy is a NodeJs implementation of a Clash Royale proxy server. It decrypts traffic between Supercell servers and the game.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/crproxy/"
    },{
      "image": "/assets/img/projects/zeropackerjs.svg",
      "title": "ZeroPackerJs",
      "date": "2018-11-20 00:00:00 +0100",
      "description": "ZeroPackerJs is serializing / deserializing library for javascript. Data is represented in binary format.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/zeropacker/"
    },{
      "image": "/assets/img/projects/apowbmodc.svg",
      "title": "ApowBmodC",
      "date": "2018-12-07 00:00:00 +0100",
      "description": "ApowBmodC is my small implementation of the efficient a ^ b mod c calculation algorithm.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/apowbmodc/"
    },{
      "image": "/assets/img/projects/sdlgrapher.jpg",
      "title": "SDL Grapher",
      "date": "2019-02-04 00:00:00 +0100",
      
      "content": "SdlGrapher allows you to plot graphs for mathematical functions with SDL 2.0 in C++.\n\nFeatures\n\n\n  Horizontal / vertical scrolling.\n  Scaling with mouse wheel.\n  No rendering if the math function returns NaN or Infinity.\n  Movable axises. Screen =&gt; Math, Math =&gt; Screen unit converters.\n  Automatically calculate scale and axis position based on interval of the math function.\n  Pixel perfect rendering.\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/sdlgrapher/"
    },{
      "image": "/assets/img/projects/bst.jpg",
      "title": "BST",
      "date": "2019-06-08 00:00:00 +0200",
      "description": "Optimized binary search tree implementation in C++.\n",
      "content": "Note: Binary search trees are not balanced by definition. This implementation does not guarantee O(log n) complexity when searching or deleting.\n\nFeatures\n\n  Pretty good performance compared to many other implementations on the internet.\n  No recursion except for debugging purposes.\n  Node-based on-delete balancing is supported. If you don’t need it, you can easily disable it.\n  Unique / non-unique element insertion.\n  2 deletion methods are supported:\n    \n      With payload copying (efficient, when it’s size is less than 2 * sizeof(void*)).\n      With pointer rearrangement.\n    \n  \n  Debug tree printing with indentation.\n  Lightweight, only one header file.\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/bst/"
    },{
      "image": "/assets/img/projects/chainhashmap.svg",
      "title": "ChainHashMap",
      "date": "2019-06-21 00:00:00 +0200",
      "description": "This is an implementation of a closed-addressed hash map in C++ without STL.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/chainhashmap/"
    },{
      "image": "/assets/img/projects/lzz.jpg",
      "title": "LZZ",
      "date": "2019-08-26 00:00:00 +0200",
      "description": "LZZ is a URL shortener that allows changing target URL’s after they have been created.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/lzz/"
    },{
      "image": "/assets/img/projects/cstring.jpg",
      "title": "CString",
      "date": "2019-08-27 00:00:00 +0200",
      "description": "Header-only, expandable and descriptor-caching string implementation in C99.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/cstring/"
    },{
      "image": "/assets/img/projects/zerorobo/gameplay01.png",
      "title": "ZeroRobo",
      "date": "2019-10-25 00:00:00 +0200",
      "description": "This is my RoboCode robot implemented in Java. It moves around special anchor points that allow it to avoid enemy bullets. Only 1vs1 mode is supported.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/zerorobo/"
    },{
      "image": "/assets/img/projects/vkantispam.jpg",
      "title": "VkAntiSpam",
      "date": "2019-11-01 00:00:00 +0100",
      "description": "Intelligent, integrated and self-learning antispam system for filtering spam in VK groups.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/vkantispam/"
    },{
      "image": "/assets/img/projects/chrem.jpg",
      "title": "chrem",
      "date": "2020-01-18 00:00:00 +0100",
      "description": "Algorithm to solve a linear system of congruences using the Chinese remainder theorem. Works also for non-coprime divisors.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/chrem/"
    },{
      "image": "/assets/img/projects/pollardrsacracker.jpg",
      "title": "PollardRsaCracker",
      "date": "2020-02-21 00:00:00 +0100",
      "description": "RSA cracking algorithm based on Pollard factorization.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/pollardrsacracker/"
    },{
      "image": "/assets/img/projects/knife.jpg",
      "title": "Knife",
      "date": "2020-03-31 00:00:00 +0200",
      "description": "Knife is a tool that reads input grammar in BNF format and converts it to a few Java classes that can parse the given grammar through a simple interface.\n",
      "content": "Knife doesn’t require any external libraries or dependencies. All generation is done ahead-of-time. After generating the parsing classes you can just copy them into your project.\n\nAlso, as other good parser generation tools, knife uses itself to read the input grammar.\n\nFeatures\n\n\n  No runtime dependencies, knife generates pure Java code that can easily be ported to other JVM-based languages.\n  Parsing is done using push-down automata without recursion.\n  Knife uses an explicit API for accepting the token stream. It allows you to easily use knife with any (including your own) lexer. You can pause and resume parsing at any point. Parsing multiple token streams simultaneously is also possible.\n  No complete parse-trees are being built during parsing. Reduction of the tree is done on-the-fly for performance. Optimized AST’s can be built during parsing with minimal overhead.\n  If your grammar is left-recursive without A =&gt;* A derivations (aka without cycles), knife will generate an equivalent grammar without left recursion for you.\n  Syntax error recovery using panic mode approach without any additional performance overhead.\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/knife/"
    },{
      "image": "/assets/img/projects/grammax.jpg",
      "title": "Grammax",
      "date": "2020-05-21 00:00:00 +0200",
      "description": "Grammax takes a grammar in BNF format as an input and converts it to a Java-class that recognizes the language generated by the grammar. Formally speaking, this tool creates a left-to-right, rightmost derivation (LR) parser for a given grammar. That means that grammax parses the given string by constructing a reversed rightmost derivation of it.\n",
      "content": "Grammax doesn’t require any external libraries or dependencies. All generation is done ahead-of-time. After generating the parsing classes you can just copy them into your project.\n\nAlso, as other good parser generation tools, grammax uses itself to read the input grammar.\n\nFeatures\n\n\n  No runtime dependencies, only pure Java code is generated.\n  Parsing is done using a push-down automation without recursion.\n  Grammax uses an explicit API for accepting the token stream. It allows you to easily use the tool with any (including your own) lexer. You can pause and resume parsing at any point. Parsing multiple token streams simultaneously is also possible.\n  Grammax supports simple lr and canonical lr parsing algorithms.\n  Automatic warnings about possible right-recursion cycles that cause a lot of parsing stack memory consumption.\n  Types can be assigned to terminals and non-terminals. The corresponding expressions are casted automatically.\n  The %top statement allows inserting package and import automatically. Therefore grammax can be used in an automated pipeline.\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/grammax/"
    },{
      "image": "/assets/img/projects/garbageset.jpg",
      "title": "GarbageSet",
      "date": "2020-05-22 00:00:00 +0200",
      "description": "Set data structure with all operation is O(1), including initialization!\n",
      "content": "This is a set data structure implementation in C. It can be initialized in constant time what makes it different compared to typical set implementation.\n\nComplexity\n\nThe following table gives an overview of what the datastructure is capable of. All the complexities are calculated assuming memory allocation is performed in O(1).\n\n\n  \n    \n      Operation\n      Description\n      Complexity\n    \n  \n  \n    \n      garbageset_init\n      Initializes the data structure with the specified capacity.\n      O(1)\n    \n    \n      garbageset_isset\n      Checks if there is an element at a specified index.\n      O(1)\n    \n    \n      garbageset_get\n      Retrieves the element at a specified indexor returns null, if there is no element at that index.\n      O(1)\n    \n    \n      garbageset_write\n      Writes a new element at the specified index or overwrites an old one if it was defined.\n      O(1)\n    \n  \n\n\nSpace complexity\n\nThe space complexity of the data structure is in O(n). However, apart from storing the payload array itself the data structure requires additional space for redundancy checking purposes. This additional space is about 2*n*sizeof(index_t) bytes where n is the capacity and index_t is the type used for indexes. With this user-defined you can easily reduce the memory overhead.\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/garbageset/"
    },{
      "image": "/assets/img/projects/numpat.jpg",
      "title": "NumPat",
      "date": "2020-08-30 00:00:00 +0200",
      "description": "Research tool for examining integer digit structure in different remainder classes.\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/numpat/"
    }
  ]
}

